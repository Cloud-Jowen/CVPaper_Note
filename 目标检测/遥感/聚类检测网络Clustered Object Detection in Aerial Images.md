## 聚类检测网络ClusDet-Clustered Object Detection in Aerial Images.

[**网络总结**](#网络总结)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](2.相关工作Relatedwork)  
[**3.网络结构**](3.网络结构)  
[**4.实验 Experiments**](4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



### 网络总结
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  

<a id="0. 摘要Abstract"></a>
### 0.摘要 Abstract
在航拍图像中检测物体是具有挑战性的，至少有两个原因：  
**（1）目标物体（如行人）在像素上非常小，使它们很难与周围背景区分开来；**  
**（2）目标通常分布稀疏且不均匀，使得检测非常低效。**  


本文针对这两个问题提出了一种解决方案，灵感来自于观察到这些目标通常是聚集在一起的。具体而言，我们提出了一种名为“Clustered Detection (ClusDet)”的网络，它将对象聚类和检测统一在一个端到端的框架中。  
ClusDet的关键组件包括**聚类提议子网络（CPNet）**、**尺度估计子网络（ScaleNet）** 和 **专用检测网络（DetecNet）**。给定输入图像，CPNet生成对象聚类区域，ScaleNet估计这些区域的对象尺度。然后，每个经过尺度归一化的聚类区域都被送入DetecNet进行对象检测。  


ClusDet相比以前的解决方案具有几个**优点**：  
**（1）它大大减少了最终对象检测的图像块数量，从而实现了高运行时间效率；**  
**（2）基于聚类的尺度估计比以前使用的基于单个对象的估计更准确，因此有效地改善了小目标的检测；**   
**（3）最终的DetecNet专门针对聚类区域，并隐含地模拟先前的上下文信息，从而提高了检测精度。**  
该方法在三个流行的航拍图像数据集（包括VisDrone、UAVDT和DOTA）上进行了测试。在所有实验中，ClusDet与最先进的检测器相比取得了很好的性能。代码在 https://github.com/fyangneil

<a id="1.介绍Introduction"></a>
### 1.介绍 Introduction
随着深度神经网络的发展，目标检测（例如Faster R-CNN [27]、YOLO [25]、SSD [23]）在自然图像（例如MS COCO[22]中的600×400像素图像）方面近年来取得了巨大进展。尽管这些检测器在一般目标检测方面表现出有前途的结果，但它们在航拍图像（例如VisDrone [37]中的2,000×1,500像素图像）上的性能在准确性和效率方面都远远不如人意，这是由两个挑战引起的：（1）相对于图像，目标通常具有较小的尺度；（2）目标通常在整个图像中分布稀疏且不均匀。

与自然图像中的目标相比，尺度挑战导致深度网络在航拍图像中对目标的特征表示效果较差。因此，现代检测器很难有效利用外观信息来区分目标与周围背景或相似对象。为了解决尺度问题，一个自然的解决方案是将航拍图像划分为几个均匀的图像块，然后对每个图像块进行检测[10, 24]。虽然这些方法在一定程度上缓解了分辨率挑战，但由于忽视了目标的稀疏性，执行检测时效率低下。因此，大量的计算资源被低效地应用于稀疏甚至没有目标的区域（见图1）。  
![image](https://github.com/Cloud-Jowen/CVPaper_Note/assets/56760687/3673e1c8-f1d5-4928-937c-f0ffe0114dbe)  

(图1:基于网格的均匀划分和提出的基于聚类的划分的比较。为了叙述目的，我们故意将图像块分为稀疏、普通和聚类三种类型。我们观察到，在基于网格的均匀划分中，超过73%的图像块是稀疏的（包括23%的图像块没有目标），约25%的图像块是普通的，约2%的图像块是聚类的。相比之下，对于基于聚类的划分，约50%的图像块是稀疏的，35%是普通的，约15%属于聚类图像块，这是基于网格划分的7倍之多。)**(2023.10.25 Jowen:图一主要是证明 gt 在图像中是成聚类分布的,按照聚类对图片划分的出的图像块包含的 gt 更多一些)**

我们从图1中观察到，在航拍图像中，目标不仅稀疏且不均匀分布，而且往往在某些区域呈高度聚集。例如，行人通常集中在广场上，车辆集中在高速公路上。因此，提高检测效率的一种直观方法是将检测器聚焦在这些聚集区域上，这些区域有大量的目标存在。  

本文受到这一动机的启发，提出了一种新颖的聚类检测（ClusDet）网络，通过将目标和聚类检测集成到一个统一的框架中来解决上述两个挑战。如图2所示  
![image](https://github.com/Cloud-Jowen/CVPaper_Note/assets/56760687/9c183619-15ae-4554-b28f-d007471fed65)  
图2：聚类对象检测（ClusDet）网络。ClusDet网络由三个关键组件组成：（1）聚类提案子网（CPNet）；（2）尺度估计子网（ScaleNet）；以及（3）专用检测网络（DetecNet）。CPNet用于预测聚类区域。ScaleNet用于估计聚类中物体的尺度。DetecNet在聚类图像块上执行检测。最终的检测结果通过融合来自聚类图像块和全局图像的检测结果生成。ICM（迭代聚类合并）和PP（分区和填充）的详细信息在第3节中给出。

ClusDet包括三个关键组件，包括聚类提议子网络（CPNet）、尺度估计子网络（ScaleNet）和基线检测网络（DetecNet）。根据航拍图像的初始检测结果，CPNet生成一组目标聚类区域。在获取聚类区域之后，它们被裁剪出来进行后续的精细检测。为此，这些区域首先必须被调整大小以适应检测器，这可能会导致聚类区域中的目标过大或过小，从而降低检测性能[30]。为了解决这个问题，我们提出了ScaleNet来估计每个聚类图像块中目标的适当尺度，然后在将其馈送到检测器之前相应地调整图像块的大小，这与[10、24、18]通过直接调整裁剪图像块的方法不同。然后，每个聚类图像块都被馈送到专用的检测器DetecNet进行精细检测。最终的检测结果是通过融合聚类图像块和全局图像上的检测结果来实现的。  

与之前的方法相比，提出的ClusDet具有以下几个优势：（i）由于CPNet的存在，我们只需要处理具有大量目标的聚类区域，这显著降低了计算成本并提高了检测效率；（ii）借助ScaleNet的帮助，每个聚类图像块都经过精细调整以实现更好的后续细节检测，从而提高了准确性；（iii）DetecNet专门用于聚类区域检测，并隐式地对先前的上下文信息进行建模，以进一步提高检测准确性。在三个航拍图像数据集上的广泛实验中，ClusDet在使用单一方法的同时以较少的计算成本实现了最佳性能。

总结起来，该论文的贡献如下：
1）提出了一种新颖的ClusDet网络，用于同时解决航拍图像中目标检测的尺度和稀疏性挑战。
2）提出了一种有效的ScaleNet，以缓解聚类图像块中非均匀尺度问题，实现更好的细节检测。
3）在包括VisDrone [37]、UAVDT [8]和DOTA [33]在内的三个代表性航拍图像数据集上实现了最先进的性能，并且计算成本较低。

<a id="2.相关工作Related work"></a>
### 2.相关工作 Related work
目标检测在过去几十年中得到了广泛的研究，有大量的文献可供参考。接下来，我们首先回顾了与我们的工作最相关的三个研究方向，然后强调了ClusDet与现有方法的区别。

**通用目标检测**。受图像识别（Image Recognition）的成功启发[17]，深度卷积神经网络（CNNs）在目标检测中占据主导地位。根据检测流程，现有的检测器大致可以分为两类：基于区域的检测器和无区域的检测器。基于区域的检测器将检测分为两个步骤，包括提取候选区域（即proposals）和目标检测。在第一阶段，通过提取候选区域显著减少了检测的搜索空间。在第二阶段，这些候选区域进一步被分类到具体的目标类别中。基于区域的检测器的代表包括R-CNN [12]、Fast/er R-CNN [11, 27]、Mask R-CNN [14]和Cascade R-CNN [3]。相反，无区域的检测器，如SSD [23]、YOLO [25]、YOLO9000 [26]、RetinaNet [21]和RefineDet [36]，在没有区域提议的情况下进行检测，这牺牲了一定的准确性，但具有较高的效率。

尽管这些通用检测器在自然图像上（例如PASCAL VOC [9]中的500×400图像和MS COCO [22]中的600×400图像）表现出优秀的性能，但当应用于高分辨率航拍图像（例如VisDrone [37]中的2,000×1,500图像，甚至更大的无人机捕获图像[19]）时，它们的性能会降低。值得注意的是，最近高分辨率图像中的目标检测引起了越来越多的研究关注[32]。

**航拍图像检测**。与自然图像中的检测相比，航拍图像中的检测更具挑战性，因为（1）对象相对于高分辨率航拍图像具有较小的尺度，（2）目标是稀疏和不均匀的，并且集中在某些区域。由于本文侧重于深度学习，我们仅回顾一些使用深度神经网络进行航拍图像检测的相关工作。在[28]中，提出了一种基于简单CNN的方法，用于自动检测航拍图像中的目标。在[2]中，将航拍图像中的检测与语义分割相结合以提高性能。在[31]中，作者直接扩展了Fast/er R-CNN [11, 27]以用于航拍图像中的车辆检测。[6]的工作提出了一种耦合的基于区域的CNN，用于航空器检测。[7]的方法研究了航拍图像检测中Region of Interests (RoI)和对象之间的错位问题，并引入了ROI变换器来解决这个问题。[35]的算法提出了一种适应尺度的候选区域网络，用于航拍图像中的目标检测。

**区域搜索策略**。在目标检测中，通常采用区域搜索策略来处理小目标。[24]的方法提出了自适应地将计算资源引导到稀疏和小目标所在的子区域。[1]的工作引入了一种上下文驱动的搜索方法，以高效地定位包含特定类别对象的区域。[4]的作者提出了通过学习上下文关系来动态探索基于候选区域的目标检测中的搜索空间的方法。[10]的方法提出利用强化学习来顺序选择更高分辨率尺度上的检测区域。在更具体的领域中，如广域航拍运动影像（WAMI）中的车辆检测，[18]的工作建议使用两阶段的时空卷积神经网络从WAMI序列中检测车辆。

**本文方法**。本文旨在解决航拍图像检测中的两个挑战。我们的方法与之前基于区域搜索的检测器（如[24，10]）相关但不同，这些检测器将高分辨率图像分割成小的均匀图像块进行检测。相反，我们的解决方案首先在图像中预测聚类区域，然后提取这些聚类区域进行精细检测，从而显着减少计算成本。虽然[18]的方法也在可能包含对象的图像块上执行检测，但我们的方法与其有很大不同。在[18]中，获得的图像块直接调整大小以适应后续检测器进行检测。相反，受[30]中观察到的极端尺度对象可能会降低检测性能的启发，我们提出了一个ScaleNet来缓解这个问题，在每个图像块上进行精细检测，从而提高检测性能。

<a id="3.网络结构"></a>
### 3.网络结构
#### 3.1 Overview
如图2所示，航拍图像的检测由三个阶段组成：聚类区域提取，聚类图像块上的精细检测和检测结果的融合。具体而言，在提取航拍图像的特征后，CPNet将特征映射作为输入并输出聚类区域。为了避免处理过多的聚类图像块，我们提出了一个迭代聚类合并（ICM）模块来减少噪声聚类图像块。然后，将聚类图像块以及全局图像的初始检测结果输入ScaleNet，以估计聚类图像块中对象的适当尺度。利用尺度信息，对聚类图像块进行缩放，并使用DetecNet进行精细检测。最终的检测结果通过标准的非极大值抑制（NMS）融合每个聚类图像块和全局图像的检测结果得到。

<a id="4.实验Experiments"></a>
### 4.实验 Experiments

<a id="5.结论Conclusion"></a>
### 5.结论 Conclusion
贴上网络使用的损失函数









