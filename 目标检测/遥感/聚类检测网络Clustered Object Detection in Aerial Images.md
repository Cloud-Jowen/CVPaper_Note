## 聚类检测网络ClusDet-Clustered Object Detection in Aerial Images.

[**网络总结**](#网络总结)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](2.相关工作Relatedwork)  
[**3.网络结构**](3.网络结构)  
[**4.实验 Experiments**](4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



### 网络总结
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  

<a id="0.摘要Abstract"></a>
### 0.摘要 Abstract
在航拍图像中检测物体是具有挑战性的，至少有两个原因：  
**（1）目标物体（如行人）在像素上非常小，使它们很难与周围背景区分开来；**  
**（2）目标通常分布稀疏且不均匀，使得检测非常低效。**  


本文针对这两个问题提出了一种解决方案，灵感来自于观察到这些目标通常是聚集在一起的。具体而言，我们提出了一种名为“Clustered Detection (ClusDet)”的网络，它将对象聚类和检测统一在一个端到端的框架中。  
ClusDet的关键组件包括**聚类提议子网络（CPNet）**、**尺度估计子网络（ScaleNet）** 和 **专用检测网络（DetecNet）**。给定输入图像，CPNet生成对象聚类区域，ScaleNet估计这些区域的对象尺度。然后，每个经过尺度归一化的聚类区域都被送入DetecNet进行对象检测。  


ClusDet相比以前的解决方案具有几个**优点**：  
**（1）它大大减少了最终对象检测的图像块数量，从而实现了高运行时间效率；**  
**（2）基于聚类的尺度估计比以前使用的基于单个对象的估计更准确，因此有效地改善了小目标的检测；**   
**（3）最终的DetecNet专门针对聚类区域，并隐含地模拟先前的上下文信息，从而提高了检测精度。**  
该方法在三个流行的航拍图像数据集（包括VisDrone、UAVDT和DOTA）上进行了测试。在所有实验中，ClusDet与最先进的检测器相比取得了很好的性能。代码在 https://github.com/fyangneil

<a id="1.介绍Introduction"></a>
### 1.介绍 Introduction
随着深度神经网络的发展，目标检测（例如Faster R-CNN [27]、YOLO [25]、SSD [23]）在自然图像（例如MS COCO[22]中的600×400像素图像）方面近年来取得了巨大进展。尽管这些检测器在一般目标检测方面表现出有前途的结果，但它们在航拍图像（例如VisDrone [37]中的2,000×1,500像素图像）上的性能在准确性和效率方面都远远不如人意，这是由两个挑战引起的：（1）相对于图像，目标通常具有较小的尺度；（2）目标通常在整个图像中分布稀疏且不均匀。

与自然图像中的目标相比，尺度挑战导致深度网络在航拍图像中对目标的特征表示效果较差。因此，现代检测器很难有效利用外观信息来区分目标与周围背景或相似对象。为了解决尺度问题，一个自然的解决方案是将航拍图像划分为几个均匀的图像块，然后对每个图像块进行检测[10, 24]。虽然这些方法在一定程度上缓解了分辨率挑战，但由于忽视了目标的稀疏性，执行检测时效率低下。因此，大量的计算资源被低效地应用于稀疏甚至没有目标的区域（见图1）。  
![image](https://github.com/Cloud-Jowen/CVPaper_Note/assets/56760687/3673e1c8-f1d5-4928-937c-f0ffe0114dbe)  

(图1:基于网格的均匀划分和提出的基于聚类的划分的比较。为了叙述目的，我们故意将图像块分为稀疏、普通和聚类三种类型。我们观察到，在基于网格的均匀划分中，超过73%的图像块是稀疏的（包括23%的图像块没有目标），约25%的图像块是普通的，约2%的图像块是聚类的。相比之下，对于基于聚类的划分，约50%的图像块是稀疏的，35%是普通的，约15%属于聚类图像块，这是基于网格划分的7倍之多。)**(2023.10.25 Jowen:图一主要是证明 gt 在图像中是成聚类分布的,按照聚类对图片划分的出的图像块包含的 gt 更多一些)**

我们从图1中观察到，在航拍图像中，目标不仅稀疏且不均匀分布，而且往往在某些区域呈高度聚集。例如，行人通常集中在广场上，车辆集中在高速公路上。因此，提高检测效率的一种直观方法是将检测器聚焦在这些聚集区域上，这些区域有大量的目标存在。  

本文受到这一动机的启发，提出了一种新颖的聚类检测（ClusDet）网络，通过将目标和聚类检测集成到一个统一的框架中来解决上述两个挑战。如图2所示  
![image](https://github.com/Cloud-Jowen/CVPaper_Note/assets/56760687/9c183619-15ae-4554-b28f-d007471fed65)  
图2：聚类对象检测（ClusDet）网络。ClusDet网络由三个关键组件组成：（1）聚类提案子网（CPNet）；（2）尺度估计子网（ScaleNet）；以及（3）专用检测网络（DetecNet）。CPNet用于预测聚类区域。ScaleNet用于估计聚类中物体的尺度。DetecNet在聚类图像块上执行检测。最终的检测结果通过融合来自聚类图像块和全局图像的检测结果生成。ICM（迭代聚类合并）和PP（分区和填充）的详细信息在第3节中给出。**(2023.10.25 Jowen:图二给出的结构与RCNN结构非常类似，它是将RPN换成聚类提案网络，得到的不同尺度的图像聚类块又送到尺度估计子网，最后)**

ClusDet包括三个关键组件，包括聚类提议子网络（CPNet）、尺度估计子网络（ScaleNet）和基线检测网络（DetecNet）。根据航拍图像的初始检测结果，CPNet生成一组目标聚类区域。在获取聚类区域之后，它们被裁剪出来进行后续的精细检测。为此，这些区域首先必须被调整大小以适应检测器，这可能会导致聚类区域中的目标过大或过小，从而降低检测性能[30]。为了解决这个问题，我们提出了ScaleNet来估计每个聚类图像块中目标的适当尺度，然后在将其馈送到检测器之前相应地调整图像块的大小，这与[10、24、18]通过直接调整裁剪图像块的方法不同。然后，每个聚类图像块都被馈送到专用的检测器DetecNet进行精细检测。最终的检测结果是通过融合聚类图像块和全局图像上的检测结果来实现的。

<a id="2.相关工作Related work"></a>
### 2.相关工作 Related work
如果有相关知识，请在这里补充，例如感受野，1*1卷积核的作用等

<a id="3.网络结构"></a>
### 3.网络结构
这里介绍网络的结构，分为两部分：第一部分是网络主体的结构。第二部分是网络整体的结构 
需要贴上图片  

<a id="4.实验Experiments"></a>
### 4.实验 Experiments

<a id="5.结论Conclusion"></a>
### 5.结论 Conclusion
贴上网络使用的损失函数









