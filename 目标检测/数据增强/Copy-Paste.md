# Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation

[**网络总结**](#网络总结)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.方法 Method**](#3.方法Method)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 网络总结
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  https://arxiv.org/pdf/2012.07177.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
在计算机视觉领域，构建数据高效且能处理罕见物体类别的实例分割模型是一个重要的挑战。利用数据增强是解决这个挑战的一个有前景的方向。在这篇论文中，我们对实例分割中的复制粘贴增强（例如[13, 12]）进行了系统研究，其中我们将物体随机粘贴到图像上。之前关于复制粘贴的研究依赖于对周围视觉环境的建模来进行物体的粘贴。然而，我们发现简单地随机粘贴物体就足够好，并且可以在强基线模型的基础上提供可观的改进。此外，我们还展示了复制粘贴与利用伪标签（例如自训练）通过半监督方法结合起来具有叠加效应。在COCO实例分割任务中，我们实现了49.1的掩膜AP和57.3的边界框AP，比之前最先进方法提高了+0.6的掩膜AP和+1.5的边界框AP。我们进一步证明了复制粘贴在LVIS基准测试中可以带来显著的改进。我们的基线模型在罕见类别上的掩膜AP比LVIS 2020挑战赛获胜模型提高了+3.6。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
实例分割[22, 10]是计算机视觉中的一个重要任务，具有许多现实世界的应用。基于最先进的卷积网络[11, 57, 67]的实例分割模型通常对数据需求较高。同时，为实例分割注释大规模数据集[40, 21]通常是昂贵且耗时的。例如，为COCO数据集的1000个实例掩膜花费了22个工时[40]。因此，开发新方法以提高最先进的实例分割模型的数据效率至关重要。

在这里，我们将重点放在数据增强[50]上，作为一种简单而有效地提高实例分割模型数据效率的方法。尽管许多增强方法，如尺度抖动和随机调整大小已经被广泛使用[26, 25, 20]，但它们更具有通用性，并没有专门为实例分割设计。一种更加物体感知的增强过程，无论是在类别还是形状上，很可能对实例分割有用。复制粘贴增强[13, 12, 15]非常适合这个需求。通过将不同尺度的各种对象粘贴到新的背景图像中，复制粘贴可以免费创建具有挑战性和新颖性的训练数据。

复制粘贴增强的关键思想是将一个图像中的对象粘贴到另一个图像中。这可以产生大量新的训练数据，有多种选择：（1）从哪个源图像中复制实例和将它们粘贴到哪个目标图像上；（2）选择从源图像中复制哪些对象实例；（3）选择在目标图像上的何处粘贴复制的实例。当利用这种数据增强方法时，选项的种类繁多，允许对如何最有效地使用这种技术进行深入探索。之前的研究[12, 15]采用了模型化周围视觉环境来决定额外对象的粘贴位置的方法。相比之下，我们发现简单地随机选择对象并将它们随机粘贴到目标图像上的策略，在多种设置下都可以显著提高性能。具体而言，在骨干架构、尺度抖动程度、训练计划和图像大小的各种设置下，它在基准方法的基础上都有明显的改进。

结合大规模尺度抖动，我们展示了复制粘贴增强在COCO数据集上显著提高数据效率的结果（图1）。特别是，与常用的标准尺度抖动数据增强相比，我们看到数据效率提高了2倍。当只使用COCO训练数据的10%时，我们还观察到低数据情况下的+10个Box AP的增益。

接下来，我们展示了复制粘贴增强策略在自训练中的额外收益[44, 73]，其中我们从标注的真实数据中提取实例，并将它们粘贴到使用伪标签注释的未标记数据上。使用EfficientNet-B7 [56]骨干网络和NAS-FPN [17]架构，在COCO test-dev数据集上实现了57.3的Box AP和49.1的Mask AP，无需测试时增强。这一结果超过了以往的最先进实例分割模型，如SpineNet [11]（46.3 mask AP）和使用测试时增强的DetectoRS ResNeXt-101-64x4d [43]（48.5 mask AP）。尽管使用了较小的图像尺寸1280而不是1536，但性能也超过了EfficientDet-D7x-1536 [57]（55.1 box AP）和YOLOv4-P7-1536 [61]（55.8 box AP）的最先进边界框检测结果。

最后，我们展示了复制粘贴增强在LVIS基准测试中通常使用的两阶段训练过程中产生更好的特征。使用复制粘贴增强，在罕见类别和常见类别上分别获得了6.1和3.7的Mask AP改进。

复制粘贴增强策略容易集成到任何实例分割代码库中，可以有效利用未标记的图像，并且不会增加训练或推断的开销。例如，我们在Mask-RCNN上的实验表明，我们可以将复制粘贴增强应用到其训练中，而无需任何更改，结果可以轻松改进，例如在48个时期上提升1.0 AP。

<a id="2.相关工作Related work"></a>
## 2.相关工作 Related work
**Data Augmentations 数据增强**
与在骨干网络架构[35, 51, 53, 27, 56]和检测/分割框架[19, 18, 47, 38, 26, 39]方面的工作量相比，计算机视觉领域对数据增强[50]相对关注较少。数据增强，诸如随机裁剪[36, 35, 51, 53]、颜色抖动[53]、自动/随机增强[6, 7]在图像分类[27, 56]、自监督学习[28, 24, 5]和半监督学习[64]以及ImageNet [48]基准测试中发挥了重要作用。这些增强方法更具有通用性，主要用于对数据变换进行编码，适用于图像分类[48]。  

**Mixing Image Augmentations  混合图像增强**
混合图像增强。与对数据变换进行编码的增强方法相比，存在一类增强方法，它通过适当改变真实标签将不同图像中的信息混合在一起。一个经典的例子是mixup数据增强方法[66]，它通过输入像素和输出标签的凸组合创建新的数据点。还有一些mixup的改进方法，如CutMix[65]，它不是混合所有像素，而是粘贴图像的矩形裁剪。还有将mixup和CutMix应用于目标检测[69]的案例。在YOLOv4中使用的Mosaic数据增强方法[1]与CutMix类似，它创建了一个由多个单独图像及其真实标签组成的矩形网格的复合图像。虽然mixup、CutMix和Mosaic在合并多个图像或裁剪版本以创建新的训练数据方面很有用，但它们仍然没有考虑到对象，并且并非专门设计用于实例分割任务。  

**Copy-Paste Augmentation 复制粘贴数据增强**
一种将多个图像的信息以对象感知的方式进行组合的简单方法是将一个图像中的对象实例复制并粘贴到另一个图像中。Copy-Paste类似于mixup和CutMix，但只复制与对象对应的精确像素，而不是对象边界框中的所有像素。我们的工作与Contextual Copy-Paste[12]和InstaBoost[15]相比的一个关键区别是，我们不需要建模周围的视觉环境来放置复制的对象实例。一个简单的随机放置策略效果很好，并且在强基线模型上取得了显著的改进。Instaboost[15]与之前的Copy-Paste[12]工作不同之处在于，它不是从其他图像中粘贴实例，而是对图像上已经存在的实例进行扰动。Cut-Paste-and-Learn[13]提出了提取对象实例、将它们混合并粘贴到不同背景上，并在增强图像的基础上进行训练的方法。我们的工作使用了相同的方法，但有一些不同之处：(1)我们不使用几何变换(例如旋转)，并发现对粘贴的实例进行高斯模糊并没有好处；(2)我们研究了在将一个图像中包含的对象粘贴到另一个已经存在实例的图像中的情况下的Copy-Paste，而[13]则研究了在具有一组对象实例和背景场景的情况下进行Copy-Paste以提高性能；(3)我们研究了在半监督学习环境中使用Copy-Paste与自训练相结合的有效性。(4)我们在广泛使用的COCO和LVIS数据集上对Copy-Paste进行了基准测试和深入研究，而Cut-Paste-and-Learn则使用GMU数据集[16]。我们论文的一个重要贡献是展示了在COCO和LVIS上改进最先进的实例分割模型中使用Copy-Paste的效果。  

**Instance Segmentation 实例分割**
实例分割[22,23]是一个具有挑战性的计算机视觉问题，旨在同时检测对象实例并分割每个实例对应的像素。Mask-RCNN[26]是一种广泛使用的框架，大多数最先进的方法[67,11,43]采用该方法。COCO数据集是衡量进展的广泛使用的基准。我们报告了在COCO基准测试中的最新结果，超越了SpineNet [11] 2.8 AP和DetectoRS [43] 0.6 AP。Copy and paste方法也被用于弱监督实例分割。Remez等人[45]引入了一种对抗性方法，其中使用生成器网络预测给定边界框内对象的分割掩码。给定生成的掩码，将对象与另一背景混合，然后使用鉴别器网络确保生成的掩码/图像看起来逼真。与这项工作不同，我们使用Copy-Paste作为增强方法。  

**Long-Tail Visual Recognition 长尾视觉识别**
最近，计算机视觉界开始关注自然图像中存在的对象类别的长尾性质[59, 21]，其中许多不同的对象类别只有很少的标注图像。在训练深度网络时，解决长尾数据的现代方法主要可以分为两组：数据重新采样[41, 21, 62]和损失重加权[30, 8, 3, 54, 37, 46]。其他更复杂的学习方法（例如元学习[63, 29, 32]、因果推断[58]、贝叶斯方法[34]等）也被用来处理长尾数据。最近的研究[9, 3, 33, 71, 37]指出了两阶段训练策略的有效性，通过将特征学习和重新平衡阶段分开，对于特征学习而言，端到端训练与重新平衡策略可能会有害。关于目标检测中数据不平衡的更全面的总结可以在Oksuz等人的工作[42]中找到。我们的工作证明了简单的Copy-Paste数据增强在LVIS基准测试中对单阶段和两阶段训练都能带来显著的收益，特别是对于罕见的对象类别。


<a id="3.方法Method"></a>
## 3.方法 Method
我们使用Copy-Paste生成新数据的方法非常简单。我们随机选择两张图像，并对每张图像应用随机的尺度抖动和随机的水平翻转。然后，我们从其中一张图像中随机选择一部分对象，并将它们粘贴到另一张图像上。最后，我们相应地调整地面实况注释：我们移除完全遮挡的对象，并更新部分遮挡对象的掩码和边界框。

与[15, 12]不同，我们没有对周围环境进行建模，因此生成的图像在对象共现或相关尺度方面可能与真实图像非常不同。例如，非常不同尺度的长颈鹿和足球运动员可能会出现在彼此旁边（见图2）。

![image](https://github.com/Cloud-Jowen/CVPaper_Note/assets/56760687/4b4fef8f-3450-425e-b95d-71560c87f4d0)
图2。我们使用简单的复制和粘贴方法为训练实例分割模型创建新图像。我们在两个随机训练图像上应用随机尺度抖动，然后从一个图像中随机选择一部分实例并将它们粘贴到另一个图像上。

**Blending Pasted Objects 混合粘贴的对象**为了将新对象合成到图像中，我们使用地面实况注释计算粘贴对象的二进制掩码（α），并将新图像计算为 I1 × α + I2 × (1 - α)，其中I1是粘贴的图像，I2是主要图像。为了平滑粘贴对象的边缘，我们对α应用了高斯滤波，类似于[13]中的“混合”方法。但与[13]不同的是，我们还发现，仅仅进行简单的合成而没有任何混合也具有类似的性能。

<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion
贴上网络使用的损失函数









