# Neural Question Generation from Text: A Preliminary Study

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.方法 Approach**](#2.方法Approach)  
&emsp;[**2.1丰富的特征编码器**](#2.1丰富的特征编码器)  
&emsp;[**2.2基于注意力的解码器**](#2.2基于注意力的解码器)  
&emsp;[**2.3相关工作Relatedwork**](#2.3相关工作Relatedwork)  
[**3.实验与结果 Experiments and Results**](#3.实验与结果)  
&emsp;[**3.1 结果和分析 Results and Analysis**](#3.1结果和分析)  
[**4.结论和未来工作 Conclusion and Future Work**](#4.结论和未来工作)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  https://arxiv.org/pdf/1704.01792.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract

自动生成问题的目标是从文本段落中生成可以由给定文本的某些子span回答的问题。传统方法主要使用僵化的启发式规则将句子转换为相关问题。在本文中，我们提出使用神经编码器-解码器模型从自然语言句子生成有意义且多样的问题。编码器读取输入文本和答案位置，以产生一个答案感知的输入表示，该表示馈送到解码器以生成一个关注答案的问题。我们在SQuAD数据集上对神经问题生成进行了初步研究，实验结果表明我们的方法可以产生流利且多样化的问题。


<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction

自然语言文本的自动问题生成旨在根据文本作为输入生成问题，具有教育目的的潜在价值（海曼，2011）。作为问答任务的反向任务，问题生成也有可能提供大量的问答对语料库。

以前的工作主要使用严格的启发式规则将句子转换成相关问题。然而，这些方法严重依赖于人工设计的转换和生成规则，不能轻易应用于其他领域。相反，Serban等人(2016)提出了一种神经网络方法，从结构化数据中生成事实性问题。

在这项工作中，我们对使用神经网络从文本生成问题进行了初步研究，这被称为神经问题生成（NQG）框架，用于在没有预定义规则的情况下从文本文档生成自然语言问题。神经问题生成框架通过在编码器中添加答案和词汇特征来扩展序列到序列模型，以生成关注答案的问题。具体来说，编码器不仅读取输入句子，还读取答案位置指示符和词汇特征。答案位置特征表示输入句子中的答案范围，这对于生成与答案相关的问题至关重要。词汇特征包括词性标记（POS）和命名实体（NER）标签，有助于更好地编码句子。最后，具有注意力机制的解码器（Bahdanau等人，2015年）根据句子生成一个特定的答案问题。

大规模的人工注释的段落与问题对在开发问题生成系统中起着关键作用。我们建议使用最近发布的斯坦福问答数据集（SQuAD）(Rajpurkar等人，2016年)作为问题生成任务的训练和开发数据集。在SQuAD中，答案通过众包被标记为给定句子中的子序列，并且包含超过10万个问题，这使得训练我们的神经网络模型成为可能。我们在SQuAD上进行实验，实验结果表明神经网络模型能够从文本中产生流畅而多样的问题。

<a id="2.方法Approach"></a>
## 2.方法 Approach 

在这部分，我们介绍了NQG框架，它由功能丰富的编码器和基于注意力的解码器组成。图1提供了我们NQG框架的概述。

![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/c62adfdd-35cc-46fd-9485-7ecba04fd045)。
（图1：神经问题生成（NQG）框架概述。）

<a id="2.1丰富的特征编码器"></a>
### 2.1 丰富的特征编码器 Feature-Rich Encoder

在NQG框架中，我们使用门控循环单元（GRU）（Cho等人，2014年）来构建编码器。为了捕获更多的上下文信息，我们使用双向GRU（BiGRU）以正向和反向的顺序读取输入。受Chen和Manning（2014）、Nallapati等人（2016）的启发，BiGRU 编码器不仅阅读句子中的单词，还阅读手工制作的特征，生成一个单词和特征向量序列。我们将词向量、词汇特征嵌入向量和答案位置指示符嵌入向量连接起来作为 BiGRU 编码器的输入。具体来说，BiGRU 编码器读取连接后的句子词向量、词汇特征和答案位置特征 $x = (x_1, x_2, \ldots, x_n)$ 来产生两个隐藏状态序列，即前向序列 $(e_{h,1}, e_{h,2}, \ldots, e_{h,n})$ 和后向序列 $(h_1, h_2, \ldots, h_n)$。最后，编码器的输出序列是这两个序列的拼接，即 $h_i = [e_{h,i}; h_i]$。

答案位置特征为了针对句子中的特定答案生成问题，我们建议使用答案位置特征来定位目标答案。在这项工作中，使用BIO 标记方案对目标答案的位置进行标记。在这种方案中，标签B表示答案的开始，标签I 继续该答案，标签O 表示不构成答案的单词。答案位置的BIO 标签嵌入到实值向量中并通过丰富的编码器馈送。通过BIO 标记功能，答案位置被编码为隐藏向量并用于生成答案聚焦的问题。

词汇特征除了句子单词之外，我们还向编码器馈入其他词汇特征。为了编码更多的语言信息，我们选择词性、POS 和命名实体识别（NER）标签作为词汇特征。在完整的句法分析中，POS 标签功能在许多自然语言处理任务中都很重要，例如信息提取和依存关系分析（Manning 等人，1999 年）。考虑到 SQuAD 是使用维基百科文章构建的，其中包含大量命名实体，因此我们添加了 NER 特征以帮助检测它们。

<a id="2.2基于注意力的解码器"></a>
### 2.2 基于注意力的解码器 Attention-Based Decoder

我们使用基于注意力的 GRU 解码器来对句子进行解码并生成问题。在时间步 t，GRU 解码器读取前一个词嵌入 wt−1 和上下文向量 ct−1 来计算新的隐藏状态 st。我们通过带有最后一个反向编码器隐藏状态 h1r 的线性层来初始化解码器 GRU 隐藏状态。当前时间步 t 的上下文向量 ct 是通过连接注意力机制（Luong 等人，2015）计算得到的，该方法会根据当前解码器状态 st 和每个编码器隐藏状态 hi 计算重要性分数。然后通过对重要性分数进行加权求和来规范化得到当前上下文向量：
```math
s_t = GRU(w_{t-1},c_{t-1},s_{t-1})
```

```math
s_0 = tanh(W_{d}\overleftarrow{h_1}+b)
```

```math
e_{t,i} = v_a^Ttanh(W_as_{t-1}+U_ah_i)
```

```math
\alpha_{t,i}=\frac{exp\left ( e_{t,i} \right ) }{ {\textstyle \sum_{i=1}^{n}\left ( e_{t,i} \right ) } }
```

```math
c_t = \sum_{i=1}^{n}  \alpha_{t,i}h_i
```

然后，我们将前一个词嵌入$`w_{t-1}`$、当前上下文向量$`c_t`$和解码器状态$`s_t`$结合以获得读取状态$`r_t`$。读出状态通过maxout隐藏层（Goodfellow等人，2013）传递，以对解码器词汇表进行softmax预测下一个单词：

```math
r_t = W_rw_{t-1} + U_rc_t + V_rs_t
```

```math
m_t = \left [ max\left \{ r_{t,2j-1},r_{t,2j} \right \}  \right ]_{j=1,...,d}^T
```

```math
p\left ( y_t|y_1,...,y_{t-1} \right ) = softmax(W_om_t)
```

其中，$`r_t`$是一个二维向量。

<a id="2.3相关工作Relatedwork"></a>
## 2.3 相关工作 Related work

为了解决罕见且未知的单词问题，Gulcehre等人。(2016)建议使用指向机制从源句子复制罕见的词。我们在NQG系统中应用了这种指向方法。当解码词t时，复制开关采用当前解码器状态st和上下文向量ct作为输入，并生成从源句子复制一个单词的概率p：

```math
p = σ(W_{s_{t}} + U_{c_{t}} + b)
```

其中σ 是sigmoid函数。我们使用公式4中的注意力概率来决定要复制哪个单词。


<a id="3.实验与结果"></a>
## 3.实验与结果 Experiments and Results

我们使用SQuAD数据集作为训练数据。SQuAD由536篇维基百科文章中众包工作者提出的超过10万个问题组成。我们提取句子-答案-问题三元组来构建训练、开发和测试集。由于测试集尚未公开，因此我们将开发集随机减半以构建新的开发和测试集。从训练集中提取的三元组包含86635个，开发集包含8965个，测试集包含8964个。我们在附录中介绍了实现细节。


**PCFG-Trans**  
PCFG-Trans 是基于规则的系统，它是在 Heilman（2011）发布的代码上修改的。我们修改了代码，使其能够根据给定的词组生成问题。

**s2s+att**  
s2s+att 我们实现了带有注意力机制的 seq2seq 作为基准方法。

**NQG**  
NQG 我们使用具有丰富特征的编码器扩展了 s2s+att，构建了 NQG 系统。

**NQG+**  
NQG+ 基于 NQG，我们引入复制机制来解决罕见单词的问题。

**NQG+Pretrain**  
NQG+Pretrain 基于 NQG+，我们使用预训练的 GloVe 向量（Pennington等人，2014年）初始化单词嵌入矩阵。

**NQG+STshare**  
NQG+STshare 在 NQG+ 的基础上，我们使编码器和解码器共享相同的嵌入矩阵。

**NQG++**  
NQG++ 基于 NQG+，我们同时使用预训练的单词嵌入和共享嵌入矩阵的方法，以进一步提高性能。

**NQG-Answer**  
NQG-答案消融测试，从NQG模型中移除答案位置指示器。

**NQG-POS**  
NQG-词性消融测试，从NQG模型中移除词性标签特征。

**NQG-NER**  
NQG命名实体识别消融测试，从NQG模型中移除命名实体识别功能。

**NQG-Case**。
NQG-大小写消融测试，从NQG模型中移除单词的大小写特征。

<a id="3.1结果和分析"></a>
### 3.1 结果和分析 Results and Analysis

我们使用BLEU-4分数（Papineni等人，2002）作为我们的NQG系统的评估指标。

![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/f99690f8-e794-409c-8c5b-9e90cf732eef)
（表1：基准方法、不同NQG框架配置和一些消融测试的BLEU评估分数。）

表1显示了不同设置的 BLEU-4 分数。我们在开发集和测试集上报告束搜索结果。我们的 NQG 框架在 PCFG-Trans 和 s2s+att 基线方案上有很大的优势。这表明词汇特征和答案位置指示符可以促进问题生成。借助复制机制，NQG+ 在 2.05 BLEU 上取得了改进，因为它解决了罕见词的问题。扩展版本 NQG++ 相比 NQG+ 在 BLEU 得分上提高了 1.11 分，这表明使用预训练的词向量初始化并让编码器和解码器共享它们有助于学习更好的单词表示。

我们通过人类评价来评估 PCFG-Trans 基准和 NQG++ 的性能。评分标准是：好（3）- 问题有意义且非常贴切于给定的句子和答案；中等（2）- 问题大致匹配句子和答案；差（1）- 问题要么没有意义，要么不匹配给定的句子和答案。我们在补充材料中提供了更详细的评分示例。三位人类评标员对从测试集中随机抽取的 200 个问题进行了标记，以判断生成的问题是否与给定的句子和答案段匹配。使用 Fleiss' kappa（Fleiss, 1971）测量了评分者之间的 Agreement。

![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/5a944f84-8922-405f-a417-b02016be8166)
（表2:人工评估结果）

表2报告了人类评分者的结果。卡帕分数显示了人类评分者之间有中等程度的一致性。我们的NQG ++ 比PCFG-Trans 基准模型的得分高0.76分，这表明由NQG ++ 生成的问题与给定的句子和答案区间更加相关。

**消融测试** 
在NQG-Answer消融测试中，答案位置指示符如预期的那样在生成答案聚焦问题时起着关键作用。如果没有它，性能会急剧下降，因为解码器无法获得关于答案子序列的信息。 消融测试，NQG-Case、NQG-POS 和 NQG-NER 显示了词性、词形和命名实体标签特征对问题生成的贡献。

**案例研究**
表3提供了由NQG ++生成的三个示例。带下划线的词是目标答案。这三例分别属于不同的问题类型，即WHEN、WHAT和WHO。可以观察到解码器可以“复制”输入句子中的片段来生成问题。除了下划线单词之外，其他有意义的片段也可以用作答案来生成正确的问题焦点问题。

![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/44e47c61-0523-4cda-a46a-957b5a1841ee)。
（表3：生成问题示例，I 是输入句子，G 是参考问题，O 是 NQG ++ 生成的问题。划线的词是目标答案。）

根据Wang和Jiang（2016）的分类方法，我们将问题分为不同的类型，即WHAT、HOW、WHO、WHEN、WHICH、WHERE、WHY和其他类型。我们评估了每种问题类型的精确度和召回率，并在图2中提供了不同问题类型的精确度和召回率指标。问题类型T的精确度和召回率定义如下：
```math
precision(T) = \frac{(true T-type questions)}{(generated T-type questions)}
recall(T) = \frac{(true T-type questions)}{(all gold T-type questions)}
```
对于大多数问题类型，即WHAT、HOW、WHO 和 WHEN 类型，我们的NQG ++模型在精确率和召回率方面都表现良好。 对于WHICH类型的问题，可以观察到无论是精确率还是召回率都不理想。 这可能是由两个原因造成的：a）有些WHICH类型的问题可以用其他方式提出，例如，“哪个团队” 可以用“谁”代替；b）WHICH类型的问题占训练数据的约7.2％，这可能不足以学习生成此类问题。 同样的原因也可能影响WHY类型问题的精确率和召回率。

<a id="4.结论和未来工作"></a>
## 4.结论和未来工作 Conclusion and Future Work
在这篇论文中，我们初步研究了基于神经网络模型的自然语言问题生成。我们提出应用神经编码器-解码器模型来根据自然语言句子生成关注答案的问题。所提出的方案使用特征丰富的编码器来编码答案位置、词性标注和命名实体识别标签信息。实验结果表明，我们的NQG方法是有效的。在未来的工作中，我们将调查自动生成的问题是否有助于提高问答系统的效果。

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion










