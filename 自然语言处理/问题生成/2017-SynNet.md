# 网络名称（此处应替换为具体的网络名称）

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  https://github.com/davidgolub/QuestionGeneration
论文链接：  https://arxiv.org/pdf/1706.09789.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract

我们开发了一种在机器理解（MC）中进行迁移学习的方法，使用一种新颖的两阶段合成网络（SynNet）。给定一个在某个领域表现良好的 MC 模型，我们的方法旨在回答另一个领域中的文档相关问题，其中不使用任何标记的问题答案对。通过在具有挑战性的 NewsQA 数据集上使用来自 SQuAD 数据集的预训练模型，我们提出的 SynNet 在单个模型上实现了 44.3% 的 F1 分数，在集成模型上实现了 46.6%，接近域内模型（F1 得分为 50.0%）的性能，并且优于域外基线 7.6%，没有使用提供的注释。[1]

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction

机器理解（MC）是在给定的上下文段落中回答问题的能力，它是自然语言处理中的关键任务。对于这项任务来说，高质量、大规模的人工注释数据集的出现（Rajpurkar等人，2016年；Trischler等人，2016年）使得能够训练大量密集但表达能力强的模型，如深度神经网络（Wang等人，2016年；Xiong等人，2016年；Seo等人，2016年）。此外，这些数据集具有吸引人的特点，即答案是段落内的一个短片段文本，这缩小了可能的答案范围。

然而，许多这些模型依赖于大量的人类标记数据来训练。 然而，数据收集是一项耗时且昂贵的任务。 此外，直接在另一个域的段落中使用一个域训练的 MC 模型来回答问题可能会导致性能下降。

虽然研究尚不充分，但能够将一个MC模型转移到多个领域具有很大的实际意义。例如，能够快速使用在维基百科上训练的MC模型来启动客户支持手册或新闻文章上的问答系统，即使没有标记数据也可以解锁大量实用的应用程序。

在本文中，我们通过两阶段合成网络（SynNet）解决MC中的这个问题。SynNet 生成新域中的段落级合成问题答案对，然后用作精细调整原始域上训练的 MC 模型的人工标注替代品。

之前已经探索过使用合成数据来增强不足的训练数据的想法。例如，在翻译任务的目标中，Sennrich等人（2016 年）提出了一种方法，可以利用真实句子生成合成翻译，以改进现有的机器翻译系统。

然而，与机器翻译不同的是，对于像 MC 这样的任务，我们需要根据上下文段落同时合成问题和答案。此外，虽然问题是语法流畅的自然语言句子，但答案通常是段落中的显著语义概念，如命名实体、动作或数字，通常是一个单词或短语。由于答案与问题的语言结构非常不同，因此更合适地将其视为两种不同类型的数据。因此，需要合成(question, answer)元组。

在我们的方法中，我们将生成问题答案对的过程分解为两个步骤：基于段落的答案生成，以及基于段落和答案的问题生成。我们首先生成答案，因为答案通常是关键的语义概念，而问题可以被看作是为了询问这个概念而组成的完整句子。

通过提出SynNet，我们可以超越直接应用在另一个域上训练的高性能MC模型的强大基准线。例如，当我们在SQuAD（Rajpurkar等人，2016）上使用预训练模型来回答CNN / Daily Mail文章中的新闻QA数据集（Tirschler等人，2016）中的问题时，我们可以将单模型SQuAD基准线的性能从39.0％提高到44.3％的F1分数，并进一步通过集成将结果提高到46.6％的F1分数，接近先前发表的工作的结果（Tirschler等人，2016）（50.0％的F1分数），无需在新域中使用标记数据。此外，错误分析表明，我们在所有常见问题类型上的准确性都高于基准线。

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work

<a id="2.1问题回答"></a>
### 2.1 问题回答 Question Answering

问答是自然语言处理中的一个活跃领域，有许多方向的研究正在进行中（Berant 等人，2013；Hill 等人，2015；Golub 和 He，2016；Chen 等人，2016；Hermann 等人，2015）。机器理解，一种提取式问答的形式，在其中答案是一段文本内的片段或多个片段，最近在社区中引起了广泛关注。大规模人类注释数据集的出现，例如超过 100,000 对现实问答对的数据集SQuAD（Rajpurkar 等人，2016），NewsQA（Trischler 等人，2016）和MSMARCO（Nguyen 等人，2016），导致了许多成功的深度学习模型（Lee 等人，2016；Seo 等人，2016；Xiong 等人，2016；Dhingra 等人，2016；Wang 和 Jiang，2016）。

<a id="2.2半监督学习"></a>
### 2.2 半监督学习 Semi-Supervised Learning

半监督学习有着悠久的历史（Chapelle等人，2009年提供了概述），并被应用于自然语言处理中的许多任务，如依存句法分析（Koo 等人，2008 年）、情感分析（Yang 等人，2015 年）、机器翻译（Sennrich 等人，2016 年）以及语义分析（Berant 和 Liang；Wang 等人；Jia 和 Liang，2016 年）。最近的工作在无标记数据上生成合成注释以提高阅读理解模型和视觉问答模型的性能（Yang 等人，2017 年；Ren 等人，2015 年），但仅限于某些形式的已标记数据领域。也有工作致力于生成高质量的问题（Yuan 等人，2017 年；Serban 等人，2016 年；Labutov 等人），但没有关于如何最好地使用它们来训练模型的研究。相比之下，我们使用两阶段的 SynNet 生成数据元组，直接提升在没有任何注释的数据集上的模型性能。

<a id="2.3迁移学习"></a>
### 2.3 迁移学习 Transfer Learning

迁移学习（Pan 和 Yang，2010）已经成功地应用于机器学习的许多领域，如机器翻译（Zoph 等人，2016）、计算机视觉（Sharif Razavian 等人，2014）和语音识别（Doulaty 等人，2015）。具体来说，在大规模图像分类挑战赛（Russakovsky 等人，2015）上训练的对象识别模型被证明是各种任务（例如图像字幕生成（Lu 等人，2016；Fang 等人，2015；Karpathy 和 Fei-Fei，2015）和视觉问答（Zhou 等人，2015；Xu 和 Saenko，2016；Fukui 等人，2016；Yang 等人，2016）等）的出色特征提取器。类似地，我们使用在SQuAD数据集上预先训练的模型作为通用特征提取器来启动NewsQA上的QA系统。

<a id="3.网络结构"></a>
## 3.网络结构

<a id="3.1"></a>
### 3.1


<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion


<a id="6.3.2合成问题"></a>
### 6.3.2 合成问题 Question Synthesis

我们随机抽样了我们的模块生成的合成问题，并在表6中展示了结果。由于复制机制，我们的模型倾向于直接使用段落中的许多单词，尤其是常见的实体，例如示例中的“俄克拉荷马”。因此，一种生成更高质量问题的方法可能是引入一个在解码过程中促进多样性的损失函数，特别是在单个段落内。反过来，这会使 RC 模型接触到新领域中更多样的训练样本，从而提高性能。

<a id="7.结论Conclusion"></a>
## 7.结论 Conclusion

我们介绍了一种用于迁移学习的两阶段SynNet，该任务既具有挑战性又具有实际重要性。通过我们的网络和一种简单的训练算法，我们能够在没有注释数据的情况下从一个域到另一个域泛化MC模型。我们在NewsQA测试集上展示了强大的结果，单个模型比基线BIDAF模型提高了5.3％，集成模型提高了7.6％F1。通过消融研究和错误分析，我们提供了对SynNet和MC模型方法的见解，可以帮助指导此任务的进一步研究。






