# 网络名称（此处应替换为具体的网络名称）

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  https://github.com/davidgolub/QuestionGeneration  
论文链接：  https://arxiv.org/pdf/1706.09789.pdf  

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract

我们开发了一种在机器理解（MC）中进行迁移学习的方法，使用一种新颖的两阶段合成网络（SynNet）。给定一个在某个领域表现良好的 MC 模型，我们的方法旨在回答另一个领域中的文档相关问题，其中不使用任何标记的问题答案对。通过在具有挑战性的 NewsQA 数据集上使用来自 SQuAD 数据集的预训练模型，我们提出的 SynNet 在单个模型上实现了 44.3% 的 F1 分数，在集成模型上实现了 46.6%，接近域内模型（F1 得分为 50.0%）的性能，并且优于域外基线 7.6%，没有使用提供的注释。[1]

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction

机器理解（MC）是在给定的上下文段落中回答问题的能力，它是自然语言处理中的关键任务。对于这项任务来说，高质量、大规模的人工注释数据集的出现（Rajpurkar等人，2016年；Trischler等人，2016年）使得能够训练大量密集但表达能力强的模型，如深度神经网络（Wang等人，2016年；Xiong等人，2016年；Seo等人，2016年）。此外，这些数据集具有吸引人的特点，即答案是段落内的一个短片段文本，这缩小了可能的答案范围。

然而，许多这些模型依赖于大量的人类标记数据来训练。 然而，数据收集是一项耗时且昂贵的任务。 此外，直接在另一个域的段落中使用一个域训练的 MC 模型来回答问题可能会导致性能下降。

虽然研究尚不充分，但能够将一个MC模型转移到多个领域具有很大的实际意义。例如，能够快速使用在维基百科上训练的MC模型来启动客户支持手册或新闻文章上的问答系统，即使没有标记数据也可以解锁大量实用的应用程序。

在本文中，我们通过两阶段合成网络（SynNet）解决MC中的这个问题。SynNet 生成新域中的段落级合成问题答案对，然后用作精细调整原始域上训练的 MC 模型的人工标注替代品。

之前已经探索过使用合成数据来增强不足的训练数据的想法。例如，在翻译任务的目标中，Sennrich等人（2016 年）提出了一种方法，可以利用真实句子生成合成翻译，以改进现有的机器翻译系统。

然而，与机器翻译不同的是，对于像 MC 这样的任务，我们需要根据上下文段落同时合成问题和答案。此外，虽然问题是语法流畅的自然语言句子，但答案通常是段落中的显著语义概念，如命名实体、动作或数字，通常是一个单词或短语。由于答案与问题的语言结构非常不同，因此更合适地将其视为两种不同类型的数据。因此，需要合成(question, answer)元组。

在我们的方法中，我们将生成问题答案对的过程分解为两个步骤：基于段落的答案生成，以及基于段落和答案的问题生成。我们首先生成答案，因为答案通常是关键的语义概念，而问题可以被看作是为了询问这个概念而组成的完整句子。

通过提出SynNet，我们可以超越直接应用在另一个域上训练的高性能MC模型的强大基准线。例如，当我们在SQuAD（Rajpurkar等人，2016）上使用预训练模型来回答CNN / Daily Mail文章中的新闻QA数据集（Tirschler等人，2016）中的问题时，我们可以将单模型SQuAD基准线的性能从39.0％提高到44.3％的F1分数，并进一步通过集成将结果提高到46.6％的F1分数，接近先前发表的工作的结果（Tirschler等人，2016）（50.0％的F1分数），无需在新域中使用标记数据。此外，错误分析表明，我们在所有常见问题类型上的准确性都高于基准线。

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work

<a id="2.1问题回答"></a>
### 2.1 问题回答 Question Answering

问答是自然语言处理中的一个活跃领域，有许多方向的研究正在进行中（Berant 等人，2013；Hill 等人，2015；Golub 和 He，2016；Chen 等人，2016；Hermann 等人，2015）。机器理解，一种提取式问答的形式，在其中答案是一段文本内的片段或多个片段，最近在社区中引起了广泛关注。大规模人类注释数据集的出现，例如超过 100,000 对现实问答对的数据集SQuAD（Rajpurkar 等人，2016），NewsQA（Trischler 等人，2016）和MSMARCO（Nguyen 等人，2016），导致了许多成功的深度学习模型（Lee 等人，2016；Seo 等人，2016；Xiong 等人，2016；Dhingra 等人，2016；Wang 和 Jiang，2016）。

<a id="2.2半监督学习"></a>
### 2.2 半监督学习 Semi-Supervised Learning

半监督学习有着悠久的历史（Chapelle等人，2009年提供了概述），并被应用于自然语言处理中的许多任务，如依存句法分析（Koo 等人，2008 年）、情感分析（Yang 等人，2015 年）、机器翻译（Sennrich 等人，2016 年）以及语义分析（Berant 和 Liang；Wang 等人；Jia 和 Liang，2016 年）。最近的工作在无标记数据上生成合成注释以提高阅读理解模型和视觉问答模型的性能（Yang 等人，2017 年；Ren 等人，2015 年），但仅限于某些形式的已标记数据领域。也有工作致力于生成高质量的问题（Yuan 等人，2017 年；Serban 等人，2016 年；Labutov 等人），但没有关于如何最好地使用它们来训练模型的研究。相比之下，我们使用两阶段的 SynNet 生成数据元组，直接提升在没有任何注释的数据集上的模型性能。

<a id="2.3迁移学习"></a>
### 2.3 迁移学习 Transfer Learning

迁移学习（Pan 和 Yang，2010）已经成功地应用于机器学习的许多领域，如机器翻译（Zoph 等人，2016）、计算机视觉（Sharif Razavian 等人，2014）和语音识别（Doulaty 等人，2015）。具体来说，在大规模图像分类挑战赛（Russakovsky 等人，2015）上训练的对象识别模型被证明是各种任务（例如图像字幕生成（Lu 等人，2016；Fang 等人，2015；Karpathy 和 Fei-Fei，2015）和视觉问答（Zhou 等人，2015；Xu 和 Saenko，2016；Fukui 等人，2016；Yang 等人，2016）等）的出色特征提取器。类似地，我们使用在SQuAD数据集上预先训练的模型作为通用特征提取器来启动NewsQA上的QA系统。

<a id="3.机器理解的迁移学习任务TheTransferLearningTaskforMC"></a>
## 3 机器理解的迁移学习任务 The Transfer Learning Task for MC

我们用下面的公式形式化机器理解的任务。我们的MC模型输入一个标记化的问句  $`q = \left \{ q_0,q_1,...,q_n \right \}`$, 一段上下文段落 $`p = \left \{ p_0,p_1,...,p_n \right \} `$, 其中$`q_i`$和$`p_i`$分别是单词，学习函数$`f(p,q) -> \left \{ a_{start},a_{end} \right \}`$ ，其中$`a_{start}`$和$`a_{end}`$是段落p中的指针索引，即答案$`a = p_{a_{start}},..p_{a_{end}}`$

给定一个带标签的段落、问题、答案三元组 $`\left \{ p,q,a \right \}^n_{i=1}`$ 从特定领域 $`s`$，即维基百科文章，我们可以学习一个MC模型$`f_s{p,q}`$，该模型能够回答该领域的所有问题。

然而，当应用在一个域中训练的模型来回答另一个域中的问题时，性能可能会下降。另一方面，在新的领域中训练模型需要对数据进行标记，这很昂贵并且耗时。

在本文中，我们提出了一项任务，即在源域训练的多文档系统$`f_s{p,q}`$转移到另一个目标域t以回答问题。在目标领域t中，我们给出一个未标记的数据集$`p_t = \left \{ p \right \}^k_{i=1}`$，其中包含k个段落。在测试时间，我们将收到目标领域的未看到的段落集合$`p^*`$，希望在这些段落上回答问题。

<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion

<a id="6.实验结果ExperimentalResults"></a>
## 6.实验结果 Experimental Results

我们在新闻问答测试集上报告主要结果（表2），在SQuAD上报告简要结果（表3），进行消融研究（表4）并进行错误分析

<a id="6.1结果"></a>
### 6.1 结果 Results

我们比较了之前发表的最佳工作，该工作训练了BARB（Tirschler等人，2016年）和Match-LSTM（Wang和Jiang，2016年）架构以及我们在NewsQA上训练的BIDAF模型。直接在NewsQA上应用在SQuAD上训练的BIDAF模型会导致性能不佳，F1度量值为39.0％，比在标注的NewsQA数据上训练的模型低13.2％。使用两阶段SynNet已经可以略微提高性能（F1度量值为40.9％），这表明通过问题-答案对向模型提供新领域的信号对于训练很重要。使用检查点平均化，我们可以看到额外提高了3.4％（F1度量值为44.3％）。当我们融合了一个在SynNet上的BIDAF模型，其表现更好。

我们还评估了SynNet在NewsQA-to-SQuAD方向上。 我们直接从另一个方向应用最佳设置，并在表3中报告结果。 SynNet比基线模型在EM上提高了1.6%，F1提高了0.7%。 由于篇幅有限，我们在这一方向上省略了消融研究。

<a id="6.3.1答案合成"></a>
### 6.3.1 答案合成 Answer Synthesis

我们随机抽样并呈现一个段落，其中包含由我们的答案合成模块提取的答案（表5和6）。尽管该模块的精度似乎很高，例如它会挑选出“大西洋超自然协会”这样的实体，但它会错过明显如“大卫·施莱德”的实体，这表明使用带有完整命名实体标记的系统进行训练会产生更好的结果，并且这也解释了为什么通过SynNet生成的数据增强与这些标签相结合会导致性能提高。

<a id="6.3.2问题合成"></a>
### 6.3.2 问题合成 Question Synthesis

我们随机抽样了我们的模块生成的合成问题，并在表6中展示了结果。由于复制机制，我们的模型倾向于直接使用段落中的许多单词，尤其是常见的实体，例如示例中的“俄克拉荷马”。因此，一种生成更高质量问题的方法可能是引入一个在解码过程中促进多样性的损失函数，特别是在单个段落内。反过来，这会使 RC 模型接触到新领域中更多样的训练样本，从而提高性能。

<a id="6.3.3机器理解模型"></a>
### 6.3.3 机器理解模型 Machine Comprehension Model

我们研究了 FineTune 的 BIDAF 在 NewsQA 上的性能，与在 NewsQA 上训练的模型相比，在 SQuAD 上训练的模型（图 2）。通过 SynNet 进行微调，可以提高所有问题类型的性能，对于位置和人物识别问题的性能提升最大。类似地，对合成问题进行训练的模型在数值和人物识别问题上接近领域内性能，但仍然难以处理需要高阶推理的问题，即以“what was”或“what did”开头的问题。设计一个明确要求这种推理的问题生成器可能是进一步缩小性能差距的一种方法。

<a id="7.结论Conclusion"></a>
## 7.结论 Conclusion

我们介绍了一种用于迁移学习的两阶段SynNet，该任务既具有挑战性又具有实际重要性。通过我们的网络和一种简单的训练算法，我们能够在没有注释数据的情况下从一个域到另一个域泛化MC模型。我们在NewsQA测试集上展示了强大的结果，单个模型比基线BIDAF模型提高了5.3％，集成模型提高了7.6％F1。通过消融研究和错误分析，我们提供了对SynNet和MC模型方法的见解，可以帮助指导此任务的进一步研究。






