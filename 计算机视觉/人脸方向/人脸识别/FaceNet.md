# FaceNet: A Unified Embedding for Face Recognition and Clustering

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：   https://arxiv.org/pdf/1503.03832  

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
尽管在面部识别领域取得了显著的近期进展（[10，14，15，17]），但大规模实施有效的面部验证和识别仍对当前方法构成严重挑战。本文提出了一种系统，称为FaceNet，该系统直接学习从面部图像到紧凑的欧几里得空间(直角坐标系是2维欧几里得空间)的映射，在此空间中距离直接对应于面部相似度的一种度量。一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值距离两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

我们的方法使用一个深度卷积网络直接去优化embedding，而不是像以前的深度学习方法那样使用中间瓶颈层。为了训练，我们使用了一个新颖的在线三元组挖掘方法生成的粗略对齐匹配/非匹配人脸块的三元组。我们的方法的优势在于更高的表示效率：我们仅用每张脸128字节就达到了最先进的面部识别性能。 

在广泛使用的Labeled Faces in the Wild (LFW) 数据集上，我们的系统达到了新的记录精度为99.63%，在YouTube Faces DB中达到95.12%。与最佳结果相比，在两个数据集上，我们的系统将错误率降低了30%。 

我们还引入了和谐嵌入的概念，以及和谐三元组损失函数，这些描述了由不同网络生成的、可以互相兼容并直接比较的不同版本的人脸嵌入。
     
<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
本文提出了一种统一的系统，用于面部验证（这是同一个人吗），识别（这个人是谁）和聚类（在这些面孔中找到共同的人）。我们的方法基于使用深度卷积网络学习每个图像的欧几里得embedding。该网络被训练成embedding在特征空间中的平方L2距离直接对应于人脸相似性：同一个人的面部特征距离小，不同人的面部特征距离大。 

一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值来比较两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

以往基于深度网络的人脸识别方法使用分类层[15, 17]，该分类层是在一组已知人脸身份上训练的，然后利用中间的bottleneck层作为表示，以在训练中使用的身份集合之外进行泛化识别。这种方法的缺点在于其间接性和低效性：必须依赖bottleneck表示能很好地泛化到新的人脸；而且通过使用bottleneck层，每个脸部的表示通常非常大（上千维）。一些近期的工作[15]通过使用主成分分析（PCA）减少了这种维度，但这仍然是一个线性变换，能够很容易在网络的一层中学习到。

与这些方法不同，FaceNet直接使用基于LMNN的三元组损失函数训练其输出为紧凑的128维嵌入。我们的三元组由两个匹配的脸部缩略图和一个非匹配的脸部缩略图组成，并且损失旨在通过距离阈值将正对齐从负对齐中分离出来。缩略图是脸部区域的紧缩裁剪，除了缩放和平移之外，没有进行任何二维或三维对齐。 

选择哪些三元组来使用对于实现良好的性能至关重要，我们受到课程学习的启发[1]，提出了一种新颖的在线负示例挖掘策略，该策略能够确保随着网络的不断训练，三元组的学习难度也在不断增加。为了提高聚类精度，我们也探索了困难正样本挖掘技术，鼓励单个人的embedding形成球形簇。 

作为我们方法可以处理的难以置信的变异性的一个例子，请看图1。显示的是来自PIE [13] 的图像对，这些图像对以前被认为是面部验证系统非常困难的。 

![image](https://github.com/user-attachments/assets/5b01b64b-8814-4930-b015-b8e193ad7588)
(图 1. 照明和姿态的不变性。姿态和照明一直是人脸识别中的一个长期难题。该图展示了在不同姿态和照明条件下，FaceNet 对同一人和不同人之间的面孔对的距离输出。距离为 0.0 表示面孔完全相同，距离为 4.0 则表示完全不同的身份。可以看出，阈值为 1.1 时，所有的面孔对都被正确分类。)

本文的其余部分概述如下：在第2节中，我们回顾了该领域的文献；第3.1节定义了三元组损失，并且第3.2节描述了我们的新型三元组选择和训练程序；在第3.3节中，我们描述了所使用的模型架构。最后，在第4和5节中，我们介绍了我们嵌入的一些定量结果，并且还定性地探索了一些聚类结果。 

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work
与最近其他使用深度网络的工作类似（[15，17]），我们的方法是一种纯粹的数据驱动的方法，它直接从面部的像素中学习其表示。我们不使用工程特征，而是使用大量标记的脸部数据集来获得适当的姿势、照明和其他变分条件不变性。在本文中，我们探索了两种不同的深层网络架构。 

近年来在计算机视觉领域取得了巨大成功的架构有两种。两者都是深度卷积网络。第一种架构基于 Zeiler 和 Fergus 的模型，该模型由多个交错的卷积层、非线性激活层、局部响应归一化层和最大池化层组成。我们还添加了几层 1×1×d 的卷积层，这些层受到了一些工作的启发。第二种架构基于 Szegedy 等人的 Inception 模型，该模型最近被用作 ImageNet 2014 的获胜方法。这些网络使用混合层，这些层并行运行几种不同的卷积和池化层，并将它们的响应连接在一起。我们发现，这些模型可以将参数数量减少多达 20 倍，并且有潜力减少所需的浮点运算量，从而在性能相当的情况下提高效率。

有大量的面部验证和识别工作。审查这些超出了本文的范围，因此我们只简要讨论最近最相关的研究工作。 

[15，17，23]的这些作品都使用了一个复杂的多阶段系统，该系统将深度卷积网络的输出与PCA用于降维和SVM用于分类相结合。 

Zhenyao等人[23]使用深度网络将人脸“扭曲”成标准的正面视图，然后学习CNN来分类每个脸属于已知身份。对于人脸识别，使用PCA和SVM的集成对网络输出进行处理。 

Taigman等人[17]提出了一种多阶段方法，将面部对齐到通用的三维形状模型。一个具有多个类别的网络被训练以在超过四千个身份上执行人脸识别任务。作者还实验了所谓的Siamese网络，在该网络中他们直接优化两个面部特征之间的L1距离。他们的最佳性能（97.35%）来自使用不同对齐和颜色通道的三个网络的组合。这些网络预测的距离（基于χ2核的非线性SVM预测）通过非线性SVM进行组合。 

Sun等人[14，15]提出了一种紧凑的网络，因此相对便宜。他们使用了由25个这样的网络组成的集合，每个网络都操作在不同的面部块上。对于他们的最终性能（在LFW上的99.47％[15]），作者将50个响应（常规和翻转）组合在一起。PCA和一个有效的线性变换对应于嵌入空间中的联合贝叶斯模型[2]被采用。该方法不需要明确的二维/三维对齐。通过结合分类和验证损失来训练这些网络。验证损失类似于我们所使用的损失[12，19]，它最小化具有相同身份的脸之间的L2距离，并且强制执行不同身份的脸之间的距离差。主要区别在于仅比较图像对，而三元组损失鼓励相对距离约束。 

与本文中使用的损失函数相似，王等人[18]在对图像进行语义和视觉相似性排序时进行了探索。 

<a id="3.方法Method"></a>
## 3.方法 Method
FaceNet使用深度卷积网络。我们讨论两种不同的核心架构：Zeiler & Fergus [22]风格的网络和最近的Inception [16]类型网络。这些网络的细节在第3节中描述。 

根据模型细节，将其视为一个黑盒子（见图2），我们方法最重要的部分在于整个系统的端到端学习。为此，我们使用直接反映我们在面部验证、识别和聚类中想要实现的目标的三元损失函数。即，我们力求将图像x映射到特征空间 R<sup>d</sup> 中的嵌入f(x)，使得同一身份的所有人脸之间的平方距离很小，而不同身份的人脸图像对之间的平方距离很大。 

![image](https://github.com/user-attachments/assets/b5cba048-3d54-418f-8f10-4db3807a7aa7)
(图2。模型结构。我们的网络由一个批次输入层和随后的L2归一化组成的深层CNN组成，这形成了面部embedding。在训练期间，这被三元损失所监督。 )



<a id="3.1"></a>
### 3.1


<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion










