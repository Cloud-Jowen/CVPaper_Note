# FaceNet: A Unified Embedding for Face Recognition and Clustering

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：   https://arxiv.org/pdf/1503.03832  

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
尽管在面部识别领域取得了显著的近期进展（[10，14，15，17]），但大规模实施有效的面部验证和识别仍对当前方法构成严重挑战。本文提出了一种系统，称为FaceNet，该系统直接学习从面部图像到紧凑的欧几里得空间(直角坐标系是2维欧几里得空间)的映射，在此空间中距离直接对应于面部相似度的一种度量。一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值距离两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

我们的方法使用一个深度卷积网络直接去优化embedding，而不是像以前的深度学习方法那样使用中间瓶颈层。为了训练，我们使用了一个新颖的在线三元组挖掘方法生成的粗略对齐匹配/非匹配人脸块的三元组。我们的方法的优势在于更高的表示效率：我们仅用每张脸128字节就达到了最先进的面部识别性能。 

在广泛使用的Labeled Faces in the Wild (LFW) 数据集上，我们的系统达到了新的记录精度为99.63%，在YouTube Faces DB中达到95.12%。与最佳结果相比，在两个数据集上，我们的系统将错误率降低了30%。 

我们还引入了和谐嵌入的概念，以及和谐三元组损失函数，这些描述了由不同网络生成的、可以互相兼容并直接比较的不同版本的人脸嵌入。
     
<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
本文提出了一种统一的系统，用于面部验证（这是同一个人吗），识别（这个人是谁）和聚类（在这些面孔中找到共同的人）。我们的方法基于使用深度卷积网络学习每个图像的欧几里得embedding。该网络被训练成embedding在特征空间中的平方L2距离直接对应于人脸相似性：同一个人的面部特征距离小，不同人的面部特征距离大。 

一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值来比较两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

以往基于深度网络的人脸识别方法使用分类层[15, 17]，该分类层是在一组已知人脸身份上训练的，然后利用中间的bottleneck层作为表示，以在训练中使用的身份集合之外进行泛化识别。这种方法的缺点在于其间接性和低效性：必须依赖bottleneck表示能很好地泛化到新的人脸；而且通过使用bottleneck层，每个脸部的表示通常非常大（上千维）。一些近期的工作[15]通过使用主成分分析（PCA）减少了这种维度，但这仍然是一个线性变换，能够很容易在网络的一层中学习到。

与这些方法不同，FaceNet直接使用基于LMNN的三元组损失函数训练其输出为紧凑的128维嵌入。我们的三元组由两个匹配的脸部缩略图和一个非匹配的脸部缩略图组成，并且损失旨在通过距离阈值将正对齐从负对齐中分离出来。缩略图是脸部区域的紧缩裁剪，除了缩放和平移之外，没有进行任何二维或三维对齐。 

选择哪些三元组来使用对于实现良好的性能至关重要，我们受到课程学习的启发[1]，提出了一种新颖的在线负示例挖掘策略，该策略能够确保随着网络的不断训练，三元组的学习难度也在不断增加。为了提高聚类精度，我们也探索了困难正样本挖掘技术，鼓励单个人的embedding形成球形簇。 

作为我们方法可以处理的难以置信的变异性的一个例子，请看图1。显示的是来自PIE [13] 的图像对，这些图像对以前被认为是面部验证系统非常困难的。 

![image](https://github.com/user-attachments/assets/5b01b64b-8814-4930-b015-b8e193ad7588)  
(图 1. 照明和姿态的不变性。姿态和照明一直是人脸识别中的一个长期难题。该图展示了在不同姿态和照明条件下，FaceNet 对同一人和不同人之间的面孔对的距离输出。距离为 0.0 表示面孔完全相同，距离为 4.0 则表示完全不同的身份。可以看出，阈值为 1.1 时，所有的面孔对都被正确分类。)

本文的其余部分概述如下：在第2节中，我们回顾了该领域的文献；第3.1节定义了三元组损失，并且第3.2节描述了我们的新型三元组选择和训练程序；在第3.3节中，我们描述了所使用的模型架构。最后，在第4和5节中，我们介绍了我们嵌入的一些定量结果，并且还定性地探索了一些聚类结果。 

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work
与最近其他使用深度网络的工作类似（[15，17]），我们的方法是一种纯粹的数据驱动的方法，它直接从面部的像素中学习其表示。我们不使用工程特征，而是使用大量标记的脸部数据集来获得适当的姿势、照明和其他变分条件不变性。在本文中，我们探索了两种不同的深层网络架构。 

近年来在计算机视觉领域取得了巨大成功的架构有两种。两者都是深度卷积网络。第一种架构基于 Zeiler 和 Fergus 的模型，该模型由多个交错的卷积层、非线性激活层、局部响应归一化层和最大池化层组成。我们还添加了几层 1×1×d 的卷积层，这些层受到了一些工作的启发。第二种架构基于 Szegedy 等人的 Inception 模型，该模型最近被用作 ImageNet 2014 的获胜方法。这些网络使用混合层，这些层并行运行几种不同的卷积和池化层，并将它们的响应连接在一起。我们发现，这些模型可以将参数数量减少多达 20 倍，并且有潜力减少所需的浮点运算量，从而在性能相当的情况下提高效率。

有大量的面部验证和识别工作。审查这些超出了本文的范围，因此我们只简要讨论最近最相关的研究工作。 

[15，17，23]的这些作品都使用了一个复杂的多阶段系统，该系统将深度卷积网络的输出与PCA用于降维和SVM用于分类相结合。 

Zhenyao等人[23]使用深度网络将人脸“扭曲”成标准的正面视图，然后学习CNN来分类每个脸属于已知身份。对于人脸识别，使用PCA和SVM的集成对网络输出进行处理。 

Taigman等人[17]提出了一种多阶段方法，将面部对齐到通用的三维形状模型。一个具有多个类别的网络被训练以在超过四千个身份上执行人脸识别任务。作者还实验了所谓的Siamese网络，在该网络中他们直接优化两个面部特征之间的L1距离。他们的最佳性能（97.35%）来自使用不同对齐和颜色通道的三个网络的组合。这些网络预测的距离（基于χ2核的非线性SVM预测）通过非线性SVM进行组合。 

Sun等人[14，15]提出了一种紧凑的网络，因此相对便宜。他们使用了由25个这样的网络组成的集合，每个网络都操作在不同的面部块上。对于他们的最终性能（在LFW上的99.47％[15]），作者将50个响应（常规和翻转）组合在一起。PCA和一个有效的线性变换对应于嵌入空间中的联合贝叶斯模型[2]被采用。该方法不需要明确的二维/三维对齐。通过结合分类和验证损失来训练这些网络。验证损失类似于我们所使用的损失[12，19]，它最小化具有相同身份的脸之间的L2距离，并且强制执行不同身份的脸之间的距离差。主要区别在于仅比较图像对，而三元组损失鼓励相对距离约束。 

与本文中使用的损失函数相似，王等人[18]在对图像进行语义和视觉相似性排序时进行了探索。 

<a id="3.方法Method"></a>
## 3.方法 Method
FaceNet使用深度卷积网络。我们讨论两种不同的核心架构：Zeiler & Fergus [22]风格的网络和最近的Inception [16]类型网络。这些网络的细节在第3节中描述。  

根据模型细节，将其视为一个黑盒子（见图2），我们方法最重要的部分在于整个系统的端到端学习。为此，我们使用直接反映我们在面部验证、识别和聚类中想要实现的目标的三元损失函数。即，我们力求将图像x映射到特征空间 R<sup>d</sup> 中的嵌入f(x)，使得同一身份的所有人脸之间的平方距离很小，而不同身份的人脸图像对之间的平方距离很大。 

![image](https://github.com/user-attachments/assets/b5cba048-3d54-418f-8f10-4db3807a7aa7)  
(图2。模型结构。我们的网络由一个批次输入层和随后的L2归一化(L2归一化是满足一个球面)组成的深层CNN组成，这形成了面部embedding。在训练期间被triplet loss监督。 )

虽然我们没有直接与其他损失进行比较，例如使用正负对的损失，如在 [14] 中方程 (2) 所用的那样，但我们相信三元组损失更适合于人脸验证。动机是来自 [14] 的损失鼓励一个身份的所有面孔投影到特征空间中的单个点上。然而，三元组损失试图强制关注每个面孔之间的距离，从而强制关注所有其他面孔之间的距离。这允许每个人的面部embedding分布在同一个曲面上，并保证与其它人的面部embedding的距离和可区分性。 

以下部分描述了该三元损失的结构及其三元损失如何在大规模下高效学习。 
<a id="3.1TripletLoss"></a>
### 3.1 Triplet Loss
embedding 由 $`f(x) \in \mathbb{R}^d `$ 表示。它将图像 x 映射到一个 d维 的欧几里得空间中。此外，我们还限制了该embedding必须存在于该d维超球面上，即 $`\left \| f(x) \right \|_2 = 1`$。这个损失函数在[19]中得到了激发，其背景是在最近邻分类的上下文中。我们希望确保特定人脸图像 $`x_i^a`$（anchor）与同一个人的不同人脸图像 $`x_i^p`$（positive）更加接近，离其他人的人脸图像 $`x_i^n`$（negative) 更远。图3给出了可视化结果。 

![image](https://github.com/user-attachments/assets/c8e7114b-c089-4e50-8205-7a9f4dc4ed9e)  
(图3。三元损失最小化具有相同身份的锚和正样本之间的距离，并最大化具有不同身份的负样本与锚之间的距离。 )

我们希望得到的结果是：
```math
\left \| f(x_i^a) - f(x_i^p) \right \|_2^2 + \alpha < \left \| f(x_i^a) - f(x_i^n) \right \|_2^2  \forall( f(x_i^a), f(x_i^p), f(x_i^n)) \in \tau (1)
```
被最小化的损失是L=
```math
\sum_{i}^{N} \left [ \left \| f(x_i^a) - f(x_i^p) \right \|_2^2 - \left \| f(x_i^a) - f(x_i^n) \right \|_2^2 + \alpha \right ]  (2)
```
其中，α 是正负样本对之间的强制间隔 margin 。$`\tau `$ 是训练集中所有可能三元组的集合，并且其大小为 N 。

生成所有可能的三元组会导致许多容易满足的三元组（即满足方程（1）中的约束）。这些三元组不会对训练做出贡献，但它们仍然会被送入网络进行学习。选择困难的三元组至关重要，这些三元组是活跃的，并且可以改善模型。下面的部分将讨论我们用于三元组选择的不同方法。 
<a id="3.2TripletSelection"></a>
### 3.2 Triplet Selection
为了确保快速收敛，选择违反方程（1）中三元组约束的三元组至关重要。这意味着，在给定 anchor 图像 $`x_i^a`$ 的情况下，我们希望选择一个$`x_i^p`$（硬正例），使得$`argmax_{x_i^p}\left \| f(x_i^a) - f(x_i^p)  \right \| _2^2`$，并且类似地选择$`x_i^n`$ (硬负例），使得$`argmin_{x_i^p}\left \| f(x_i^a) - f(x_i^n)  \right \| _2^2`$
在整个训练集中计算argmin和argmax是不可行的。此外，这可能会导致不良的训练，因为误标记和图像质量差的脸会主导困难的正负样本。有两个明显的解决方案可以避免这个问题：

• 在每n步生成三元组，使用最新的网络检查点，并在数据的子集上计算argmin和argmax。   
• 在线生成三元组。这可以通过从 mini-batch 中选择困难的正/负示例来完成。 

 在这里，我们关注在线生成，并使用数千个示例的大型 mini-batch。仅在 mini-batch 内计算 argmin 和 argmax 。 

为了获得有意义的 anchor-positive 距离表示，需要确保每个 mini-batch 中包含每个人的最小样本数。在我们的实验中，我们从训练数据中采样，使得每个 mini-batch 中大约选取 40 张不同人的脸。此外，还会向每个 mini-batch 中添加随机采样的负样本。

我们没有选择最困难的正样本，而是使用 mini-batch 中的所有 anchor-positive 对，并且仍然选择最难的负样本。我们没有在 mini-batch 中比较硬锚定-正样本对和所有锚定-正样本对之间的侧边对比，但我们发现实践中，全部锚定-正样本方法更加稳定，在训练初期收敛速度稍快一些。 

我们没有选择最困难的正样本，而是使用 mini-batch 中的所有 anchor-positive 对，并且仍然选择最难的负样本。我们没有在mini-batch 中比较 hard anchor-positive 对和所有 anchor-positive 对之间的 margin 对比，但在实践中我们发现，全部 anchor-positive 方法更加稳定，在训练初期收敛速度稍快一些。 

我们还探讨了离线生成三元组与在线生成三元组的结合使用，这可能允许使用更小的 batch size，但实验结果并不能证明这一结论。

选择最困难的负样本可能让模型收敛到一个不好的局部最小值，特别是它可能会导致模型崩溃（即f (x) = 0）。为了缓解这种情况，我们需要选择以下的负样本 $`x_i^n`$ 
```math
\left \| f(x_i^a) - f(x_i^p)  \right \| _2^2 < \left \| f(x_i^a) - f(x_i^n)  \right \| _2^2 (4)
```
我们称这些负例为半硬的，因为它们比正例更远离锚点，但仍然很困难，因为平方距离接近锚点和正例之间的距离。那些负例位于阈值α之内。 (也就是离的没那么远的负样本，没有超过正负样本的分界线)

正如前面提到的，正确三元组选择对于快速收敛至关重要。一方面我们希望使用小mini-batch，因为这些在Stochastic Gradient Descent (SGD) [20]中倾向于改善收敛性。另一方面，实验细节展示包含数十到数百个示例的小批量更有效率。然而，与批处理大小相关的最主要限制是我们在mini-batch内部选择困难相关三元组的方式。大多数实验中使用的批处理大小约为1,800个示例。 

<a id="3.3DeepConvolutionalNetworks"></a>
### 3.3 Deep Convolutional Networks
 在所有实验中，我们使用标准反向传播（BP）和随机梯度下降（SGD）训练CNN。在大多数实验中，我们从学习率0.05开始，然后降低到最终模型。模型从随机初始化，类似于[16]，并在CPU集群上进行1,000至2,000小时的训练。在训练了500小时后，损失减少（准确度增加）的速度急剧减慢，但额外的训练仍能显著提高性能。α设置为0.2。 

我们使用了两种类型的架构，并在实验部分更详细地探讨了它们的权衡。它们在实际应用中的主要区别在于参数数量和浮点运算量（FLOPS）。最佳模型可能会因应用的不同而有所不同。例如，运行在数据中心的模型可以有很多参数并且需要大量的 FLOPS，而运行在手机上的模型则需要参数较少，以便能够适应内存限制。我们所有的模型都使用了修正线性单元（ReLU）作为非线性激活函数。

第一类，如表1所示，在Zeiler & Fergus [22]架构的标准卷积层之间添加了1×1×d卷积层，如[9]中所述，并导致一个深度为22的模型。它总共包含1.4亿个参数，并且每张图像需要大约16亿次浮点运算。 

![image](https://github.com/user-attachments/assets/5134d425-db6c-4587-bd28-47add5b06765)
(表1。NN1。该表显示了我们基于Zeiler & Fergus [22]的模型结构，其灵感来自[9]中的1×1卷积。输入和输出大小描述为rows × cols × #filters 。核规格为 rows × cols，stride 以及最大池化[6]的大小为p = 2。 )

我们使用的第二类模型基于GoogLeNet风格的Inception模型[16]。这些模型参数数量减少了20倍（约为660万到750万），并且计算量减少了最多5倍（在5亿到16亿之间）。其中一些模型在尺寸（包括深度和滤波器数量）上大幅减少，从而可以在手机上运行。例如，模型NNS1有2600万参数，每张图片仅需220M FLOPS；而另一个模型NNS2有430万参数，仅需20M FLOPS。表2详细描述了我们的最大网络NN2。NN3在架构上与NN2相同，但输入大小减少到160x160。NN4的输入大小仅为96x96，从而大幅降低了CPU需求（NN2的285M FLOPS与1.6B FLOPS相比）。除了减少输入大小外，它还在较高层不使用5x5卷积，因为到那个时候感受野已经足够小了。通常我们发现，5x5卷积可以在整个网络中去除，只会导致微小的准确性下降。图4对比了我们所有的模型。

![image](https://github.com/user-attachments/assets/ec264392-7711-42c2-b569-a1cd80792520)
(图4。FLOPS与精度的权衡。显示了在不同模型大小和架构范围内，FLOPS和精度之间的权衡。我们实验中重点关注的四个模型被突出显示。 )
 
<a id="4.实验Experiments"></a>
## 4.实验 Experiments
我们在四个数据集上评估我们的方法，除了Labelled Faces in the Wild和YouTube Faces外，我们还对人脸验证任务进行了评估。即，给定一对人脸图像，使用平方L2距离阈值 $`D(x_i,x_j)`$ 来确定相同和不同的分类。所有同一身份的面部对$`(i,j)`$表示为 $`P_{same}`$，而不同身份的所有对表示为 $`P_{diff}`$。

我们定义所有真接受的集合为：
```math
TA(d) = \left \{ (i,j)\in P_{same},with D(x_i,x_j)\le d \right \}
```

这些是正确分类为相同的阈值d的面部对（i，j）。同样 
```math
FA(d) = \left \{ (i,j)\in P_{diff},with D(x_i,x_j)\le d \right \}
```
是所有被错误分类为相同的对（假接受）。 

对于给定的面部距离 d，验证率 VAL(d) 和错误接受率 FAR(d) 定义为
```math
VAL(d) = \frac{\left | TA(d) \right | }{\left | P_{same} \right | },FAR(d) = \frac{\left | FA(d) \right | }{\left | P_{diff} \right | }
```

<a id="4.1保留集Hold-outTestSet"></a>
### 4.1 保留集 Hold-out Test Set
我们保留了一组约一百万张图像的保留集，其分布与我们的训练集相同，但身份不同。为了评估，我们将其分为五个不相交的身份为200K图像的集合。然后在100K×100K图像对上计算FAR和VAL率。标准误差报告了这五次划分的结果。 

<a id="4.2个人照片PersonalPhotos"></a>
### 4.2 个人照片 Personal Photos
这是一个与我们的训练集分布相似的测试集，但已手动验证其标签非常干净。它由三个个人照片集合组成，总共约有12000张图片。我们计算了所有12000平方对图像的FAR和VAL率。 

<a id="4.3学术数据集AcademicDatasets"></a>
### 4.3 学术数据集 Academic Datasets
Labeled Faces in the Wild (LFW)是面部识别的默认学术测试集。我们遵循不受限制、标记外部数据的标准协议，并报告平均分类准确率以及标准误差。 

Youtube Faces DB [21] 是一个在人脸识别社区中流行的新数据集。设置类似于LFW，但不是验证图像对，而是使用视频对。

<a id="5.实验Experiments"></a>
## 5.实验 Experiments
如果没有特别说明，我们使用约有8百万不同身份的训练人脸缩略图。在每张图像上运行一个面部检测器，并生成每个面部的紧邻边界框。这些人脸缩略图被调整为相应网络的输入大小。我们的实验中输入尺寸范围从96×96像素到224×224像素不等。 

<a id="5.1计算精度权衡ComputationAccuracyTrade-off"></a>
### 5.1 计算精度权衡 Computation Accuracy Trade-off
在深入探讨更具体的实验细节之前，我们将讨论特定模型所需的准确性和FLOPS之间的权衡。图4显示了x轴上的FLOPS和我们在第4节中从用户标记测试数据集获得的在0.001错误接受率（FAR）下的准确性。有趣的是可以看到模型需要计算与它实现的准确性之间存在很强的相关性。该图突出了我们将在我们的实验中详细讨论的五个模型（NN1、NN2、NN3、NNS1、NNS2）。 

我们还研究了模型参数数量与准确性的权衡。然而，在这种情况下，情况并不那么清晰。例如，基于Inception的NN2模型在性能上与NN1相当，但只有后者的十分之一的参数。FLOPS的数量是可比的。显然，如果进一步减少参数数量，性能会有所下降。其他模型架构可能允许进一步降低而不会损失准确性，就像在这种情况下Inception[16]所做的那样。 

<a id="5.2CNN模型的影响EffectofCNNModel"></a>
### 5.2 CNN模型的影响 Effect of CNN Model
现在我们对所选的四个模型进行更详细的性能分析。一方面，我们有传统的Zeiler & Fergus 基础架构，其中包含1 × 1卷积（见表1）。另一方面，我们有Inception 基础架构，其显著地减少了模型大小。总体而言，在最终性能中，两种基础架构的顶级模型表现相当。然而，我们的某些基于Inception 的模型，例如NN3，仍然在显著减少FLOPS 和模型大小的同时实现了良好的性能。 

我们个人照片测试集的详细评估如图5所示。尽管最大的模型相比于小型的NNS2在准确性上有显著提升，但后者在手机上运行速度为每张图片30毫秒，且精度足够用于人脸聚类。在假阳性率（FAR）低于 (10^{-4}) 时ROC曲线的急剧下降表明测试数据的真实标签存在噪声。在极低的假阳性率下，单个错误标记的图像可能对曲线产生显著影响。

![image](https://github.com/user-attachments/assets/c796a5f4-f297-43b9-8104-7a9ca290af4b)  
(图5。网络架构。该图显示了我们在第4节中从个人照片测试集获得的四个不同模型的完整ROC曲线。在10E-4 FAR处出现的急剧下降可以由ground truth标签中的噪声来解释。按性能顺序排列的模型是：NN2：输入为224×224的基于Inception的模型；NN1：Zeiler&Fergus基于网络，具有1×1卷积；NNS1：仅包含220M FLOPS的小型Inception风格模型；NNS2：仅包含20M FLOPS的小型Inception模型。 )

<a id="5.3图像质量敏感性SensitivitytoImageQuality"></a>
### 5.3 图像质量敏感性 Sensitivity to Image Quality
表4显示了我们的模型在各种图像大小范围内的鲁棒性。网络对JPEG压缩非常稳健，并且在JPEG质量为20时表现非常好。对于脸型缩略图，性能下降很小，甚至在尺寸为80×80像素时也显示出可接受的性能。这值得注意，因为该网络是在输入图像大小为220×220像素的情况下训练的。使用低分辨率的脸部进行训练可以进一步提高这个范围。 

![image](https://github.com/user-attachments/assets/4c0e60cb-6f30-45be-9b79-5605796afb4f)  
(表4。图像质量。左边的表格显示了在不同JPEG质量下，精度为10E-3时验证率的影响。右边的表格显示了像素大小对精度为10E-3时验证率的影响。该实验是在我们测试保留数据集的第一分割中使用NN1进行的。 )

<a id="5.4embedding维度EmbeddingDimensionality"></a>
### 5.4 embedding维度 Embedding Dimensionality
我们探索了多种 embedding 维度，并选择了128作为所有实验的维度，除了表5中报告的对比实验。尽管一般期望较大的embedding维度能至少达到与较小维度相同的性能，但这些更大的 embedding 可能需要更多的训练才能达到相同的准确性。也就是说，表5中报告的性能差异在统计上并不显著。

应该注意的是，在训练过程中使用了一个128维的浮点向量，但可以将其量化为不损失精度的128字节。因此每个面部都由一个紧凑表示的128维字节向量来代表，这对于大规模聚类和识别来说是理想的。较小的 embedding 可能在精度上略有损失，并且可以在移动设备上使用。 

<a id="5.5训练数据量AmountofTrainingData"></a>
### 5.5 训练数据量 Amount of Training Data
 表6显示了大量训练数据的影响。由于时间限制，此评估在较小的模型上运行；在较大的模型上效果可能更大。很明显，在我们的个人照片测试集（第4.2节）中使用数百万个示例会导致准确率明显提高。与仅使用数百万张图像相比，相对错误减少率为60%。使用另一个数量级更多的图像（数十亿）仍然会带来一些提升，但改进趋于平缓。 

![image](https://github.com/user-attachments/assets/09a85c01-2389-4b48-8aca-03cc235cf78f)  
(表6。训练数据大小。该表比较了在输入为96×96像素的小型模型上经过700小时的训练后性能。模型架构类似于NN2，但没有Inception模块中的5×5卷积。 )

<a id="5.6LFW上的性能PerformanceonLFW"></a>
### 5.6 LFW上的性能 Performance on LFW
我们使用标准的不受限制、标记外部数据协议来评估我们的模型。在LFW上，我们使用了9个训练分割来选择L2距离阈值。然后对第10个测试分割进行分类（相同或不同）。除了第8个分割外，所有测试分割的最佳阈值为1.242 (1.256)。 

我们的模型在两种模式下进行评估： 
1. 固定中心裁剪的LFW提供的缩略图。  
2. 使用专有的面部检测器（类似于Picasa [3]）在提供的LFW缩略图上运行。如果它无法对齐脸部（这种情况发生在两张图片中），则使用LFW对齐。 

图6概述了所有失败案例。顶部展示了误接受情况，底部展示了误拒绝情况。使用(1)中描述的固定中心裁剪，我们的分类准确率为98.87%±0.15，而使用额外的面部对齐(2)时，记录破纪录的均值标准误为99.63%±0.09。这将[17]中DeepFace报告的错误率降低了超过7倍，并且比[15]中DeepId2+的前沿水平降低了30%。这是模型NN1的性能，即便是体积更小的NN3也达到了统计上没有显著差异的性能。

![image](https://github.com/user-attachments/assets/1fbd6398-cea9-40f6-ae0e-9d82a9278cb2)  
(图6。LFW错误。这显示了在LFW上被误分类的所有图像对。这里显示的13个假拒绝中只有8个是实际错误，其余5个是在LFW中被错误标记的。 )

<a id="5.7在Youtube Faces数据库上的性能PerformanceonYoutubeFacesDB"></a>
### 5.7 在Youtube Faces数据库上的性能 Performance on Youtube Faces DB
我们使用每个视频中我们的人脸检测器检测到的前一百帧的所有对的平均相似性。这给我们带来了95.12％±0.39的分类精度。使用第一个一千帧的结果为95.18％。与[17]每段视频评估一百帧相比，我们的方法将错误率降低了近一半。DeepId2+ [15]达到了93.2%，而我们的方法减少了这一误差的30%，与我们在LFW上的改进相当。 

<a id="5.8面部聚类FaceClustering"></a>
### 5.8 面部聚类 Face Clustering
我们的紧凑嵌入（compact embedding）非常适合用于将用户的个人照片按相同身份分组。与纯粹的验证任务相比，面部聚类所施加的分配约束产生了真正令人惊叹的结果。图7展示了一个用户个人照片集合中的一个簇，这个簇是通过聚合聚类生成的。它清晰地展示了在遮挡、光照、姿势甚至年龄变化下的惊人不变性。

<a id="6.总结Summary"></a>
## 6.总结 Summary
我们提供了一种直接学习欧几里得空间嵌入用于面部验证的方法。这与其他方法[15, 17]不同，后者使用CNN瓶颈层，或需要额外的后处理步骤，如多个模型的拼接、主成分分析（PCA）以及支持向量机（SVM）分类。我们的端到端训练方法不仅简化了设置，还表明直接优化与任务相关的损失函数可以提升性能。

我们的模型的另一个优势是它只需要最小的对齐（面部区域周围的紧密裁剪）[17]，例如，执行复杂的三维对齐。我们还尝试了相似变换对齐，并注意到这实际上可以稍微提高性能。尚不清楚是否值得额外复杂性。 

我们的模型的另一个优势是它只需要最小的对齐（面部区域周围的紧密裁剪）[17]，例如，执行复杂的三维对齐。我们还尝试了相似变换对齐，并注意到这实际上可以稍微提高性能。尚不清楚是否值得额外复杂性。 

未来的工作将重点放在更好地理解错误案例上，进一步改进模型，并且减少模型大小和CPU要求。我们还将研究如何改善目前极其漫长的训练时间，例如使用较小的批处理尺寸和离线以及在线正负样本挖掘的我们的课程学习变体。 

<a id="7.附录Appendix"></a>
## 7. 附录 Appendix: Harmonic Embedding
在本节中，我们介绍谐波嵌入的概念。通过这种方式，我们表示由不同模型v1和v2生成的嵌入集，但它们是兼容的，即可以相互比较。 

这种兼容性大大简化了升级路径。例如，在一个场景中，如果嵌入v1已经在大量图像上计算过，而现在要推出新的嵌入模型v2，这种兼容性可以确保平滑过渡，无需担心版本不兼容的问题。图8展示了我们在3G数据集上的结果。从中可以看出，改进后的模型NN2显著优于NN1，而将NN2的嵌入与NN1的嵌入进行比较时，性能处于中间水平。

<a id="7.1谐波三元损失HarmonicTripletLoss"></a>
## 7.1 谐波三元损失 Harmonic Triplet Loss
为了学习谐波嵌入，我们混合v1的嵌入与正在学习的v2的嵌入。这在三元组损失中进行，并且产生了额外的三元组，这些三元组鼓励不同版本的嵌入之间的兼容性。图9可视化了对三元组损失做出贡献的不同组合的三元组。 

我们从独立训练的NN2中初始化v2嵌入，并重新训练最后层（嵌入层）以随机初始化，使用兼容性鼓励三元组损失。首先只重新训练最后一层，然后继续用谐波损失训练整个v2网络。 

图10显示了这种兼容性可能在实践中如何工作的可能解释。大多数v2嵌入可能会被嵌入到与对应v1嵌入接近的位置，然而，错误放置的v1嵌入可以稍微扰动以使其新的位置在嵌入空间中提高验证精度。 

<a id="7.2总结Summary"></a>
## 7.2 总结 Summary
这些发现非常有趣，而且令人惊讶的是它工作得如此好。未来的工作可以探索这个想法能扩展到多远。显然，v2嵌入的改进程度有限，但仍与v1兼容。此外，训练可以在手机上运行的小型网络并兼容大型服务器端模型也会很有趣。 

