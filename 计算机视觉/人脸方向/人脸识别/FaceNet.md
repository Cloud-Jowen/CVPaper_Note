# FaceNet: A Unified Embedding for Face Recognition and Clustering

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：   https://arxiv.org/pdf/1503.03832  

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
尽管在面部识别领域取得了显著的近期进展（[10，14，15，17]），但大规模实施有效的面部验证和识别仍对当前方法构成严重挑战。本文提出了一种系统，称为FaceNet，该系统直接学习从面部图像到紧凑的欧几里得空间(直角坐标系是2维欧几里得空间)的映射，在此空间中距离直接对应于面部相似度的一种度量。一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值距离两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

我们的方法使用一个深度卷积网络直接去优化embedding，而不是像以前的深度学习方法那样使用中间瓶颈层。为了训练，我们使用了一个新颖的在线三元组挖掘方法生成的粗略对齐匹配/非匹配人脸块的三元组。我们的方法的优势在于更高的表示效率：我们仅用每张脸128字节就达到了最先进的面部识别性能。 

在广泛使用的Labeled Faces in the Wild (LFW) 数据集上，我们的系统达到了新的记录精度为99.63%，在YouTube Faces DB中达到95.12%。与最佳结果相比，在两个数据集上，我们的系统将错误率降低了30%。 

我们还引入了和谐嵌入的概念，以及和谐三元组损失函数，这些描述了由不同网络生成的、可以互相兼容并直接比较的不同版本的人脸嵌入。
     
<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
本文提出了一种统一的系统，用于面部验证（这是同一个人吗），识别（这个人是谁）和聚类（在这些面孔中找到共同的人）。我们的方法基于使用深度卷积网络学习每个图像的欧几里得embedding。该网络被训练成embedding在特征空间中的平方L2距离直接对应于人脸相似性：同一个人的面部特征距离小，不同人的面部特征距离大。 

一旦生成了embedding，那么上述任务就变得简单明了：人脸验证只是通过阈值来比较两个embedding之间的距离；识别成为k-NN分类问题；聚类可以使用诸如k均值或凝聚式聚类等现成的技术来实现。 

以往基于深度网络的人脸识别方法使用分类层[15, 17]，该分类层是在一组已知人脸身份上训练的，然后利用中间的bottleneck层作为表示，以在训练中使用的身份集合之外进行泛化识别。这种方法的缺点在于其间接性和低效性：必须依赖bottleneck表示能很好地泛化到新的人脸；而且通过使用bottleneck层，每个脸部的表示通常非常大（上千维）。一些近期的工作[15]通过使用主成分分析（PCA）减少了这种维度，但这仍然是一个线性变换，能够很容易在网络的一层中学习到。

与这些方法不同，FaceNet直接使用基于LMNN的三元组损失函数训练其输出为紧凑的128维嵌入。我们的三元组由两个匹配的脸部缩略图和一个非匹配的脸部缩略图组成，并且损失旨在通过距离阈值将正对齐从负对齐中分离出来。缩略图是脸部区域的紧缩裁剪，除了缩放和平移之外，没有进行任何二维或三维对齐。 

选择哪些三元组来使用对于实现良好的性能至关重要，我们受到课程学习的启发[1]，提出了一种新颖的在线负示例挖掘策略，该策略能够确保随着网络的不断训练，三元组的学习难度也在不断增加。为了提高聚类精度，我们也探索了困难正样本挖掘技术，鼓励单个人的embedding形成球形簇。 

作为我们方法可以处理的难以置信的变异性的一个例子，请看图1。显示的是来自PIE [13] 的图像对，这些图像对以前被认为是面部验证系统非常困难的。 

![image](https://github.com/user-attachments/assets/5b01b64b-8814-4930-b015-b8e193ad7588)  
(图 1. 照明和姿态的不变性。姿态和照明一直是人脸识别中的一个长期难题。该图展示了在不同姿态和照明条件下，FaceNet 对同一人和不同人之间的面孔对的距离输出。距离为 0.0 表示面孔完全相同，距离为 4.0 则表示完全不同的身份。可以看出，阈值为 1.1 时，所有的面孔对都被正确分类。)

本文的其余部分概述如下：在第2节中，我们回顾了该领域的文献；第3.1节定义了三元组损失，并且第3.2节描述了我们的新型三元组选择和训练程序；在第3.3节中，我们描述了所使用的模型架构。最后，在第4和5节中，我们介绍了我们嵌入的一些定量结果，并且还定性地探索了一些聚类结果。 

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work
与最近其他使用深度网络的工作类似（[15，17]），我们的方法是一种纯粹的数据驱动的方法，它直接从面部的像素中学习其表示。我们不使用工程特征，而是使用大量标记的脸部数据集来获得适当的姿势、照明和其他变分条件不变性。在本文中，我们探索了两种不同的深层网络架构。 

近年来在计算机视觉领域取得了巨大成功的架构有两种。两者都是深度卷积网络。第一种架构基于 Zeiler 和 Fergus 的模型，该模型由多个交错的卷积层、非线性激活层、局部响应归一化层和最大池化层组成。我们还添加了几层 1×1×d 的卷积层，这些层受到了一些工作的启发。第二种架构基于 Szegedy 等人的 Inception 模型，该模型最近被用作 ImageNet 2014 的获胜方法。这些网络使用混合层，这些层并行运行几种不同的卷积和池化层，并将它们的响应连接在一起。我们发现，这些模型可以将参数数量减少多达 20 倍，并且有潜力减少所需的浮点运算量，从而在性能相当的情况下提高效率。

有大量的面部验证和识别工作。审查这些超出了本文的范围，因此我们只简要讨论最近最相关的研究工作。 

[15，17，23]的这些作品都使用了一个复杂的多阶段系统，该系统将深度卷积网络的输出与PCA用于降维和SVM用于分类相结合。 

Zhenyao等人[23]使用深度网络将人脸“扭曲”成标准的正面视图，然后学习CNN来分类每个脸属于已知身份。对于人脸识别，使用PCA和SVM的集成对网络输出进行处理。 

Taigman等人[17]提出了一种多阶段方法，将面部对齐到通用的三维形状模型。一个具有多个类别的网络被训练以在超过四千个身份上执行人脸识别任务。作者还实验了所谓的Siamese网络，在该网络中他们直接优化两个面部特征之间的L1距离。他们的最佳性能（97.35%）来自使用不同对齐和颜色通道的三个网络的组合。这些网络预测的距离（基于χ2核的非线性SVM预测）通过非线性SVM进行组合。 

Sun等人[14，15]提出了一种紧凑的网络，因此相对便宜。他们使用了由25个这样的网络组成的集合，每个网络都操作在不同的面部块上。对于他们的最终性能（在LFW上的99.47％[15]），作者将50个响应（常规和翻转）组合在一起。PCA和一个有效的线性变换对应于嵌入空间中的联合贝叶斯模型[2]被采用。该方法不需要明确的二维/三维对齐。通过结合分类和验证损失来训练这些网络。验证损失类似于我们所使用的损失[12，19]，它最小化具有相同身份的脸之间的L2距离，并且强制执行不同身份的脸之间的距离差。主要区别在于仅比较图像对，而三元组损失鼓励相对距离约束。 

与本文中使用的损失函数相似，王等人[18]在对图像进行语义和视觉相似性排序时进行了探索。 

<a id="3.方法Method"></a>
## 3.方法 Method
FaceNet使用深度卷积网络。我们讨论两种不同的核心架构：Zeiler & Fergus [22]风格的网络和最近的Inception [16]类型网络。这些网络的细节在第3节中描述。  

根据模型细节，将其视为一个黑盒子（见图2），我们方法最重要的部分在于整个系统的端到端学习。为此，我们使用直接反映我们在面部验证、识别和聚类中想要实现的目标的三元损失函数。即，我们力求将图像x映射到特征空间 R<sup>d</sup> 中的嵌入f(x)，使得同一身份的所有人脸之间的平方距离很小，而不同身份的人脸图像对之间的平方距离很大。 

![image](https://github.com/user-attachments/assets/b5cba048-3d54-418f-8f10-4db3807a7aa7)  
(图2。模型结构。我们的网络由一个批次输入层和随后的L2归一化(L2归一化是满足一个球面吗)组成的深层CNN组成，这形成了面部embedding。在训练期间被triplet loss监督。 )

虽然我们没有直接与其他损失进行比较，例如使用正负对的损失，如在 [14] 中方程 (2) 所用的那样，但我们相信三元组损失更适合于人脸验证。动机是来自 [14] 的损失鼓励一个身份的所有面孔投影到特征空间中的单个点上。然而，三元组损失试图强制执行每个面孔之间的距离，从而强制执行所有其他面孔之间的距离。这允许一个身份的面孔生活在曲面上，同时仍然保证与其它身份的距离和可区分性。 

以下部分描述了该三元损失的结构及其三元损失如何在大规模下高效学习。 
<a id="3.1TripletLoss"></a>
### 3.1 Triplet Loss
embedding 由 $`f(x) \in \mathbb{R}^d `$ 表示。它将图像 x 映射到一个 d维 的欧几里得空间中。此外，我们还限制了该embedding必须存在于该d维超球面上，即 $`\left \| f(x) \right \|_2 = 1`$。这个损失函数在[19]中得到了激发，其背景是在最近邻分类的上下文中。我们希望确保特定人脸图像 $`x_i^a`$（anchor）与同一个人的不同人脸图像 $`x_i^p`$（positive）更加接近，离其他人的人脸图像 $`x_i^n`$（negative) 更远。图3给出了可视化结果。 

![image](https://github.com/user-attachments/assets/c8e7114b-c089-4e50-8205-7a9f4dc4ed9e)  
(图3。三元损失最小化具有相同身份的锚和正样本之间的距离，并最大化具有不同身份的负样本与锚之间的距离。 )

我们希望得到的结果是：
```math
\left \| f(x_i^a) - f(x_i^p) \right \|_2^2 + \alpha < \left \| f(x_i^a) - f(x_i^n) \right \|_2^2  \forall( f(x_i^a), f(x_i^p), f(x_i^n)) \in \tau (1)
```
被最小化的损失是L=
```math
\sum_{i}^{N} \left [ \left \| f(x_i^a) - f(x_i^p) \right \|_2^2 - \left \| f(x_i^a) - f(x_i^n) \right \|_2^2 + \alpha \right ]  (2)
```
其中，α 是正负样本对之间的强制间隔 margin 。$`\tau `$ 是训练集中所有可能三元组的集合，并且其大小为 N 。

生成所有可能的三元组会导致许多容易满足的三元组（即满足方程（1）中的约束）。这些三元组不会对训练做出贡献，因为它们仍然会通过网络。选择困难的三元组至关重要，这些三元组是活跃的，并且因此可以改善模型。下面的部分将讨论我们用于三元组选择的不同方法。 
<a id="3.2TripletSelection"></a>
### 3.2 Triplet Selection
为了确保快速收敛，选择违反方程（1）中三元组约束的三元组至关重要。这意味着，在给定 anchor 图像 $`x_i^a`$ 的情况下，我们希望选择一个$`x_i^p`$（硬正例），使得$`argmax_{x_i^p}\left \| f(x_i^a) - f(x_i^p)  \right \| _2^2`$，并且类似地选择$`x_i^n`$ (硬负例），使得$`argmin_{x_i^p}\left \| f(x_i^a) - f(x_i^n)  \right \| _2^2`$
在整个训练集中计算argmin和argmax是不可行的。此外，这可能会导致不良的训练，因为误标记和图像质量差的脸会主导困难的正负样本。有两个明显的解决方案可以避免这个问题：

• 在每n步生成三元组，使用最新的网络检查点，并在数据的子集上计算argmin和argmax。   
• 在线生成三元组。这可以通过从 mini-batch 中选择困难的正/负示例来完成。 

 在这里，我们关注在线生成，并使用数千个示例的大型 mini-batch。仅在 mini-batch 内计算 argmin 和 argmax 。 

为了获得有意义的 anchor-positive 距离表示，需要确保每个 mini-batch 中包含每个人的最小样本数。在我们的实验中，我们从训练数据中采样，使得每个 mini-batch 中大约选取 40 张不同人的脸。此外，还会向每个 mini-batch 中添加随机采样的负样本。

与选择最困难的正样本不同，我们使用 mini-batch 中的所有锚定-正样本对，并且仍然选择最难的负样本。我们没有在 mini-batch 中比较硬锚定-正样本对和所有锚定-正样本对之间的侧边对比，但我们发现实践中，全部锚定-正样本方法更加稳定，在训练初期收敛速度稍快一些。 

我们还探讨了离线生成三元组与在线生成三元组的结合使用，这可能允许使用更小的批量大小，但实验结果并不明确。在实际操作中，选择最困难的负样本可能会导致效果不佳。

训练初期的局部最小值，特别是它会导致模型崩溃（即f (x) = 0）。为了缓解这种情况，选择x以使 
```math
\left \| f(x_i^a) - f(x_i^p)  \right \| _2^2 < \left \| f(x_i^a) - f(x_i^n)  \right \| _2^2 (4)
```
我们称这些负例为半硬的，因为它们比正例更远离锚点，但仍然很困难，因为平方距离接近锚点和正例之间的距离。那些负例位于阈值α之内。 

正如前面提到的，正确三元组选择对于快速收敛至关重要。一方面我们希望使用小mini-batch，因为这些在Stochastic Gradient Descent (SGD) [20]中倾向于改善收敛性。另一方面，实施细节使得包含数十到数百个示例的小批量更有效率。然而，与批处理大小相关的最主要限制是我们在mini-batch内部选择困难相关三元组的方式。大多数实验中使用的批处理大小约为1,800个示例。 

<a id="3.3DeepConvolutionalNetworks"></a>
### 3.3 Deep Convolutional Networks
 在所有实验中，我们使用标准反向传播（BP）和随机梯度下降（SGD）训练CNN。在大多数实验中，我们从学习率0.05开始，然后降低到最终模型。模型从随机初始化，类似于[16]，并在CPU集群上进行1,000至2,000小时的训练。在训练了500小时后，损失减少（准确度增加）的速度急剧减慢，但额外的训练仍能显著提高性能。α设置为0.2。 

我们使用了两种类型的架构，并在实验部分更详细地探讨了它们的权衡。它们在实际应用中的主要区别在于参数数量和浮点运算量（FLOPS）。最佳模型可能会因应用的不同而有所不同。例如，运行在数据中心的模型可以有很多参数并且需要大量的 FLOPS，而运行在手机上的模型则需要参数较少，以便能够适应内存限制。我们所有的模型都使用了修正线性单元（ReLU）作为非线性激活函数。

第一类，如表1所示，在Zeiler & Fergus [22]架构的标准卷积层之间添加了1×1×d卷积层，如[9]中所述，并导致一个深度为22的模型。它总共包含1.4亿个参数，并且每张图像需要大约16亿次浮点运算。 

![image](https://github.com/user-attachments/assets/5134d425-db6c-4587-bd28-47add5b06765)
(表1。NN1。该表显示了我们基于Zeiler & Fergus [22]的模型结构，其灵感来自[9]中的1×1卷积。输入和输出大小描述为rows × cols × #filters 。核规格为 rows × cols，stride 以及最大池化[6]的大小为p = 2。 )

我们使用的第二类模型基于GoogLeNet风格的Inception模型[16]。这些模型参数数量减少了20倍（约为660万到750万），并且计算量减少了最多5倍（在5亿到16亿之间）。其中一些模型在尺寸（包括深度和滤波器数量）上大幅减少，从而可以在手机上运行。例如，模型NNS1有2600万参数，每张图片仅需220M FLOPS；而另一个模型NNS2有430万参数，仅需20M FLOPS。表2详细描述了我们的最大网络NN2。NN3在架构上与NN2相同，但输入大小减少到160x160。NN4的输入大小仅为96x96，从而大幅降低了CPU需求（NN2的285M FLOPS与1.6B FLOPS相比）。除了减少输入大小外，它还在较高层不使用5x5卷积，因为到那个时候感受野已经足够小了。通常我们发现，5x5卷积可以在整个网络中去除，只会导致微小的准确性下降。图4对比了我们所有的模型。

![image](https://github.com/user-attachments/assets/ec264392-7711-42c2-b569-a1cd80792520)
(图4。FLOPS与精度的权衡。显示了在不同模型大小和架构范围内，FLOPS和精度之间的权衡。我们实验中重点关注的四个模型被突出显示。 )
 
<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion










