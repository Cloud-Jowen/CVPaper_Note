# Rank consistent ordinal regression for neural networks with application to age estimation

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  https://arxiv.org/pdf/1901.07884v7.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
在许多实际的预测任务中，类别标签包含有关标签之间相对顺序的信息，而这些信息无法通过常用的损失函数（如多类别交叉熵）捕捉到。最近，深度学习社区采用了序数回归框架来考虑这种顺序信息。神经网络通过将序数目标转化为二分类子任务来具备序数回归能力。然而，这种方法在不同的二分类器之间存在一致性问题。为了解决这些不一致性，我们提出了具有强有力的理论保证（对于秩单调性和一致的置信度得分）的COnsistent RAnk Logits（CORAL）框架。此外，所提出的方法与网络架构无关，并且可以扩展任意先进的深度神经网络分类器以用于序数回归任务。在面部图像年龄预测的一系列数据集上对所提出的秩一致方法进行的实证评估显示，与参考的序数回归网络相比，预测误差显著减少。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
序数回归（也称为序数分类）描述了在序数尺度上预测标签的任务。在这里，排名规则或分类器h将每个对象$`x_i ∈ X`$映射成一个有序集合h:X→Y，其中$`Y={r_1 ≺...≺r_K}`$。与分类不同，标签提供了足够的信息来排序对象。然而，与度量回归相反，标签值之间的差异是任意的。

虽然机器学习领域已经开发出许多强大的预测建模算法，但大多数算法都是为分类任务设计的。Li和Lin（2007）提出的扩展二元分类方法是许多序数回归实现的基础。然而，基于神经网络的此方法的实现通常会在二元排名之间出现分类器不一致性问题（Niu等人，2016）。这种单独的二元分类器的预测之间不一致的问题在图1中进行了说明。我们提出了一种新的方法和定理，可保证分类器的一致性，并且可以轻松地在各种神经网络架构中实现。

此外，本文还针对使用卷积神经网络（CNNs）结合我们的方法来预测个体年龄的具有挑战性的真实世界数据集，提供了理论上秩一致性保证的实证分析。由于人脸的老化效应因个体年龄不同而异，因此老化可以被视为非平稳过程。在童年期间，面部老化主要与面部形状的改变相关，而在成年期间，老化主要由皮肤纹理的变化定义（Ramanathan等人，2009；Niu等人，2016）。基于这种假设，可以使用基于序数回归的方法来建模年龄预测（Yang等人，2010；Chang等人，2011；Cao等人，2012；Li等人，2012）。

本文的主要贡献如下：

一致秩对数（CORAL）框架用于具有分类器一致性理论保证的序数回归；
实现CORAL以适应常见的CNN架构，如ResNet（He等人，2016），用于序数回归；
对不同年龄估计数据集进行实验，显示CORAL的保证二元分类器一致性相对于参考框架的序数回归具有更好的预测性能。

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work

<a id="2.1序数回归和排名"></a>
### 2.1 序数回归和排名 Ordinal regression and ranking
过去已经开发了多种广义线性模型的序数回归的多元扩展，其中包括流行的比例几率和比例危害模型（McCullagh，1980）。此外，机器学习领域还基于经过充分研究的分类算法的扩展，通过重新定义问题以利用多个二元分类任务，开发了序数回归模型（Baccianella等人，2009）。在这方面的早期工作包括使用感知机（Crammer和Singer，2002；Shen和Joshi，2005）和支持向量机（Herbrich等人，1999；Shashua和Levin，2003；Rajaram等人，2003；Chu和Keerthi，2005）。Li和Lin（2007）提出了一个通用的规约框架，统一了一些现有算法的观点。

<a id="2.2序数回归的CNN方法"></a>
### 2.2 序数回归的CNN方法 Ordinal regression and ranking
虽然早期使用卷积神经网络（CNNs）进行序数目标的研究采用了传统的分类方法（Levi和Hassner，2015；Rothe等人，2015），但是Li和Lin（2007）提出的将序数回归转化为二元分类的通用规约框架最近被Niu等人（2016）采用，并被称为序数回归CNN（OR-CNN）。在OR-CNN方法中，具有K个等级的序数回归问题被转化为K-1个二元分类问题，其中第k个任务预测人脸图像的年龄标签是否超过第k个等级rk，k=1,...,K−1。所有K-1个任务共享相同的中间层，但在输出层中分配不同的权重参数。

虽然OR-CNN在基准数据集上能够达到最先进的性能，但它并不能保证一致的预测，因此对于个别的二元任务的预测可能会有分歧。例如，在年龄估计设置中，如果第k个二元任务预测一个人的年龄超过30岁，但之前的任务预测该人的年龄不到20岁，这将是矛盾的。当将K-1个任务的预测结果合并以获得估计年龄时，这种不一致可能不是最优的。

Niu等人（2016）认识到分类器的不一致性并非理想，他们还指出确保K-1个二元分类器的一致性会大大增加训练复杂性（Niu等人，2016）。本文提出的CORAL方法解决了以上两个问题，具有分类器一致性的理论保证，并且不增加训练复杂性。

<a id="2.3其他用于年龄估计的CNN架构"></a>
### 2.3 其他用于年龄估计的CNN架构 Other CNN architectures for age estimation
Chen等人（2017）提出了OR-CNN（Niu等人，2016）的修改版本，称为Ranking-CNN，它使用一组CNN进行二元分类，并汇总预测结果以估计给定人脸图像的年龄标签。研究人员表明，训练一组CNN比训练具有多个二元输出的单个CNN可以提高预测性能（Chen等人，2017），这与一个众所周知的事实一致，即集成模型可以比集合中的每个单独分类器实现更好的泛化性能（Raschka和Mirjalili，2019）。

最近的研究还表明，训练一个多任务CNN，该CNN共享底层参数用于各种面部分析任务（人脸检测、性别预测、年龄估计等），可以提高不同任务之间的整体性能（Ranjan等人，2017）。

另一种利用二元分类器进行序数回归的方法是Polania等人（2019）提出的连体CNN架构，该架构通过输入图像与多个精选的锚点图像之间的配对比较来计算排名。

<a id="3.CORAL"></a>
## 3.CORAL
我们提出的 CORAL 框架旨在解决 Niu 等人（2016）提出的 OR-CNN 中分类器不一致的问题，该框架基于多个用于排名的二元分类任务。

<a id="3.1前置知识"></a>
### 3.1 前置知识 Preliminaries
设  $`  D = \left \{ x_i,y_i \right \}_{i=1}^N  `$ 为由N个训练样本组成的训练数据集。这里，$`x_i \in X`$ 表示第i个训练样本，yi表示相应的排名，其中$`y_i \in Y = {r_1,r_2,...r_K}`$，有序排名 $`r_K > r_{K-1} > r_{1}`$。序数回归任务是找到一个排名规则$`h:X -> Y`$，使得最小化损失函数 $`L(h)`$ 。

设C是一个$`K×K`$的成本矩阵，其中$`C_{y,r_k}`$表示对于将示例(x, y)预测为排名$`r_k`$的成本（Li和Lin，2007）。通常情况下，$`C_{y,y} = 0`$,且对于$`y≠rk`$，$`C_{y,r_k} > 0`$。在有序回归中，我们通常希望成本矩阵的每一行呈V形，即如果$`r_k \le y`$，则$`C_{y,r_{k-1}} \ge  C_{y,r_k}`$，如果$`r_k \ge y`$，则$`C_{y,r_{k}} \le  C_{y,r_{k+1}}`$。分类的成本矩阵中的条目$` C_{y,r_k} = \mathbb{1}\left \{ y \neq r_k \right \} `$不考虑排序信息。在有序回归中，其中排名被视为数值，常用的绝对成本矩阵由$`C_{y,r_k} = \left | y-r_k \right | `$定义。

Li和Lin（2007）提出了一个通用的降维框架，用于将有序回归问题扩展为多个二元分类问题。该框架需要成本矩阵在每一行上都是凸的（对于每个y都有：
$`(  C_{y,r_{k+1}} - C_{y,r_k} \ge   C_{y,r_k}  - C_{y,r_{k-1}})`$），以获得一个排名单调阈值模型。由于每个二元任务的成本加权对每个训练示例都是特定的，这种方法在实践中被认为是不可行的，因为它具有很高的训练复杂性（Niu等，2016）。

我们提出的CORAL框架既不需要成本矩阵具有凸行条件，也不需要依赖于每个训练示例的显式加权项，即可获得一个排名单调的阈值模型，并对每个二元任务产生一致的预测。

<a id="3.2一致性排名logits模型的序数回归"></a>
### 3.2 一致性排名logits模型的序数回归
在本节中，我们描述了我们提出的用于序数回归的一致性排名logits（CORAL）框架。子节3.2.1描述了用于排名预测的标签扩展为二元任务的方法。CORAL框架的损失函数在子节3.2.2中描述。在子节3.2.3中，我们证明了关于二元分类任务之间排名一致性的定理，这保证了二元任务的预测具有一致的排名。

<a id="3.2.1标签扩展和排名预测"></a>
### 3.2.1 标签扩展和排名预测 Label extension and rank prediction
给定一个训练数据集$`D = \left \{ x_i,y_i \right \}_{i=1}^N `$，一个排名$`y_i`$ 首先被扩展成 K − 1 个二元标签$`y_i^{(1)},...,y_i^{(K-1)}`$ ，使得$`y_i^{(k)}\in \left \{ 0,1 \right \} `$  表示 $`y_i`$ 是否超过排名 $`r_k`$，例如，$`y_i^{(k)} = \mathbb{1}\left \{ y_i,r_k \right \}`$。这里的指示函数 $`\mathbb{1}\left \{ \cdot  \right \}`$ 在内部条件为真时取值为1，否则为0。在模型训练过程中使用扩展的二元标签，我们在输出层训练了一个具有 K − 1 个二元分类器的单个CNN模型，如图2所示。

<img width="1144" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/259dc2ee-8230-4827-a774-f4fa85bc87b9">。
（图2：一致排名logits卷积神经网络（CORAL-CNN）用于年龄预测的示意图。通过估计的概率值，使用公式5得到二元标签，然后通过公式1将其转换为年龄标签。）

根据二元任务的响应，对于输入 $`x_i`$ ，通过 $`h(xi) = rq`$ 得到预测的排名标签。排名索引$`q`$由以下公式给出$`q = 1 + {\textstyle \sum_{k=1}^{K-1}}f_k(x_i) `$其中 $`f_k(x_i) \in \left \{ 0,1 \right \} `$ 是输出层第 k 个二元分类器的预测值。我们要求$` \left \{ f_k \right \}_{k=1}^{K-1} `$反映序数信息并且是排名单调的，即 $`f_1(x_i)\ge f_2(x_i)\ge ...\ge f_{K-1}(x_i)`$，这保证了一致的预测结果。为了实现排名单调性并确保二元分类器的一致性（定理1），K − 1 个二元任务共享相同的权重参数，但具有独立的偏置单元（图2）。

<a id="3.2.2损失函数"></a>
### 3.2.2 损失函数 Loss function
设 W 表示神经网络的权重参数，不包括最后一层的偏置单元。倒数第二层的输出记为$`g(x_i,W)`$ ，它与最终输出层的所有节点共享一个权重；然后向 $`g(x_i,W)`$ 添加 K - 1 个独立的偏置单元，使得$`\left \{  g(x_i,W) + b_k\right \}_{k=1}^{K-1}`$成为最终层中相应二元分类器的输入（其中 k=1）。令$`σ(z) = 1/(1 + exp(−z))`$ 为逻辑 sigmoid 函数。任务 k 的预测经验概率被定义为：
$`\hat{P}(y_{i}^{(k)}=1) = σ(g(x_i,W)+b_k)`$

对于模型训练，我们最小化损失函数
```math
L(W,b) = -\sum_{i=1}^{N}\sum_{k=1}^{K-1}\lambda^{(k)}[log(σ(g(x_i,W)+b_k))y_i^{(k)} +
log(1-σ(g(x_i,W)+b_k))(1-y_i^{(k)})]
```
（公式），这是K-1个二元分类器的加权交叉熵。对于排名预测（公式1），通过以下方法获得二元标签：
$`f_{k}(x_i)=\mathbb{1}\left \{  \hat{p}(y_i^{(k)}=1)>0.5 \right \} `$

在公式4中，$`\lambda ^{(k)}`$表示与第k个分类器相关联的损失权重（假设$`\lambda ^{(k)}>0`$）。在本文的剩余部分中，我们将$`\lambda ^{(k)}`$称为任务k的重要参数。一些任务可能不太稳健或更难优化，这可以通过选择非均匀任务加权方案来考虑。为简单起见，我们使用均匀任务加权进行所有实验，即$`∀k：\lambda ^{(k)}= 1`$。 在下一节中，我们将提供分类器一致性的理论保证，在任务重要权重为正数的情况下，给出均匀和非均匀任务重要性加权的理论保证。

<a id="3.2.3分类器一致性的理论保证"></a>
### 3.2.3 分类器一致性的理论保证 Theoretical guarantees for classifier consistency
以下定理表明，通过最小化损失函数 L，学习到的输出层偏置单元是非递增的，即 $`b_1 ≥ b_2 ≥ ... ≥ b_{K−1}`$。因此，K - 1 个任务的预测置信度分数或概率估计是递减的，例如，
```math
\hat{P}(y_i^{(1)}=1)\ge\hat{P}(y_i^{(2)}=1)\ge\hat{P}(y_i^{(K-1)}=1)
```
对于所有的 i，确保了分类器的一致性。因此，$`\left \{ f_k \right \}_{k-1}^{K-1}`$也是排名单调的。

定理1（有序的偏置单元）。通过最小化损失函数，最优解$`(W^*,b^*)`$满足$`b_1^*\ge b_2^*\ge ...\ge b_{K-1}^*`$
证明。假设（W，b）是一个最优解，且对于某个k，$``$bk < bk+1。声明：将bk替换为bk+1或将bk+1替换为bk会减少目标值L。令
```math
A_1 ={n:y_n^{\left ( k \right ) } =y_n^{\left ( k+1 \right ) } =1},
A_2 ={n:y_n^{\left ( k \right ) } =y_n^{\left ( k+1 \right ) } =0},
A_3 ={n:y_n^{\left ( k \right ) } =1,y_n^{\left ( k+1 \right ) } =0},
```
由于排序关系，我们有
$`A_1 \cup A_2 \cup A_3 = {1,2,...,N}`$
记$`p_n\left ( b_k \right )  = σ(g(x_n, W) + b_k) `$和
```math
δ_n = log(p_n(b_{k+1})) − log(p_n(b_k)),
δ_n^{'}  = log(1-p_n(b_{k})) − log(1-p_n(b_{k+1})),
```


由于$`p_n(b_k)`$随着$`b_k`$的增加而增加，我们有$`δ_n >0`$和$`δ_n^{'}>0`$。
如果我们将$`b_k`$替换为`b_{k+1}`$，与第k个任务相关的损失项将被更新。损失L（等式4）的变化可以表示为：
```math
\bigtriangleup _1L = \lambda ^{(k)}[-\sum_{n\in A_1}δ_n + \sum_{n\in A_2}δ_n^{'} - \sum_{n\in A_3}δ_n ]
```
同样地，如果我们将`b_{k+1}`$替换为`b_k`$，损失L的变化可以表示为：
```math
\bigtriangleup _2L = \lambda ^{(k+1)}[\sum_{n\in A_1}δ_n - \sum_{n\in A_2}δ_n^{'} - \sum_{n\in A_3}δ_n^{'} ]
```

通过添加 $`\frac{1}{\lambda^{(k)}} \bigtriangleup _1L`$ 和 $`\frac{1}{\lambda^{(k+1)}} \bigtriangleup _2L`$,我们有
```math
\frac{1}{\lambda^{(k)}} \bigtriangleup _1L+\frac{1}{\lambda^{(k+1)}} \bigtriangleup _2L = -\sum_{n \in A_3}^{δ
_n+δ_{n}^{′}} < 0
```
并且知道$`\delta_1L < 0 `$或者$`\delta_2L < 0 `$。因此，我们的断言是合理的。我们得出结论，任何最小化损失函数 L 的最优解 $`(W^*,b^*)`$ 都满足$`b_1^* ≥ b_2^* ≥ ... ≥ b_{K−1}^*`$

需要注意的是，李和林（2007）提出的关于排名单调性的定理与定理1相比，需要一个每行yn都是凸的成本矩阵C。在这种凸性条件下，令$`\lambda _{y_n}^{(k)} = \left | C_{y_n,r_k} - C_{y_n,r_{k+1}}\right | `$表示与第n个训练样本上的第k个任务相关的损失的权重，它依赖于标签$`y_n`$。李和林（2007）证明了通过使用样本特定的任务权重$`\lambda _{y_n}^{(k)}`$，最优的阈值是有序的 - 牛等人（2016）指出在实践中样本特定的任务权重是不可行的。此外，这个假设要求当$`r_{k+1} < y_n`$时，$`\lambda _{y_n}^{(k)} \ge \lambda _{y_n}^{(k+1)}`$，当$`r_{k+1} > y_n`$时，$`\lambda _{y_n}^{(k)} \le \lambda _{y_n}^{(k+1)}`$。定理1不受此要求的限制，并允许我们为每个任务选择一个固定的权重，这不依赖于单个训练样本，大大降低了训练的复杂性。此外，定理1允许选择简单的均匀任务加权或考虑数据集的不平衡，在保证预测概率非递减和一致的任务预测的情况下。根据定理1，保证排名单调性的唯一要求是任务权重是非负的。

<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="4.1数据集和前处理"></a>
### 4.1 数据集和前处理Datasets and preprocessing
MORPH-2数据集（Ricanek和Tesafaye，2006）包含55,608张人脸图像，从 https://www.faceaginggroup.com/morph/ 下载并进行预处理。预处理过程中，使用面部标志检测（Sagonas等人，2016）定位了各自数据集中的平均眼睛位置，并使用MLxtend v0.14中的EyepadAlign功能将数据集中的每个图像对齐到平均眼睛位置（Raschka，2018）。然后，对人脸进行重新对齐，使得每个图像的鼻尖位于图像的中心。本研究使用的年龄标签范围在16至70岁之间。

CACD数据集（Chen等人，2014）从 http://bcsiriuschen.github.io/CARC/ 下载，并按照与MORPH-2类似的方式进行预处理，使得人脸跨越整个图像，鼻尖位于中心位置。该数据集总共包含159,449张图像，年龄范围为14至62岁。

亚洲人脸数据库（AFAD）由Niu等人（2016）提供，可以从 https://github.com/afad-dataset/tarball 获取。本研究使用的AFAD数据库包含了165,501张15至40岁之间的人脸。由于人脸已经居中，无需进一步预处理。

按照Niu等人（2016）的描述，将每个图像数据库随机划分为80%的训练数据和20%的测试数据。所有图像都被调整为128×128×3像素大小，然后随机裁剪为120×120×3像素，以增强模型的训练。在模型评估过程中，128×128×3的RGB人脸图像将被中心裁剪到模型输入大小为120×120×3。

我们在代码仓库（第4.4节）中分享了所有数据集的训练和测试分区，以及本文中使用的所有预处理代码。

<a id="4.2神经网络架构"></a>
### 4.2 神经网络架构 Neural network architectures
为了评估CORAL在人脸图像年龄估计方面的性能，我们选择了ResNet-34架构（He等人，2016），这是一种现代CNN架构，在各种图像分类任务上都取得了良好的性能。在本文的剩余部分中，我们将原始的ResNet-34 CNN与标准的交叉熵损失称为CE-CNN。为了使用所提出的CORAL方法实现ResNet-34 CNN进行序数回归，我们用相应的二元任务替换了最后一个输出层（如图2所示），并将此实现称为CORAL-CNN。类似于CORAL-CNN，我们修改了ResNet-34的输出层以实现(Niu等人，2016)中描述的序数回归参考方法，我们将此架构称为OR-CNN。

<a id="4.3训练和验证细节"></a>
### 4.3 训练和验证细节 Training and evaluation
为了对模型进行评估和比较，我们在最后一个训练时期后，在测试集上计算了平均绝对误差（MAE）和均方根误差（RMSE），
```math
MAE = \frac{1}{N}\sum_{i=1}^{N}\left |  y_i-h(x_i)\right | 
```
```math
RMSE = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(y_i-h(x_i))^{2} } 
```
分别表示第i个测试示例的真实排名yi和预测排名h(xi)之间的误差。

本文的模型训练使用了不同的随机种子（0、1和2）进行了三次重复，用于模型权重初始化，而不同方法之间的随机种子是一致的，以便进行公平比较。由于本研究重点研究排名一致性，所以关于优化算法的广泛比较超出了本文的范围，因此所有CNN都是使用随机梯度下降通过自适应矩估计（Kingma和Ba，2015）进行200个时期的训练，并使用指数衰减率β0 = 0.90和β2 = 0.99（默认设置）和批量大小为256。为避免因为为比较序回归方法而设计自己的CNN架构而引入经验偏差，我们采用了标准架构（ResNet-34（He等人，2016）；第4.2节）进行比较。此外，在CORAL-CNN中，我们选择了一种统一的任务加权方案来对K-1个二进制分类器的交叉熵进行加权，例如，在等式4中，我们设置$`∀k：λ^{(k)}= 1`$。

<a id="4.4软硬件信息"></a>
### 4.4 软硬件信息 Hardware and software
所有损失函数和神经网络模型均在PyTorch 1.5（Paszke等人，2019）中实现，并在NVIDIA GeForce RTX 2080Ti和Titan V图形卡上进行训练。源代码可在https://github.com/Raschka-research-group/coral-cnn 获取。

<a id="5.结果和讨论Results and discussion"></a>
## 5.结果和讨论 Results and discussion
我们在三个独立的人脸图像数据集上进行了一系列关于年龄估计（第4.1节）的实验，以比较提出的CORAL方法（CORAL-CNN）与Niu等人提出的序回归方法（OR-CNN）。所有的实现都基于第4.2节中描述的ResNet-34架构。我们将标准的ResNet-34分类网络与交叉熵损失（CE-CNN）作为性能基准。

<a id="5.1从人脸图像中估计表观年龄"></a>
## 5.1 从人脸图像中估计表观年龄 Estimating the apparent age from face images
在所有的序回归数据集（表1）中，我们发现无论是OR-CNN还是CORAL-CNN都优于标准的交叉熵分类损失（CE-CNN），后者不利用排序信息。同样地，在表1中总结的结果显示，提出的保持排序一致性的CORAL方法相比于不保证分类器一致性的OR-CNN（Niu等人，2016）有着显著的性能提升。

此外，我们对每个实验进行了三次重复，使用不同的随机种子进行模型权重初始化和数据集洗牌，以确保CORAL-CNN相对于OR-CNN的性能改进是可复现的，而非巧合。因此，我们可以得出结论，通过CORAL保证分类器的一致性对序回归CNN的预测性能有明显的积极影响（关于OR-CNN的排名不一致性的更详细分析请参见第5.2节）。

在所有方法（CE-CNN、CORAL-CNN和OR-CNN）中，不同数据集上的整体性能呈以下顺序：MORPH-2 > AFAD > CACD（表1）。一个可能的解释是MORPH-2具有最佳的整体图像质量，并且照片是在相对一致的光照条件和观察角度下拍摄的。例如，我们发现AFAD包含分辨率非常低的图像（例如20x20）。CACD也含有一些质量较低的图像。由于CACD与AFAD的大小大致相同，对于这个数据集整体性能较低的原因可能还可以通过需要考虑更广泛年龄范围（CACD：14-62岁，AFAD：15-40岁）来解释。
<img width="1090" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/5790ea35-5617-4b20-9a1f-c692670f6e4d">  
（表格1. 在测试集上的年龄预测误差。所有模型都基于ResNet-34架构。）

<a id="5.2经验性排名不一致性分析"></a>
## 5.2 经验性排名不一致性分析 Empirical rank inconsistency analysis
根据设计，我们提出的CORAL保证了排名一致性（定理1）。此外，我们对CORAL-CNN和OR-CNN的排名不一致性进行了经验分析（图3展示了排名不一致性的一个例子）。  

<img width="895" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/5ebd0e0e-905f-40a1-a627-ad00b76efca1">  
(图3. MORPH-2测试数据集中四个不同例子的每个二元分类器任务的预测概率图。在所有情况下，与CORAL-CNN相比，OR-CNN出现了一个或多个不一致性（由箭头指示）。)

表2总结了OR-CNN和CORAL-CNN模型在每个测试数据集上的平均排名不一致性数量。

<img width="1105" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/e2594c1e-c9f8-4165-a585-7a07a99b06d2">  
(表2. CORAL-CNN和Niu等人的序回归CNN在不同测试数据集上发生的不一致性的平均数量。倒数第二列和最后一列分别列出了仅关注正确和错误年龄预测时的平均不一致性数量。)

正如预期的那样，CORAL-CNN没有排名不一致性。当仅考虑OR-CNN正确或错误预测年龄的情况下，对比平均不一致性数量，当OR-CNN做出错误预测时，平均不一致性数量更高。这个观察结果可以看作是排名不一致性损害了预测性能的证据。因此，这个发现表明通过CORAL解决排名不一致性对序回归CNN的预测性能是有益的。


<a id="6.结论Conclusion"></a>
## 6.结论 Conclusion
本文中，我们开发了 CORAL 框架，通过扩展二元分类实现了有序回归，并提供了对分类器一致性的理论保证。此外，我们证明了分类器的一致性，而无需依赖排名或训练标签的加权方案，这使得实现简单且模型训练高效。CORAL 可以方便地应用于扩展常见的卷积神经网络架构，用于有序回归任务。实验证明，CORAL 框架大大提升了在三个独立的年龄估计数据集上基于 CNN 的预测性能。我们的方法可以轻松推广到其他有序回归问题和不同类型的神经网络架构，包括多层感知机和循环神经网络。










