# Learning Expectation of Label Distribution for Facial Age and Attractiveness Estimation

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  https://github.com/paplhjak/facial-age-estimation-benchmark  
论文链接：  https://arxiv.org/pdf/2007.01771v2.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
通过使用卷积神经网络（CNN），面部属性（如年龄和魅力）的估计性能得到了显著提高。然而，现有方法在训练目标和评估指标之间存在一致性不足的问题，因此可能不够优化。此外，这些方法通常采用具有大量参数的图像分类或人脸识别模型，从而导致计算成本高昂和存储开销大。本文首先分析了两种最先进方法（Ranking-CNN和DLDL）之间的基本关系，并表明Ranking方法实际上隐含地学习了标签分布。因此，我们首次将这两种流行的最先进方法统一到了DLDL框架中。其次，为了减少一致性问题并降低资源消耗，我们设计了一种轻量级网络架构，并提出了一个统一的框架，可以同时学习面部属性分布和回归属性值。我们的方法在面部年龄和魅力估计任务上证明了其有效性。我们的方法使用单一模型取得了SOTA结果，仅包含原始模型36倍的参数数量，并且推理速度提高了3倍。此外，即使将参数数量进一步减少到0.9M（3.8MB磁盘存储），我们的方法仍能够达到与SOTA相媲美的结果。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
人脸包含了许多重要的个体特征信息，例如身份、表情、年龄、魅力和性别。这些信息已经被广泛应用于实际应用领域，如视频监控、客户画像、人机交互和个人识别。在这些任务中，开发自动年龄和魅力估计方法近年来成为一个有吸引力但具有挑战性的课题。

从面部图像中找到年龄和魅力的任务为什么具有挑战性呢？首先，与图像分类或人脸识别相比，现有的面部属性数据集往往非常有限，因为很难收集到完整且充分标注的数据集。例如，ChaLearn15明显年龄估计挑战赛中只有2476张训练图像。其次，不同标签组中的图像数量非常不平衡。此外，不同数据集的分布也非常不同。如图1所示，ChaLearn16（大约2岁和26岁处有两个峰值）和Morph（大约20岁和40岁处有两个峰值）上有两个峰值，而ChaLearn15只有一个峰值。类似的现象也出现在面部魅力数据集中。这些不平衡为开发一个准确可靠的年龄和魅力估计方法带来了严重的挑战。第三，与其他面部属性（如性别或表情）相比，年龄/魅力估计是一个非常精细的识别任务，例如，当一个人从25岁长到26岁时，我们人类很难察觉到他/她面部特征的变化。

我们是否可以使用一个统一的框架来有效地从面部图像中估计年龄和魅力呢？首先，这两个任务都是基于面部图像的，因此有可能使用一个统一的基础模型。其次，无论是年龄估计还是面部魅力评估，标签都是有序的。通常情况下，它们都被整合到序数回归或序数分类的主题中，其主要特点是类别在自然或暗示的顺序中相关联。这种任务的常见示例包括电影和面部魅力评分（例如从1星到5星）或面部年龄（例如从婴儿到儿童到成年人）或图像美学（例如从“不可接受”到“专业”到“卓越”）。第三，在面部年龄和魅力任务中，任意两个相邻标签之间存在不确定性信息，并且它们的评估指标通常都使用平均绝对误差（MAE）。因此，我们尝试在本文中将面部年龄和魅力估计整合到一个统一的框架中。

面部属性估计的常见评估指标是预测值与实际数值之间的平均绝对误差（MAE）。因此，将面部属性估计视为度量回归问题[6]，即最小化MAE，是非常自然的。然而，这样的方法通常无法达到令人满意的性能，因为一些异常值可能会导致大的误差项，从而导致不稳定的训练过程。后来，Rothe等人[7]训练了深度卷积神经网络（CNN）进行年龄估计，将其视为多类分类问题，最大化地考虑了实际类别的概率，而不考虑其他类别。由于类别之间的不平衡问题和有限的训练图像，这种方法很容易产生过拟合[8]。

最近，排名CNN[9, 10, 11, 12]和深度标签分布学习（DLDL）技术在面部年龄估计上取得了最先进的性能。这两种方法都利用了不同层级上相邻年龄之间的相关信息。排名方法将单值估计转换为一系列二元分类问题，在训练阶段直接从这些二元输出中聚合排名器的输出。DLDL首先将实数值转换为离散标签分布。然后，训练的目标是拟合整个分布。在推断阶段，像[7]一样，预测分布上的期望值被视为最终输出。我们很容易发现所有这些方法中训练目标和评估指标之间存在不一致性。因此，它们可能不是最优的。如果消除这种不一致性，我们期望可以提高它们的性能。

此外，我们观察到几乎所有最先进的面部属性估计方法[14, 13, 7, 8, 15]都是由在大规模图像分类（如ImageNet [1]）或人脸识别（如VGGFace [2]）数据集上训练的预训练模型初始化，并在目标数据集上进行微调。这些预训练模型采用了一些流行且强大的架构（如VGGNet [16]）。不幸的是，这些模型通常具有巨大的计算成本和存储开销。以VGG-16为例，它有1.3834亿个参数，占用了超过500MB的存储空间。因此，很难部署在资源受限的设备上，例如手机。最近，一些研究人员致力于压缩这些预训练模型，以实现减少参数数量并保持精度的可能性[17]。与这些压缩方法不同，我们直接设计了一个轻量级的深度网络架构，并从头开始进行训练。

在本文中，我们将标签分布学习[23]和期望回归集成到一个统一框架中，以简单而轻量的CNN架构缓解训练和评估阶段之间的不一致性。所提出的方法有效且高效地提高了先前DLDL在面部属性估计的预测误差和推断速度上的性能，因此我们称其为DLDL-v2。我们的贡献总结如下。

（1）据我们所知，我们首次提供了关于排名方法实际上是在隐含地学习标签分布的分析，并展示了这一结果，从而将现有最先进的面部属性估计方法统一到了DLDL框架中；  
（2）我们提出了一个端到端的学习框架，该框架在特征学习和分类器学习中联合学习标签分布和相邻标签之间的相关信息，并对单一标签的真实值进行回归；  
（3）我们使用单一且小型模型在面部年龄和吸引力估计任务上创造了新的最先进结果，而无需外部年龄/吸引力标记数据或多模型集成；  
（4）我们提出的框架在一定程度上是可解释的。我们发现网络在估计不同年龄阶段的人的年龄时采用了不同的模式。同时，我们还定量分析了我们的方法对不同面部区域的敏感性。  

我们将本文其余部分组织如下。第2节介绍了关于面部属性（如年龄和吸引力）估计的相关工作。然后，第3节介绍了提出的DLDL-v2方法，包括问题定义、现有方法之间的关系，以及我们的联合学习框架及其模型架构。之后，在第4节报告了实验结果。在第5节，我们讨论了DLDL-v2如何对输入面部图像进行最终决策，并分析了它为什么能够很好地工作。最后，第6节给出了结论。一些初步结果已经在会议报告中发表[24]。

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work
在过去的二十年中，许多研究人员都致力于面部属性估计。早期的研究是采用两阶段解决方案，包括特征提取和模型学习。最近，提出了深度学习方法，将这两个阶段整合到端到端的框架中。在本节中，我们简要回顾这两种类型的框架。

**两阶段方法** 第一阶段的任务是如何从面部图像中提取具有区分性的特征。活动外观模型（AAM）[25]是通过提取面部图像的形状和外观特征的最早方法。后来，生物启发特征（BIF）[26]作为最成功的年龄特征被广泛用于年龄估计。但是，在面部吸引力分析中，依赖于面部标志位置的几何特征[27]和纹理特征[28]被广泛使用，因为对于面部吸引力预测来说，BIF特征可能不是最佳选择。显然，手工设计特征的缺点在于当面对新任务时需要重新设计特征提取方法，这通常需要领域知识和大量的工作。第二阶段是如何利用这些设计的特征来准确估计面部属性。分类和回归模型通常用于估计面部属性。前者包括k最近邻（KNN）、多层感知器（MLP）和支持向量机（SVM），后者包括二次回归、支持向量回归（SVR）和软边际混合回归[29]。与分类和回归不同，排名技术[30, 31, 32, 33, 34]利用年龄的序数信息来学习面部年龄估计模型。

此外，耿等人提出了一种标签分布学习（LDL）方法，利用相邻标签之间的相关性来改善年龄估计[35]和美学感知[36]的性能。最近，还提出了LDL的一些改进方法[37, 38]。邢等人[37]使用逻辑增强回归代替LDL中的最大熵模型。同时，何等人[38]通过加权线性组合输入图像的标签和其上下文相邻图像的标签来生成年龄标签分布。这些方法仅学习分类器，而不是视觉表示。

**单阶段方法** 深度卷积神经网络在各种视觉识别任务中取得了令人瞩目的成果。最大的成功在于通过单阶段学习策略学习特征表示，而不是使用手工设计的特征。现有的面部属性估计技术可分为四类：度量回归（MR）[6]、多类分类（DEX）[7]、排名[9, 10, 11]和DLDL[8]。

MR将年龄估计视为实值回归问题。训练过程通常最小化估计值与真实值之间的平方差。

DEX采用通用的图像分类框架，在训练过程中最大化实际类别的概率。在推断阶段，Rothe等人[7]经验性地表明，通过对softmax归一化输出概率进行期望值计算可以获得比最大概率类别预测更好的性能。然而，MR和DEX都容易导致不稳定的训练[8]。

排名方法将面部属性回归转化为一系列二元分类问题。牛等人[9]提出了一种通过将多个二元分类问题集成到卷积神经网络中的多输出CNN。接着，陈等人[10, 11]训练了一系列二元分类CNN以获得更好的性能。对于给定的测试图像，排名器的输出直接从这些二元输出中聚合。

DLDL将单个值转化为标签分布，并以端到端的方式进行学习。最近，沈等人[39]提出了基于DLDL和可微分决策树的LDLFs方法。胡等人[40]利用年龄差异信息来提高年龄估计的准确性。这些方法在年龄估计方面取得了最先进的性能。此外，杨等人[41]提出了一种多任务深度框架，通过联合优化图像分类和分布学习来实现情绪识别。然而，这些方法可能不够优化，因为训练目标和评估指标之间存在不一致。

本文关注如何在参数更少的深度卷积神经网络中减轻或消除这种不一致性。从静态面部图像中估计年龄和吸引力是该研究的适用应用场景。

<a id="3.网络结构"></a>
## 3.网络结构
在本节中，我们首先给出联合学习问题的定义。接下来，我们展示排名隐含地学习标签分布。最后，我们介绍我们的框架和网络架构。

<a id="3.1联合学习问题"></a>
### 3.1 联合学习问题 The Joint Learning Problem
符号表示法。我们使用像 $`p`$ 这样的粗体小写字母来表示向量，其中 $`p`$ 的第 $`i`$ 个元素被表示为 $`p_i`$。$`1`$ 表示一个全为 1 的向量。像 $`W`$ 这样的粗体大写字母用于表示矩阵，其中第 $`i`$ 行第 $`j`$ 列的元素被表示为 $`W_{ij}`$。圆圈运算符 $`◦`$ 用于表示逐元素乘法。

输入空间为$`X = R^{h*w*c}`$，其中h、w和c分别是输入图像的高度、宽度和通道数。标签空间$`y = R `$为实值。训练集包含 $`N`$ 个实例，表示为 $`D = \left \{ \left ( x^n,y^n \right )  \right \}_{n=1}^{N} `$ ，其中 $`x^n \in X`$ 表示第 $`n`$ 个输入图像，$`y^n \in Y`$ 表示其对应的标签。为了清楚起见，我们可以省略图像索引 $`n`$。联合学习的目标是学习一个映射函数 $`X -> Y`$，使得在给定输入图像 $`x`$ 上，预测值 $`\hat{y}`$ 与真实值 $`y`$ 之间的误差尽可能小。

然而，度量回归通常无法达到令人满意的性能。我们观察到在现实生活中，人们通常以“大约25岁左右”的方式预测另一个人的表观年龄，这表明不仅使用25岁，还使用邻近的年龄（例如24岁和26岁）来描述面部特征。面部吸引力评估也存在类似情况。基于这一观察，标签分布学习方法可以通过将单一值回归问题转化为标签分布学习问题来利用这些信息。

为了实现这个目标，我们不再对输入 $`x`$ 输出单个值 $`y \in R`$ ，而是将可能的 $`y`$ 值范围划分为几个标签。例如，在年龄估计中，假设 $`y \in \left [ 0,100 \right ]`$ 是合理的。因此，我们可以定义一个有序标签向量$`l = \left [ 0:\bigtriangleup l:100  \right ]`$（MATLAB表示法），其中 $`\bigtriangleup l`$ 是一个固定的实数。然后，标签分布 $`p`$ 可以表示为 $`\left ( p_1,p_2,...,p_K \right )`$，其中$` p_i`$是 $`y = l_i`$的概率（即 $`1 \le i \le K`$ 的 $`Pr\left ( y=l_i \right )`$ ）[8]。由于在量化 $`y`$ 时使用了等距步长$`\bigtriangleup l`$，正态分布的概率密度函数（p.d.f.）是从 $`y`$ 和 $`\sigma`$ 生成真实标签分布 $`p`$ 的自然选择。

```math
p_k = \frac{1}{\sqrt{2\pi }\sigma  } exp\left (  -\frac{\left ( l_k - y \right )^2 }{2\sigma^2} \right ) 
```

其中 $`\sigma`$ 是一个超参数。标签分布学习的目标是在训练阶段最大化真实标签分布 $`p`$ 与由 CNN 生成的分布 $`\hat{p}`$ 之间的相似性。在预测阶段，通过特殊的推断函数将预测分布 $`\hat{p}`$ 转换为单个值。然而，这种方法并不理想，因为训练目标与评估指标之间存在不一致性。因此，我们有兴趣在一个端到端的框架中，不仅学习标签分布 $`p`$，还能够回归出一个实数值 $`y`$。

<a id="3.2排名是学习标签分布"></a>  
### 3.2 排名是学习标签分布 Ranking is Learning Label Distribution
在面部年龄/吸引力估计问题中，基于排名 [9, 10, 11] 和基于 DLDL [8, 42, 39, 13] 的方法已经取得了最先进的性能。在本节中，我们将从标签编码的角度探讨它们之间的本质关系。

我们从标签编码的角度来探索它们之间的关系。在基于 DLDL 的方法中，对于一个真实标签为  $`y`$、超参数为  $`\sigma`$ 的面部图像  $`x`$，目标向量  $`p^{ld}`$（即标签分布）由正态概率密度函数生成（公式（1））。例如，一个50岁面部图像的目标向量如图2a所示，其中 $`l = \left [ 0,1,...,100 \right ] `$。在排名CNN中，由于第 $`k`$ 个二元分类器专注于确定图像的年龄排名是否大于$`l_k`$，因此需要 $`K - 1`$ 个二元分类器用于 $`K`$ 个等级。对于一个真实标签为 $`y \in \left (  l_{k-1},l_k  \right ]  `$ 的面部图像 $`x`$，具有长度为 $`K-1`$ 的目标向量被编码为$`p^{rank} = \left [ 1,...,1,0,...,0 \right ] `$，其中前 $`k-1`$ 个值为1，其余为0。一个50岁面部图像的目标排名向量如图2c中的深色线所示。

众所周知，对于具有概率密度函数p、均值y和标准差σ的一般正态分布，累积分布函数（c.d.f.）是...
```math
c_k = \frac{1}{2}\left [ 1+erf\left ( \frac{l_k-y}{\sigma \sqrt{2} }  \right )  \right ]
```
其中
```math
erf(x) = \frac{2}{\sqrt{\pi } }\int_{0}^{x}e^{-t^2}
```
图2b显示了与图2a中的概率密度函数对应的累积分布函数。根据公式（2），我们知道
```math
\left\{\begin{matrix}
  & 1 - c_k > 0.5,  l_k < y\\
  & 1- c_k \le 0.5,lk \ge y
\end{matrix}\right.
```

如图2c所示，在 $`k=1,2,...,K-1`$ 的情况下，当 σ 为一个小的正实数时，1−c的曲线非常接近 $`p^{rank}`$ 的曲线。
```math
p^{rank}\approx 1 - c_k
```


因此，$`pT{rank}`$ 是标签分布学习的一个特例，其中分布是随着 $`σ→0`$ 逐渐累积的。也就是说，Ranking本质上是学习一个累积分布函数(c.d.f.)，而DLDL旨在学习一个概率密度函数(p.d.f.)。更一般地，我们有 $`c = Tp^{ld}`$，其中 $`T`$ 是一个转换矩阵，对于所有的 $`i≤j`$ ，$`T_{ij}=1`$，当 $`i > j`$ 时，$`T_{ij}=0`$。我们有 
```math
p^{rank}\approx 1 - Tp^{ld}
```

因此，Ranking编码和标签分布之间存在线性关系。标签分布编码 $`p^{ld}`$ 可以用不同的σ表示更有意义的年龄/吸引力信息，而Ranking编码 $`p^{rank}`$ 则不能。此外，DLDL更高效，因为只需要训练一个网络。

然而，正如之前讨论的，所有这些方法都可能不是最优的，因为训练目标与评估指标之间存在不一致。

<a id="3.3联合学习框架"></a>
### 3.3 联合学习框架 Joint Learning Framework
为了同时学习标签分布并输出期望值，在本节中我们提出了DLDL-v2框架。
<a id="3.3.1标签分布学习模块"></a> $``$
### 3.3.1 标签分布学习模块 Joint Learning Framework
为了利用标签分布学习的良好性质，我们将其集成到我们的框架中，形成一个标签分布学习模块。如图3所示，该模块包括一个全连接层、一个softmax层和一个损失层。该模块遵循[8]中的DLDL方法。
具体而言，给定输入图像x和相应的标签分布p，我们假设 $`f = F\left ( x;\theta  \right ) `$ 是CNN最后一层的激活，其中 $`\theta`$ 表示CNN的参数。一个全连接层通过以下方式将f转换为$`x \in R^K`$

```math
x = W^{T}f+b
```

然后，我们使用softmax函数将x转化为一个概率分布，即，
```math
\hat{p}_k = \frac{exp\left ( x_k \right ) }{ {\textstyle \sum_{t}^{}exp(x_t)} } 
```

在给定输入图像的情况下，标签分布学习模块的目标是找到参数θ、W和b，以生成与真实标签分布p相似的$`\hat{p}`$。

我们采用库尔巴克-莱布勒散度(KL散度)作为衡量真实标签分布和预测分布之间不相似性的度量。因此，我们可以定义一个训练样本的损失函数如下:
```math
L_{ld} = \sum_{k}^{}p_kln\frac{p_k}{\hat(p_k)}
```

<a id="3.3.2期望回归模块"></a> $``$
### 3.3.2 期望回归模块 The Expectation Regression Module
需要注意的是，标签分布学习模块只能学习一个标签分布，而不能回归一个精确的值。为了减少训练和评估阶段之间的不一致性，我们提出了一个期望回归模块，进一步调整预测值。如图3所示，该模块包括一个期望层和一个损失层。

期望层将预测分布和标签集作为输入，并输出其期望值。
```math
\hat{y} = \sum_{k}^{} \hat{p_k}l_k
```

其中pˆk表示输入图像属于标签lk的预测概率。给定一个输入图像，期望回归模块最小化期望值 $`\hat{y}`$ 和真实值 $`y`$ 之间的误差。我们使用l1损失作为误差度量，如下所示：
```math
L_{er} = \left | \hat{y}-y \right | 
```
其中 $`|·|`$ 表示绝对值。需要注意的是，该模块不引入任何新的参数。

<a id="3.3.3学习"></a> $``$
### 3.3.3 学习 Learning
给定一个训练数据集D，我们框架的学习目标是通过联合学习标签分布和期望回归来找到参数θ、W和b。因此，我们的最终损失函数是标签分布损失 $`L_{ld}`$ 和期望回归损失 $`L_{er}`$ 的加权组合：
```math
L = L_{ld} + L_{er}
```
其中λ是权重，用于平衡两个损失的重要性。把两个损失带入得到：
```math
L = -\sum_{k}^{}p_kln\hat{p}_k + \lambda\left |  {\textstyle \sum_{k}^{}\hat{p}_k}l_k - y  \right | 
```

我们采用随机梯度下降法来优化我们模型的参数。关于 $`\hat{p}_k`$ 的导数可以表示为：
```math
\frac{\partial L}{\partial \hat{p}_k} = \frac{p_k}{\hat{p}_k} + \lambda l_k sign\left ( \hat{y}-y \right )
```

对于任意的k和j，softmax函数（方程（8））的导数是众所周知的，如下所示：
```math
\frac{\partial \hat{p}_k}{\partial x_j} = \hat{p}_k\left (  \delta_\left ( k=j \right )  -\hat{p}_j\right  )
```

δ(k = j) 是当 k = j 时为 1，否则为 0。根据链式法则，我们有
```math
\frac{\partial L}{\partial x_j} = \left ( \hat{p}_j-p_j \right ) + \lambda sign\left ( \hat{y}-y \right )\hat{p_j}\l
i.e.,   \frac{\partial L}{\partial x} = \left ( \hat{p}-p \right ) + \lambda sign\left ( \hat{y}-y \right ) \hat{p_j}\
```

再次应用链式法则，我们可以轻松地得到关于W、b和θ的L的导数，如下所示：
```math
\frac{\partial L}{\partial W} = \frac{\partial L}{\partial x}f, \frac{\partial L}{\partial b} =\frac{\partial L}{\partial x},\frac{\partial L}{\partial \theta } = \frac{\partial L}{\partial x}W^T\frac{\partial F}{\partial \theta }
```

一旦学习到W、b和θ，任何新实例x的预测值yˆ可以通过在前向网络计算中使用方程（10）来生成。
```math
\hat{y} = \sum_{k}^{} \hat{p_k}l_k
```

<a id="3.4网络架构"></a>
### 3.4 网络架构 Network Architecture
考虑到模型的大小和效率，我们对VGG-16进行了以下四个方面的修改。VGG-16包含13个卷积(Conv)层，五个最大池化(Max-Pooling)层和三个全连接(FC)层，每个Conv层和FC层后面都跟着一个ReLU层。

首先，我们观察到三个FC层大约包含整个模型90%的参数。我们移除了所有的FC层，并添加了一个混合池化(Hybrid-Pooling)层，该层由一个MP层和一个全局平均池化(GAP)层构成。我们发现HP策略比单独使用GAP更有效。

其次，为了进一步减小模型大小，我们减少了每个Conv层中的滤波器数量，使其变得更加瘦削。

第三，批量归一化(Batch Normalization, BN)被广泛应用于最新的架构，如ResNet。因此，我们在每个Conv层后面添加了一个BN层，以加快网络的训练速度。

最后但并非最不重要的是，在HP层之后，我们添加了标签分布学习模块和期望回归模块，如图3所示。

由于我们设计的网络用于年龄/吸引力估计，并且其架构比原始的VGG-16更瘦削，我们将我们的模型称为ThinAgeNet或ThinAttNet，其压缩率为0.5，参数量为3.7M。我们还训练了一个非常小的模型，压缩率为0.25，我们称之为TinyAgeNet或TinyAttNet，参数量仅为0.9M。
<a id="4.实验Experiments"></a>
## 4.实验 Experiments
在这一部分中，我们使用开源框架Torch7在面部年龄和吸引力数据集上进行实验，以验证提出的DLDL-v2方法的有效性。所有实验都在NVIDIA M40 GPU上进行。为了再现本文中的所有结果，在论文被接受后，我们将发布源代码和预训练模型。

<a id="4.1实现细节"></a> $``$
### 4.1 实现细节  Implementation Details 
**预处理** 我们使用多任务级联卷积神经网络[45]对所有图像进行人脸检测和面部关键点检测。然后，基于这些面部关键点，我们将面部对齐到直立姿势。最后，所有的人脸都被裁剪并调整大小为224×224。在输入网络之前，所有调整大小的图像都要减去每个颜色通道的均值并除以标准差。
**数据增强** 在ChaLearn数据集中存在许多非控制的环境因素，如脸部位置、光照、多样化的背景、图像颜色（灰度和彩色）和图像质量。为了处理这些问题，我们对每个训练图像应用数据增强技术，使网络在每个训练周期中以原始图像的不同变化形式作为输入。具体而言，我们主要使用五种类型的增强方法对裁剪和调整大小的训练图像进行处理，包括随机水平翻转、随机缩放、随机颜色/灰度变换、随机旋转和标准颜色抖动。
**训练细节** 我们使用MS-Celeb-1M数据集的一个子集对深度CNN模型进行带有softmax损失的人脸识别预训练。一个问题是，在这个数据集中，一小部分身份有大量的图像，而其他身份只有很少的图像。为了避免身份之间的不平衡问题，我们剔除了图像数量低于阈值的身份。在我们的实验中，我们使用大约54K个身份的约5M张图像作为训练数据。

预训练完成后，我们移除网络的分类层，并添加标签分布学习和期望回归模块。然后，在目标数据集上进行微调。在公式（14）中，我们设置 $`\lambda = 1`$ 。有序标签向量被定义为 $`l = [l_{min}:\bigtriangleup l:l_{max}]`$ （MATLAB表示法）。对于年龄估计，我们设置$`l_{min} = 0`$，$`\bigtriangleup l = 1`$，$`l_{max} = 100`$。对于吸引力估计，我们设置$`l_{min} = 1`$和$`\bigtriangleup l = 0.1`$。由于SCUT-FBP和CFD数据集上有不同的评分规则，分别将$`l_max`$设置为5和7。每个图像的标签分布使用公式（1）生成。所有数据集中都提供了真实标签（年龄或吸引力分数）。然而，在ChaLearn15、ChaLearn16和SCUT-FBP中提供了标准差，但在Morph和CFD中没有提供。一般来说，标准差σ接近相邻标签之间的间隔是一个被讨论和分析过的良好选择，这在DLDL [8]中有所讨论。按照这个原则，我们分别在Morph中将σ设置为2，在CFD中将σ设置为0.5。所有网络都使用Adam进行优化，其中β1 = 0.9，β2 = 0.999，$`\epsilon = {10}^{-8}`$。初始学习率对于所有模型都是0.001，并且每30个epochs学习率会减小一个因子10。每个模型使用128个mini-batches进行60个epochs的训练。

**推断细节** 在推断阶段，我们将测试图像及其水平翻转的副本输入网络，并将它们的预测结果平均作为图像的最终估计值。

<a id="4.2评估指标"></a> $``$
### 4.2 评估指标  Evaluation Metrics
我们使用MAE（平均绝对误差）来评估面部年龄或吸引力估计的性能，其中ŷn和yn分别表示第n个测试图像的估计值和真实值。
```math
MAE = \frac{1}{N} {\textstyle \sum_{n=1}^{N}}  \left | \hat{y}^n - y^n \right |
```

此外，ChaLearn竞赛定义了一个特殊的度量（ε错误），如下所示：
```math
\epsilon-error = \frac{1}{N} {\textstyle \sum_{n=1}^{N}}  \left [ 1-exp\left ( -\frac{\left ( \hat{y}^n - y^n \right )^2 }{2\left ( \sigma ^n \right )^2 }  \right ) \right ] 
```
其中，ŷn和yn分别表示第n个测试图像的估计值和真实值。σn是第n个测试图像的标准差。

我们还按照[21, 13]的方法计算均方根误差（RMSE）和皮尔逊相关系数（PC），计算公式如下：
```math
RMSE = \sqrt{\frac{1}{N}\sum_{n=1}^{N}\left | \hat{y}^n - y^n \right |^2   } 
PC = \frac{\sum_{n=1}^{N}\left ( y^n - \\bar{y}  \right )\left ( \hat{y}^n - \\bar{\hat{y}^n} \right )   }{\sqrt{\sum_{n=1}^{N} \left ( y^n - \\bar{y}  \right )^2}\sqrt{\sum_{n=1}^{N}\left ( \hat{y}^n - \\bar{\hat{y}^n} \right )^2}  } 
```

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion










