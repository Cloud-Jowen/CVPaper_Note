[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  https://arxiv.org/pdf/2307.04570v2.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
由于基准测试过程中的不一致性，不同年龄估计方法之间的比较具有挑战性，这导致已发布结果的可靠性受到质疑。以往的研究声称使用专门方法在过去十年中取得了持续的性能改进；然而，我们的研究结果对这些说法提出了质疑。本文确定了当前使用的评估协议中存在的两个琐碎但持久的问题，并描述了如何解决这些问题。我们详细描述了我们的评估协议，并提供了使用该协议的具体示例。我们利用该协议对最先进的面部年龄估计方法进行了广泛的比较分析。令人惊讶的是，与面部对齐、面部覆盖、图像分辨率、模型架构或用于预训练的数据量等其他因素相比，这些方法之间的性能差异微不足道。我们利用获得的见解提出使用FaRL作为骨干模型，并展示其效率。结果强调了一致的数据预处理实践对于可靠且有意义的比较的重要性。我们将源代码公开发布。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
年龄估计在最近几年中引起了极大的兴趣。然而，对评估过程的更深入研究揭示了两个潜在问题。首先，大多数公共数据集没有标准化的数据划分定义，并且使用的划分很少公开发布，使得结果不可重复。其次，方法通常修改年龄估计系统的多个组件，这使得难以确定哪些修改导致性能提升。

我们专注于通过改变其最后一层或多分类器来适应一般架构的最新方法。虽然这看起来可能会受到限制，但需要注意的是，该领域提出的大多数方法都属于这一类（约70％）。通过比较只修改网络一小部分的方法，我们的目标是确保公平评估，因为其余设置可以保持相同。除了通常的类内性能之外，我们还评估了它们在不同数据集上的泛化能力，这是迄今为止年龄预测文献中被忽视的内容。令人惊讶的是，我们发现损失函数和决策层对结果的影响通常是最主要的区别不同方法的因素，与其他因素相比几乎没有影响。

本文的贡献：

• 我们展示了现有的年龄估计评估实践并没有提供一致性的结果，这给那些旨在推进前人工作的研究人员和那些努力找到最有效方法以应用到实践中的从业者带来了障碍。  
• 我们定义了一个合适的评估协议，对最先进的面部年龄估计方法进行了广泛的比较分析，并发布了我们的代码。  
• 我们表明，使用不同的决策层或训练损失所导致的性能差异要小得多，而其他预测流程的其他部分则会导致更大的性能差异。我们确定预训练使用的数据量是最具影响力的因素，并使用该观察结果建议将FaRL [30]用作骨干架构。我们在公开的年龄估计数据集上展示了其有效性。  


<a id="2.对当前评估实践的批评CritiqueofCurrentEvaluationPractices"></a>
## 2.对当前评估实践的批评 Critique of Current Evaluation Practices

<a id="2.1数据划分"></a>
## 2.1 数据划分 Data Splits
聚焦于年龄估计的论文通常使用多个数据集进行测试[1,4,20,21,23,24,29]，其中最常用的是MORPH [23]数据集。然而，这些论文之间的评估程序并不统一。例如，OR-CNN [21]将数据集随机分为两部分：80%用于训练，20%用于测试。没有提到用于模型选择的验证集。随机划分(RS)协议也用于[3、5、12、13、19、28]，但由于很少公开，因此具体的数据划分方式在研究之间有所不同。由于数据集中包含同一人的多张图片（许多在同一年龄拍摄），同一个个体可能同时出现在训练集和测试集中。这种重叠会引入偏差，导致评估结果过于乐观。使用随机划分时，数据泄漏的程度会有所不同，使得某些数据划分比其他数据划分更具挑战性。此外，这从根本上改变了整个设置；很少有人会在训练数据中部署年龄估计系统(这句话太绕口了)。因此，比较不同方法并确定哪种方法是基于已发表结果最有效的方法变得困难。

仅有部分论文[22, 27]意识到由划分策略引入的偏差，并通过实施主题独占 (SE) 划分来解决这个问题。这种方法确保一个人的所有图像都独占于 (i) 训练集、(ii) 验证集或者 (iii) 测试集中。

为了评估在MORPH数据集上随机划分 (RS) 的普遍程度，我们对自2013年以来在CVPR和ICCV上发表的所有关于年龄估计的论文进行了调查（见附录）。我们发现了16篇关注年龄估计的论文，其中有九篇使用了随机划分，两篇使用了SE，五篇使用了专门的划分方式，而三篇则未使用MORPH数据集。我们还对其他研究会议和期刊进行了调查，包括：IJCAI、BMVC、ACCV、IEEE TIP、Pattern Recognit. Lett.、Pattern Anal. Appl.，并找到了八篇有影响力的年龄估计论文使用了MORPH数据集。其中，有七篇使用了随机划分，一篇使用了专门的划分方式。

总体而言，我们发现只有约10%使用MORPH数据集的论文采用了SE协议。这一发现令人担忧，因为MORPH[23]是用于比较年龄估计方法最流行的数据集。其他数据集也未提供可靠的基准，因为标准化的数据划分仅适用于两个公开的年龄估计数据集：(i) ChaLearn Looking at People Challenge 2016 (CLAP2016) 数据集[1]，该数据集相对较小，仅包含不到8000张图像；(ii) Cross-Age Celebrity Dataset (CACD2000) [4]，该数据集具有嘈杂的训练注释，并非用于年龄估计。因此，仅使用这些数据集进行方法比较也是不令人满意的。其他流行的数据集，如AgeDB数据集[20]和Asian Face Age Dataset (AFAD) [21]，每个人都包含多个图像，需要进行SE分割。然而，它们缺乏得到学术界认可的数据分割，并且通常使用随机数据划分协议。因此，它们受到了与MORPH[23]相同的问题的困扰。

<a id="2.2流程组件"></a>
## 2.2. 流程组件 Pipeline Components
为了公平地比较多种方法，应该对它们使用相同的实验设置。当前最先进的年龄估计方法都遵循一个共同的处理流程，包括四个关键组件：（i）数据预处理，（ii）模型架构，（iii）决策层和损失函数，以及（iv）用于训练模型和评估性能的特定数据。尽管新颖的方法会引入不同的组件（iii），但它们经常同时改变多个组件，使得很难将性能改进归因于所声称的修改。

为了比较不同的损失函数，例如[3,10,12,13,16,17,21,22]，应该保持组件（i）、（ii）和（iv）恒定，同时变化组件（iii），这样可以分离出所选方法对性能的影响。这似乎是琐碎的，然而年龄估计领域大多数情况下忽视了这一点。此外，许多论文对其他组件只字不提，没有明确说明它们，使得未来的比较毫无意义。重要的是要质疑研究论文中报告的改进是否真正源于其所提出的新损失函数，还是可以归因于其他修改。我们强烈主张对每个组件进行单独处理，并精确描述实验设置。

在过去的十年中，引入了许多新的年龄估计方法，可以保证每年都有持续的性能改进。然而，受这些发现的启发，我们提出一个问题：已发布的年龄估计结果有多可靠？在第3节中，我们旨在建立一个合适的评估协议，并在第4节中使用它来可靠地评估方法[10,12,13,17,21,22,25]。图1展示了最先进方法在各自研究中报告的性能与我们提出的评估协议实施后所取得的结果之间的对比。

<img width="407" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/e974c147-9a74-4547-bef3-6607fdf2f209">  

(图1. MORPH数据集上现有文献所报道的和我们测量的年龄估计方法的平均绝对误差 (MAE) ↓，随时间变化的趋势。随机分割仍然是普遍的数据分割策略。文献中一致的性能提升被归因于专门用于年龄估计的损失函数。主题独占的数据分割策略很少被采用。在统一的主题独占数据分割和除了损失函数外的所有因素固定的情况下，所有评估方法产生类似的结果，未能实现随机分割所承诺的性能提升)

<a id="3.评估协议EvaluationProtocol"></a>
## 3.评估协议 Evaluation Protocol
我们发现两个微不足道但持久存在的问题，阻碍了对年龄估计方法进行可靠比较。在本节中，我们解决了关于一致数据分割的初始挑战。我们提供了明确的评估协议指南，以确保可复制和公平的评估。具体来说，该协议应建立一个可重现的方法，用于定义（i）训练和（ii）性能评估中使用的数据。在指定训练数据时，需要说明训练数据集是唯一的信息来源，还是模型预先使用了其他数据进行了预训练。此外，根据用于模型评估的数据可以将评估细分为数据集内和跨数据集的结果。我们将在下面描述如何在这些设置中评估模型。

**数据集内性能评估**  为了评估数据集内的性能，使用单个数据集来训练和评估年龄估计系统。在这种情况下，应该：（i）将数据集随机分割成主题独占的训练集、验证集和测试集1；（ii）在训练集上训练模型；（iii）在验证集上测量模型的性能；（iv）如果必要，返回到步骤（ii）并再次训练模型；（v）在测试集上评估模型的性能，然后（vi）发布测试集上的结果以及系统组件和使用的数据的详细描述。如果数据集中样本数量有限，可以通过步骤（i）创建多个数据分割的训练、验证和测试集。在此之后，迭代步骤（ii）到（v）n次，其中n是生成的数据分割数。建议在报告结果时同时展示平均测试性能和其标准差。

**跨数据集性能评估**  为了评估跨数据集的性能，上述评估过程中的步骤（i）中生成的数据分割来自多个数据集的集合，确保完整选择的数据集必须完全用于评估，有效构成指定的测试集。评估过程的其余步骤保持不变。

无论是数据集内还是跨数据集的情况，每个系统都需要仅对测试数据进行一次评估，并发布结果。所有先前的模型开发和超参数调整必须仅基于对验证集的结果。此外，应指出训练数据是否是用于训练的唯一信息来源，或者模型是否已经使用额外数据进行预训练。在后一种情况下，还应提供额外数据的详细描述及其利用方式。

<a id="4.比较方法分析ComparativeMethodAnalysis"></a>
## 4.比较方法分析 Comparative Method Analysis
本节应用评估协议来比较最先进的年龄估计方法。我们保持一致的预处理流程、模型架构和数据集，同时有选择地改变决策层和损失函数，以纳入[10、12、13、17、21、22、25]等重要作品中提出的修改。

<a id="4.1方法"></a>
### 4.1 方法 Methodology
**数据集** 我们使用了7个数据集进行评估: AgeDB [20]、AFAD [21]、CACD2000 [4]、CLAP2016 [1]、FG-NET [15]、MORPH [23]和UTK-Face [29]。我们还利用IMDB-WIKI数据集 [24]进行预训练(见附录)，该数据集的干净标签来自FrancandCˇech[11]。

**数据划分** 对于CLAP2016和CACD2000数据集，我们使用数据集作者提供的单一数据划分。对于其余数据集，我们创建了五个主题独占(SE)的数据划分。为了生成划分，我们将数据集划分为60%用于训练、20%用于模型选择(验证)和20%用于评估模型性能(测试)。此外，我们确保每个分区具有相同的年龄分布。由于其规模较小，我们仅使用FG-NET进行评估。我们将我们的数据拆分公开。

**模型架构和权重初始化**  我们使用ResNet-50 [14]作为骨干网络架构。我们始终从相同的初始化开始训练方法。我们在实验中使用了三种初始化方式：（i）随机初始化，（ii）在ImageNet上预训练的权重（TorchVision的IMAGENET1K V2），（iii）在ImageNet上预训练的权重，并在IMDB-WIKI（年龄估计）上进一步进行交叉熵预训练。在预训练之后，模型的最后一层被替换为特定于所需方法的层。然后，在下游数据集上对模型进行微调。值得注意的是，对于基线的交叉熵方法，我们在微调之前也替换了最后一层。这确保了实验设置与其他方法完全相同。

**训练细节**  我们使用带有参数β1 = 0.9、β2 = 0.999的Adam优化器。对于在IMDB-WIKI数据集上的预训练，我们将学习率设置为α = 10−3，并总共训练100个epochs。对于在其余数据集上的微调，我们将学习率降低为α = 10−4，并训练模型50个epochs。我们使用批量大小为100。根据验证集上计算的MAE指标选择最佳模型。在训练过程中，我们使用两种数据增强方式：（i）水平翻转，和（ii）裁剪出边界框的80%至100%部分并将其调整为模型输入形状。我们承认，通过额外的超参数调整，模型的性能可能会得到改善。然而，我们的训练参数是合理的，并且可以直接进行方法比较。

**预处理**  我们使用Deng等人开发的RetinaFace模型进行人脸检测和面部关键点检测。我们完整地覆盖了面部区域，即图像涵盖整个头部。我们将图像调整为256×256像素的分辨率，并对图像的像素值进行标准化处理。为此，我们从ImageNet [7]上计算的颜色通道的均值和标准差中减去均值并除以标准差。有关预处理流程的详细信息和选择背后的原因，请参见附录部分。

<a id="4.2结果"></a>
### 4.2 结果 Results
我们使用测试数据计算的平均绝对误差(MAE)作为性能指标。为了确定是否有任何一种方法始终比其他方法更好，我们采用Demsˇar [6]所描述的Friedman检验和Nemenyi关键差异检验。测试中使用的主要统计量是在多个数据集上计算的方法的平均排名(1表示最佳)。然后利用平均排名的差异来决定一种方法是否显著优于其他方法，或者改进是否由随机性引起(零假设)。我们使用显著性水平(p值)为α=5%。

**数据内表现** 在表6中可以看到数据内的性能结果，用灰色背景突出显示。通过使用Friedman检验和Nemenyi检验，我们可以得出结论，在预训练情况下，使用任何方法都没有显著优于交叉熵的结果。换句话说，我们没有观察到任何方法对标准方法的性能有系统性改进。

当从随机初始化开始时，我们注意到使用单峰损失[17]进行训练往往不稳定。在评估中排除单峰损失[17]之后，我们应用了Friedman检验和Nemenyi检验。结果表明，OR-CNN [21]、DLDL [12]和平均-方差损失 [22]相对于交叉熵表现出显著的性能改进。在数据有限的情况下，无法进行预训练，因此建议使用上述方法之一。在进行IMDB-WIKI预训练的情况下，每种方法的平均排名(1表示最佳)是：(i) 交叉熵：3.50，(ii) OR-CNN [21]：3.83，(iii) DLDL [12]：2.67，(iv) DLDL-v2 [13]：3.92，(v) SORD [10]：3.00，(vi) 平均-方差[22]：5.92，(vii) 单峰[17]：5.17。

**跨数据集泛化** 在未使用其进行训练的数据集上评估模型的性能得到了跨数据集的结果，如表6所示。例如，对在MORPH上进行训练的模型在所有其他数据集上进行评估。对于所有方法来说，跨数据集的性能(不出所料)明显低于数据内的性能。使用Friedman检验和Nemenyi检验，我们可以得出结论，在进行预训练的情况下，无论是使用哪种方法[10, 12, 13, 17, 21, 22]还是交叉熵，在泛化能力方面没有显著差异。在进行IMDB-WIKI预训练的情况下，每种方法在跨数据集性能方面的平均排名(1表示最佳)是：(i) 交叉熵：4.42，(ii) OR-CNN [21]：3.35，(iii) DLDL [12]：3.62，(iv) DLDL-v2 [13]：3.93，(v) SORD [10]：3.40，(vi) 平均-方差[22]：4.47，(vii) 单峰[17]：4.81。

当在与其训练集不同的数据集上进行评估时，这些方法都表现不佳。在训练集为UTKFace或CLAP2016时，获得了最佳的跨数据集结果。在AFAD或MORPH数据集上训练的模型则显示出最差的性能。这种差异可以归因于UTKFace和CLAP2016具有更广泛的图像范围，使它们能够有效地推广到其他数据集。相反，MORPH或AFAD数据集的多样性有限，例如，AFAD主要包含亚洲人种的图像，而MORPH约80%的个体由非裔美国人组成，这导致了知识转移的困难。当将在MORPH数据集上训练的模型应用于其他年龄估计数据集时，性能显著下降，这凸显了不仅仅依赖MORPH数据集作为年龄估计基准的重要性。为了确保对不同方法进行可靠评估，从其他数据集中获取结果至关重要。

<a id="5.组件分析"></a>
## 5.组件分析 Component Analysis
在本节中，我们分析了骨干架构和数据准备流程对模型性能的影响。在修改系统组件时，我们将所有其他组件保持默认设置，即在第4节中提到的交叉熵方法。我们利用这些观察来提出一个使用FaRL [30]骨干架构的强大基线年龄估计模型。

<a id="5.1模型架构"></a>
## 5.1 模型架构 Model Architecture
在年龄估计文献中可以找到多种不同的骨干架构。在这些架构中，VGG16 [10,13,17,22,27,28]和ResNet-50 [2,3,19]是最常见的选择。我们评估了架构选择对结果的影响，并在表格5中展示了我们的发现。我们观察到，模型的选择对性能的影响比年龄估计方法本身的选择更为显著。

<a id="5.2数据准备流程"></a>
## 5.2 数据准备流程 Data Preparation Pipeline
年龄估计模型只需要图像中特定的区域，即人脸作为输入，而不是整个图像。然而，这个选择过程对模型性能的影响事先并不清楚。此外，用于年龄估计的面部图像在尺度和分辨率上可能存在差异，因为它们来自不同的来源，需要将它们调整为统一的分辨率。在本节中，我们研究了上述数据准备流程对年龄估计模型性能的影响。

**面部对齐** 许多研究缺乏对其面部对齐过程的解释。其他研究仅仅提及使用面部关键点进行对齐。为了评估是否需要标准化的对齐方法来公平比较多种方法，我们采用了三种不同的对齐过程，并评估其对模型性能的影响。首先，我们 (i) 不进行对齐，而是使用面部检测模型提出的边界框作为最简单的方法。其次，我们 (ii) 使用提出的边界框，但将其旋转以水平对齐眼睛。最后，我们使用一种对齐程序，该程序规范了旋转、位置和比例，并在附录中进行了描述。图2展示了这些面部对齐方法的可视化表示。使用不同对齐程序训练的模型的性能如表1所示。当处理像AFAD这样已经进行预对齐的数据集时，我们观察到对齐程序 (iii) 与简化的变体 (i) 或 (ii) 相比，没有显著改进。在采用标准条件收集的数据集（如MORPH数据集）上获得了类似的结果。然而，当处理AgeDB和CLAP2016等真实环境中的数据集时，我们发现对齐程序 (iii) 相对于简化方法能够带来明显的改进。有趣的是，在也包含真实环境图像的UTKFace数据集上，仅旋转提出的边界框的方法 (ii) 相对于方法 (iii) 能够取得更好的结果。总的来说，各种对齐程序之间的差异并不重大。因此，可以认为任何有效地规范化面部位置、旋转和比例的面部对齐技术都会产生可比较的结果。

![image](https://github.com/user-attachments/assets/0c2c6952-0dd3-4922-9e3d-5df7e8146942)  
(图2:使用FG-NET数据集的平均脸比较不同对齐方法。 )

![image](https://github.com/user-attachments/assets/7be9113b-8d55-4a3c-9569-68dc95089a9e)

(表1。不同面部对齐的ResNet-50模型的MAE↓。这些模型是在IMDB-WIKI上预训练的。 )



**面部覆盖** 虽然面部对齐定义了面部gt的位置、方向和比例，但图像中可见的面部范围也需要指定。我们称此概念为面部覆盖。它测量在图像中显示了多少面部，并且可以从最小覆盖（仅显示眼睛和嘴巴）到完全覆盖（整个头部可见）进行变化。确定完全面部覆盖与最小覆盖之间的最佳折衷方案并不明显。完全面部覆盖提供了全面的面部视图，允许年龄估计算法考虑更广泛的面部线索。另一方面，部分覆盖可能有助于减少过拟合，通过消除无关的面部线索和具有高方差的特征。为了演示各种面部覆盖水平，请参阅图3。面部覆盖的概念在年龄估计文献中得到了有限的关注。因此，在以前的研究中使用的面部覆盖程度只能从这些作品中的图像中推断出来。例如，Berg等人似乎采用的是最小覆盖，显示出比仅仅眼睛和嘴巴稍多的内容。大多数其他工作 [3, 13, 14, 18, 22, 28] 倾向于采用部分覆盖，其中大部分脸，包括下巴和额头，是可见的，但不是整个头和头发。Pan等人的作品 [23]、Rothe 等人的作品 [25] 和 Zhang 等人的作品 [29] 中展示了整个头部。

![image](https://github.com/user-attachments/assets/88b485dd-dfac-4668-bbbd-1e7ee8171f7a)  
(图3。使用FG-NET数据集的平均脸比较不同面部覆盖水平。 )

不同覆盖水平的模型性能如表2所示。一般来说，完全面部覆盖，即在输入模型中包括整个头部，对大多数数据集都取得了最佳结果。然而，对于AFAD和MORPH数据集，部分覆盖表现更好。值得注意的是，AFAD数据集中包含预处理图像，这些图像无法捕捉到整个头部。因此，在使用这个数据集时，使用完整的面部覆盖会导致出现黑条，并且人脸的有效像素分辨率降低。然后可以预期增加面部覆盖会带来较差的结果。最小的覆盖范围仅限于眼睛和嘴巴以上的面部区域,始终表现最差。在充分的像素分辨率下，全脸覆盖的表现最佳。

![image](https://github.com/user-attachments/assets/9fed90fb-13d5-4705-8fc8-f47425a67c0f)  
(表2。不同面部覆盖范围的ResNet-50模型的MAE↓。这些模型是在IMDB-WIKI上预训练的。)

**输入分辨率** 为了研究输入分辨率对年龄估计的影响，我们使用了所有数据集上的多个分辨率进行实验：具体来说，分别是256×256、128×128和64×64像素。结果如表3所示。我们的发现表明，在所有数据集中，图像分辨率的增加始终导致模型性能的改善。因此，最佳性能是在256×256像素分辨率下实现的。  

![image](https://github.com/user-attachments/assets/1e56bf2e-a0ef-4f6a-ab4a-a7399e740306)  
(表3。不同图像分辨率的ResNet-50模型的MAE↓。这些模型是在IMDB-WIKI上预训练的。 )

在文献中，可以找到从60×60到256×256像素的各种分辨率，其中新的工作倾向于使用更大的分辨率图像。由于分辨率的增加可以直接观察到提高结果；并且随着年份的增加而增加；很难说新提出的算法是否更好，或者它们是否由于使用更高分辨率的图像而表现得更好。  

**输入变换** 最后，我们研究了林等人提出的输入变换 [19] ，该方法涉及将人脸图像转换为tanh极坐标表示。这种方法在面部语义分割中表现出显著的性能改进。然后，林等人修改网络进行年龄估计，并报告了令人印象深刻的结果 [20] 。我们探索了应用这种变换对年龄估计的好处。然而，我们的发现表明，与基线相比，这种变换并没有改善结果，如表4所示。因此，我们认为林等人观察到的改进的年龄估计性能并不来自使用不同的表示，而是来自预训练于语义分割或他们的模型架构。

![image](https://github.com/user-attachments/assets/81377597-439f-4e40-80ce-81b12269a56a)   
(表4。不同输入变换的ResNet-50模型的MAE↓。这些模型是在IMDB-WIKI上预训练的[26]。 )

<a id="5.3FaRLBackbone"></a>
## 5.3 FaRLBackbone  
我们观察到，对决策层和损失函数的调整对最终模型性能的影响很小。相反，在修改预测管道中的其他组件时会出现较大的性能差异。值得注意的是，预训练数据似乎是最具影响力的因素。根据这个见解，我们不建议创建一个专门用于增强年龄估计系统的损失函数。相反，我们利用郑等人提出的FaRL主干[31]，使用ViT-B-16模型。FaRL模型通过结合(i)图像文本对的对比损失和(ii)遮挡图像块的预测进行训练。训练在包含面部图像（5亿）的LAION图像文本对数据集上进行。我们保留了由FaRL提取出的特征表示，而没有改变模型的权重。 我们选择使用 FaRL 的决定完全是基于其所包含的大量预训练数据，而不是背后的具体特征。可以使用相同的方法训练不同的图像编码器。但是，由于训练此类模型的成本，我们选择使用可用的FaRL ViT-B-16主干。我们在FaRL提取特征上使用简单的多层感知机（MLP），包括两个具有每个神经元512个神经元的层，并且随后是ReLU激活。交叉熵用作选择损失函数。对于每个下游数据集，我们预先在IMDB-WIKI上训练MLP或将其初始化为随机权重。根据下游数据集上的验证损失，我们选择首选选项。与之前一样，在对下游数据集进行微调之前，我们将替换最终层。

这个直接修改在AgeDB、CLAP2016和UTKFace数据集上表现优于其他模型。它还在AFAD中取得了更好的结果，在CACD2000中与其它模型的性能相当，但在MORPH中的表现较差。应用FN测试表明，该模型在内部数据集评估和跨数据集评估中均具有统计学意义的改进，见表6。我们归因于FaRL在MORPH上的较差表现是由于LAION[27]和MORPH[24]图像分布的巨大差异。因为我们没有对FaRL[31]的特征表示进行微调，因此有可能在其他数据集中学习到的表示优于LAION但不足于MORPH。 

![image](https://github.com/user-attachments/assets/2ce193ba-5bef-4e8f-8b35-d4633aec595d)
(表6。ResNet-50模型的内部数据集和跨数据集平均绝对误差（MAE）↓。标记为初始化：IMDB表示模型使用ImageNet权重进行初始化，然后在IMDB-WIKI上使用交叉熵训练，并且最后在下游数据集上微调。Imag.表示使用预训练的ImageNet权重进行初始化。Rand.表示随机初始化。 )

我们并不声称这个模型是最终解决方案，但使用 FaRL 主干网络所取得的结果以及我们公开的实现提供了一个稳健且直接的基准，以便与未来的方法进行比较。

<a id="6.讨论与总结"></a>
## 6.讨论与总结 Discussion and Conclusions
本文旨在建立一个公平的比较框架，用于评估各种年龄估计方法。我们对七个不同的数据集进行了全面分析，包括AgeDB [21]、AFAD [22]、CACD2000 [4]、CLAP2016 [1]、FG-NET [16]、MORPH [24] 和UTK-Face [30] ，并根据它们的平均绝对误差 (MAE) 对模型进行比较。为了确定任何方法是否优于其他方法，我们使用了Friedman检验和Nemenyi关键差异测试。在预训练模型时，我们没有观察到使用专门设计的用于年龄估计的损失函数所带来的统计学上显著的改进。通过随机初始化模型，在小数据集上观察到了一些超过基线交叉熵的方法。具体来说，对于Mean-Variance损失 [23]、OR-CNN [22] 和DLDL [13] 。这些改进可以归因于这些方法提供的隐式正则化。 

先前发表的结果报告了随着时间的推移连续性能改进（如图1所示）。我们的发现挑战了这些声明。我们主张，所报道的改进可以归因于随机数据划分策略或超参数调整以实现最佳测试集性能。对数据准备管道的分析表明，面部覆盖范围或输入分辨率等其他因素比年龄估计特定损失函数的选择对结果的影响更大。基于这些发现，我们使用FaRL [31] 模型作为年龄估计的基础，并证明其有效性。总结如下： 

• 我们表明现有的年龄估计评估实践无法提供对最新方法的一致比较。我们定义了一个适当的评估协议，以解决这个问题。
• 我们表明，近年来年龄估计结果的改进不能归因于在[10、13、14、18、22和23]中引入的专业化损失函数，如文献所声称。 
• 通过分析年龄估计管道的不同组件，我们构建了一个使用FaRL [31]主干的预测模型，并证明了它的有效性。 
• 为了促进可重复性并简化未来的比较，我们已将我们的实现框架和精确的数据划分公开发布。 






