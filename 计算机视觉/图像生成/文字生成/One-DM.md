# One-DM: One-Shot Diffusion Mimicker for Handwritten Text Generation

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.方法 Method**](#3.方法Method)  
&emsp;[**3.1**](#3.1)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  https://github.com/dailenson/One-DM  
论文链接：  https://arxiv.org/pdf/2409.04004

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
现有的手写文本生成方法通常需要超过十份的手写字体作为风格参考，但在实际应用中，用户更倾向于使用单个参考样本的手写生成模型，以提高便利性和效率。这种方法被称为“一次生成”，显著简化了过程，但因其从单个样本准确捕捉书写者风格的难度较大，尤其是当提取字符边缘的精细细节时，存在一定的挑战性，尤其是在稀疏前景和不希望的背景噪声之间。为了应对这一问题，我们提出了一种名为“One-shot Diffusion Mimicker”（One-DM）的方法来生成仅需一个参考样本即可模仿任何书法风格的手写文本。受事实启发，即个体样本中的高频信息往往包含独特的风格模式（例如，字符倾斜和字母连接），我们开发了一个新颖的风格增强模块，通过将单个样本中的高频成分纳入其中来改进风格提取。然后，我们将风格特征与文本内容融合为合并条件，引导扩散模型生成高质量的手写文本图像。广泛的实验表明，我们的方法可以在多个语言中成功地使用单个样本进行手写文本生成，并且在使用超过十个样本的情况下优于先前的方法。我们的源代码可在https://github.com/dailenson/One-DM 上获得。  

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
在数字时代，手写文本生成将传统的个性化书写与自动过程的效率相结合，提供了一个数字化格式来保存个人手写的原汁原味。这项任务旨在自动产生不仅对应特定文本内容而且模仿给定范例作者书写的风格的手写文本图像（例如，字符倾斜、草书连接、笔画厚度和墨水颜色）这为手部有缺陷的人提供了极大的便利，也促进了手写体设计过程的加速。  

在过去的文献中，已经有一些关于手写文本生成的研究。其中一些研究使用了对抗生成网络（GAN）来实现这一目标。例如，ScrabbleGAN[13]利用随机噪声作为样式输入，并基于字符级别的标签对内容输入进行条件设置，从而实现了具有随机采样样式的手写单词合成。最近的一项研究表明，去噪扩散概率模型（DDPM）等扩散模型[37, 50, 66]甚至可以比GAN产生更高质量的图像生成结果[11]。这激发了一些尝试，如WordStylist[44]、GC-DDPM[12]和CTIG-DM[70]，它们试图将去噪过程与固定的作者ID联系起来，以生成具有可控风格的手写文本图像。然而，这些方法的主要限制在于它们无法模仿未见过的作者的手写风格[12,13,44,70]。

要模仿任何给定的书写风格，一些以前的方法（例如 [5、27 和 46]）需要用户提供几个样本作为样式参考。它们使用一个样式编码器从给定的样本中提取书写风格，从而为生成样本提供了灵活的控制。然而，传统的少量样本生成流程不方便、效率低且耗时，如图 1 所示。因此用户更倾向于仅需单个样本作为样式参考的一次性生成方法。我们的目标是研究具有重要实际价值的更具挑战性的一次性生成任务，并努力实现高质量的手写文本图像生成，以满足所需的内容和风格。 

![image](https://github.com/user-attachments/assets/1f9eeb13-2fb4-4e5b-9219-7a465f07027b)  
(图1：单次和少量手写文本生成方法之间的用户体验比较。它揭示了单次设置导致更好的用户体验。)

单次生成任务的主要挑战在于准确地从仅有的一个风格参考图像中提取用户的书写风格。如图2所示，字符作为抽象符号通常只占参考图像的很小一部分。此外，参考图像往往包含嘈杂的背景信息，这在提取个人书写风格时是一个很大的障碍。先前的一次性生成方法[9,14,15]简单地遵循少量样本方法的架构设计，使用通用CNN编码器直接从单个样本中提取书写风格。然后将提取到的风格与文本内容结合并输入到CNN解码器中以生成所需的书写图像。这些方法由于其较差的样式提取能力，在模仿手写风格方面表现出有限的效果。

![image](https://github.com/user-attachments/assets/3ba38344-aa56-40f1-a39e-4cf47aa2bf27)  
(图2：手写文本样本及其对应的高频成分。我们发现，高频成分具有更明显的字符轮廓，并且清晰地展示了诸如字符倾斜和连笔连接等风格模式。)
(高频成分是怎么搞的)

为了应对上述挑战，我们的主要想法是利用样本的高频信息来增强手写风格的提取。如图2所示，高频信息涵盖了手写字体的整体轮廓，允许对诸如文本倾斜、字母间距和连笔等关键风格模式进行清晰观察。因此，将高频信息纳入有助于更有效地提取手写风格。

基于上述见解，我们提出了一种用于手写文本生成的单次扩散模仿器（One-DM），该模仿器同时受期望风格和任意内容的引导。具体而言，首先开发了一个增强风格模块来并行处理参考图像及其高频成分。考虑到参考图像通常包含背景噪声，我们设计了一个门机制以抑制背景噪声的流入。对于高频成分，例如显示更清晰风格模式的字符倾斜和连笔，我们采用对比学习框架 [28、36、67、68] 进一步获取具有区分性的风格特征，指导使用真实且多样化的风格进行手写文本合成。随后，从两个分支中提取出的风格特征与特定的内容原型在风格内容融合模块中适当地融合。最后，无缝集成的风格和内容特征作为条件输入，引导渐进式合成带有风格的手写文本图像的过程。值得注意的是，我们的 One-DM 只通过我们的风格增强模块有效地模仿了用户的手写风格，超越了少量样本方法，在产生高质量的风格化手写文本方面取得了更好的效果。

综上所述，我们的贡献如下：

-我们提出了一种用于生成样式化手写文本的新型扩散模型，该模型仅需要一个参考样本作为风格输入，并模仿其书写风格来生成任意内容的手写文本。  
-我们引入了参考样本的高频成分，以增强对手写字体风格的提取。所提出的风格增强模块可以有效地捕捉写作风格模式并抑制背景噪声的干扰。  
-在英语、中文和日语的手写数据集上进行了广泛的实验，证明我们的方法即使只使用一个风格参考也优于以前的方法，这些方法的参考数量是我们的15倍。  

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work

**手写文本生成** 手写文本通常以两种格式存储：在线轨迹形式或离线图像形式。在线手写生成方法[2，8，31，55，57，69]经常使用循环神经网络（RNN）[2，7，31，55-57，69]、transformer解码器[8]或扩散模型[40，48]来逐步生成书写轨迹。与在线方法不同，离线生成方法的优势在于不需要额外的轨迹监督信息，并且可以生成具有笔画宽度和墨水颜色的真实手写文本，这是在线方法无法实现的。

在深度学习中，先前的离线手写生成方法 [3、5、9、13、22、27、41、46] 主要依赖于生成对抗网络 (GAN)。早期工作 [3、13] 将词向量嵌入 [3] 或拼接字母token [13] 条件化为生成过程以合成手写单词图像。然而，这些方法难以灵活控制书写风格。因此，提出了基于 15 种风格参考的少量样本方法 [5、27、46]。例如，GANwriting [27] 使用卷积神经网络编码器 [18、62、63] 从几个样本中提取用户的书写风格，并将其与特定文本内容相结合以在所需风格下生成手写体。在其后续工作中 [26] ，合成样本被证明有助于训练更稳健的手写文本识别器。此外，HWT [5] 使用transformer编码器 [32、58] 从参考样本中提取丰富的风格模式，从而增强风格模仿性能。最近，VATr [46] 使用符号图像作为内容表示，使超出字符集的字符生成成为可能。

近期，单样本生成方法涌现[9、14、15]。尽管这些技术仅使用一个样本就可以模仿手写风格，但在样式化生成结果方面仍落后于少量样本的方法。此外，以前的手写生成方法[3、5、9、13-15、27]通常依赖复杂的语义表示，例如循环嵌入[3]和字母级token[5、9、13-15、27]。SLOGAN [41]从易于获得的印刷图像中提取文本内容。然而，由于其固定的作者ID，它在泛化到未见过的书写风格时面临着挑战。同样，一些基于扩散的方法[12、44、70]将样式ID作为去噪过程的条件，并且无法模拟它们之前没有遇到过的样式。相比之下，我们的One-DM可以从一种样式的样本中有效地获取样式信息，因此可以生成任意样式的手写体。由于空间限制，我们在附录A中讨论了更多相关的工作，包括通用图像生成的扩散方法、对比式方法[59]以及频率式方法[35、45]。

<a id="3.方法Method"></a>
## 3.方法 Method
**问题陈述** 我们旨在合成由文本内容和书写风格控制的手写文本图像。给定任意字符串 A 和来自作者 w<sub>s</sub> 的单个样式样本 I<sub>s</sub>，生成的手写单词图像 X<sub>s</sub> 应复制 w<sub>s</sub> 的独特书写风格，并保持 A 的内容不变，其中文本内容 $A = {a_i}_{i=1}^L$ 覆盖长度 L ，a<sub>i</sub> 不受任何限制地从字符集中选择。 

为了应对这一任务，我们引入高频信息来增强书写风格的提取。现有的方法 [5、9、14、15、27、46] 常常使用简单的卷积神经网络或transformer编码器直接处理样式图像，往往导致不理想的风格提取。相比之下，我们通过创新Laplacian高频率提取和门控机制引入一种新颖的One-shot diffusion mimicker（One-DM）。我们的One-DM能够有效地从单个参考中捕获样式特征，并抑制背景噪声。 

<a id="3.1总体方案"></a>
### 3.1 总体方案
我们的高级想法集中在从风格参考图像中提取高频信息以增强风格模式的提取。一种直接的方法是使用一个普通的transformer编码器来从风格图像及其相应的高频图像中提取风格特征。这种简单的解决方案遇到了两个主要问题：（1）缺乏有效的监督目标仍然使准确学习原始图像中的作者风格模式具有挑战性，（2）从原始图像中捕获到的风格特征仍保留有噪声背景， 

为了解决上述问题，我们开发了一种更有效的方法，如图3所示。我们的方法包括一个风格增强模块、内容编码器、风格内容融合模块和条件扩散模块。首先，我们使用拉普拉斯核作为高频滤波器从风格参考中提取高频成分。然后，两个并行的风格编码器同时从风格参考及其高频信息中提取相应的风格特征。由于风格参考中经常存在不希望有的背景噪声，因此我们设计了一个门机制来促进有信息风格特征的传输，并抑制噪声的传输。在高频成分中的风格模式相对干净且更加明显，有助于观察个体风格，例如字符倾斜。对于观察，我们提出一种对比学习目标，称为 LaplacianNCE ，以强制执行从高频成分中进行更具区分性的风格学习。 

![image](https://github.com/user-attachments/assets/cfd0fe81-2f1c-4c7d-a30c-e74653d9667b)
图3：所提方法的概述。风格参考首先通过高通滤波器提取其高频成分。随后，空间和高频风格编码器分别从风格参考及其高频信息中独立提取风格特征 F<sub>spa</sub> 和 F<sub>fre</sub> 。经过门机制过滤后的 F<sub>spa</sub> 与F<sub>fre</sub> 和内容特征 E 在融合模块中进行融合，并作为条件输入引导扩散生成过程。

关于内容指导，我们把给定的字符串 A 转换为统一字体图像，就像在 VATr [46]中一样。简而言之，Unifont的关键优势是它涵盖了所有Unicode字符，允许我们的方法将任何用户输入转换成相应的图像。我们进一步将渲染结果喂入一个结合ResNet18和Transformer编码器的内容编码器。这个过程首先使用ResNet18并行处理每个字符图像，然后将它们连接起来形成单词序列特征。Transformer编码器随后处理这些特征以提取具有全局上下文的信息内容特征 $E = {e_i}_{i=1}^L \in R^{L * c}$ ，其中c是通道维度。获得风格特征和内容指导后，我们无缝融合了它们，使用一种风格-内容融合模块。用融合的结果来引导条件扩散模型的去噪过程来合成所需的书写文本图像。去噪过程由损失函数L_rec监督。 

总结一下，我们方法的整体训练目标结合了两个损失函数：
```math
L = L_{lapNCE} + L_{rec}
```

<a id="3.2风格增强模块Style-enhancedModule"></a>
### 3.2 风格增强模块 Style-enhanced Module
我们提出了一种风格增强模块，通过将参考图像I<sub>s</sub>中的高频成分 $H_s \in R^{h×w×c}$ （其中 $I_s \in R^{h×w×c}$）整合到风格提取中，以提高清晰的风格模式。如图2所示，在像字符倾斜和形状连接这样的高频内容中，更清晰的风格模式被呈现出来。如图3所示，我们使用拉普拉斯核作为高频滤波器来从 I<sub>s</sub> 中提取 H<sub>s</sub> 。拉普拉斯核在不需要快速傅里叶变换（FFT）和频率域参数分离的情况下，擅长提取高频信息。然后，两个风格编码器 E<sub>spa</sub> 和 E<sub>fre</sub> 分别处理 I<sub>s</sub> 和 H<sub>s</sub> 。这种独立处理导致了独特的风格特征：来自 E<sub>spa</sub> 编码器的 $`F_{spa} = \left \{  f_{spa}^i\right \}_{i=1}^d \in R^{d×c} `$ 和来自 E<sub>fre</sub> 编码器的和 $`F_{fre} = \left \{  f_{fre}^i\right \}_{i=1}^d \in R^{d×c} `$，其中 $`d=h×w`$ 。虽然结构相同，但 E<sub>spa</sub> 和 E<sub>fre</sub> 不共享权重。然后，提出的 L<sub>lapNCE</sub> 迫使 E<sub>fre</sub> 编码器专注于从 H<sub>s</sub> 中提取有鉴别力的风格特征。设计了一个门机制，以选择性地过滤出参考样式特征中的背景噪声，仅允许有意义的样式模式通过。 

**Laplacian对比学习** 本文提出的 L<sub>lapNCE</sub> 的目标是引导高频风格编码器 E<sub>fre</sub> 从高频信息中学习更具有区分性的风格特征，因此我们提出将提取的属于同一作者的风格特征 F<sub>fre</sub> 拉近，而将来自不同作者的风格特征拉开距离。我们将我们的 L<sub>lapNCE</sub> 表示如下：
```math
L_{lapNCE} = - \frac{1}{N}\sum_{i \in M}^{}\frac{1}{\left |  P(i)\right | }\sum_{p \in P(i)}^{} log \frac{exp\left ( z_i · z_p  / \tau \right ) }{ {\textstyle \sum_{a \in A(i)}^{}exp\left ( z_i · z_p  / \tau \right )} }  
```
具体来说，$`i \in M = \left \{ 1...N \right \} `$ 是mini-batch中大小为 N 的任何元素的索引，$`A(i) = M `$ \ $`\left \{ i \right \}`$是与 i 不同的其他索引。Z<sub>i</sub> 是一个属于作者 w<sub>i</sub> 的锚样本，并且$`P\left ( i \right ) = \left \{ p \in A(i):w_p =w_i \right \}`$是它的内批正样本集，而$`A(i)`$ \ $`P(i)`$是它的负样本集。这里，$`z = Proj\left ( F_{fre} \right )`$ ，其中 Proj 是一个可学习的多层感知机（MLP），τ 是一个标量温度参数，·表示内积符号。 

**门机制** 如图2所示，参考图像中字符的笔画区域通常稀疏，并且背景噪声会干扰特征提取。为了应对这一挑战，我们提出了一种门机制来选择性地过滤样本信息 I<sub>s</sub> ，如图3所示。具体来说，提取出的样本风格特征 F<sub>spa</sub> 被输入到一个门层中，该层由可学习的全连接层和随后的Sigmoid激活组成，以获得相应的门单元 $`W = \left \{ w_i \right \}_{i=1}^d \in R^d `$。每个单元 w<sub>i</sub> 决定了对应 $`f_{spa}^i`$ 的通过率，在 w<sub>i</sub> 较大的情况下允许更高的通过率。这种设计有效地实现了在抑制多余背景噪声的同时提取出具有信息性的风格特征$`\hat{F}_{spa} = \left \{ \hat{f}_{spa}^i \right \}_{i=1}^{d}`$，其中 $`\hat{f}_{spa}^i = f_{spa}^i · w_i`$。 

<a id="3.3风格内容融合模块Style-contentFusionModule"></a>
### 3.3 风格内容融合模块 Style-content Fusion Module
在获得文本内容特征 E 和两个风格特征 $`\hat{F}_{spa}`$ 、F<sub>fre</sub> 后，我们整合所有特征到两个多头注意力机制中以引导扩散模型的去噪生成过程，如图3所示。具体来说，第一个交叉注意力模块使用文本内容E作为查询来识别样式参考中最相关的样式信息，并由此推断每个字符对应的样式属性。例如，如果文本内容是'a'，它优先搜索样式参考中的'a', 'b', 'd', 'g'等字符的相关样式特征，因为这些字符出现相似的循环结构，暗示着更多的可比样式属性。这个过程（图3中的交叉注意力）表示为： 
```math
O = Atten_1\left ( Q_1 = E,K_1=V_1=\hat{F}_{spa}+F_{fre} \right )
```
随后，我们通过简单地将O和E相加来获取内容和样式指导之间的初始融合嵌入。合并后的中间向量被用作自我关注机制中的查询、键和值，以促进信息的全面交互。最后，混合嵌入g作为扩散过程的条件。第二个多头注意力（图3中的自注意力）定义如下：
```math
g = Atten_2\left ( Q_2 = K_2 = V_2 = O + E \right )
```

<a id="3.4条件扩散模型ConditionalDiffusionModel"></a>
### 3.4 条件扩散模型 Conditional Diffusion Model
条件扩散模型 p<sub>θ</sub> 的目标是生成由获得的条件 g 引导的手写文本的真实图像。具体来说，如图3所示，在g的指导下，p<sub>θ</sub>执行一个去噪生成过程，从采样的高斯噪声 x<sub>T</sub> 开始，逐步去噪以获取所需的手写文本x0： 
```math
p_\theta \left ( x_0|g \right ) = \int p_\theta \left ( x_{0:T}|g \right )d_{x_1:T}, 
```
```math
p_\theta \left ( x_{0:T}|g \right )d_{x_1:T} = p(x_T)\prod_{t=1}^{T}p_\theta(x_{t-1}|xt,g),
```
```math
p_\theta(x_{t-1}|xt,g) = \mathcal{N}(x_{t-1};\mu_\theta(x_t,g,t),\sum_\theta(x_t,g,t)) 
```

去噪过程旨在学习如何逆向执行预先定义的正向过程，如DDPM [20] 中所述。 正向过程被建模为固定马尔可夫链，在此过程中，符合正态分布的噪声逐渐添加到 x<sub>t-1</sub> 以获得 x<sub>t</sub> 。 这可以数学表达如下：
```math
q(x_t|x_{t-1},g) = \mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)
```
其中噪声由方差计划 β<sub>t</sub> 表征。在训练过程中，对最大似然目标应用变分约束来引导生成过程从条件为g的标准高斯噪声 x<sub>T</sub> 中恢复 x<sub>0</sub> 。我们给出的训练目标如下： 
```math
\mathcal{L}_{rec} = \mathbb{E}_{t,q} \left \| \mu_t(x_t,x_0) - \mu_\theta(x_t,g,t) \right \|_2^2
```

其中，$`\mu_t(x_t,x_0)`$ 是后验 $`q(x_t|x_{t-1})`$ 的均值，具有闭式解。我们将在附录B中给出更多细节。
<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion
本文介绍了一种新颖的One-DM，用于手写文本生成，仅需要一个风格参考即可产生逼真的手写文本图像。我们通过将高频率成分从风格参考中集成到样式提取中来增强样式提取。对于具有明显样式模式的高频成分，我们采用拉普拉斯对比学习来捕获更多有鉴别力的样式特征。此外，门机制改进了从参考中转移信息特征的过程，减少了背景噪声。我们的One-DM在多个语言脚本中优于少量样本方法。未来，我们将探索One-DM在字体生成和矢量字体创建任务中的潜力。 









