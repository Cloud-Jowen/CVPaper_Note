# Squeeze-and-Excitation Networks

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.Squeeze-and-Excitation Blocks**](#3.Squeeze-and-ExcitationBlocks)  
[**4.模型和计算复杂度 Model and Computational Complexity**](#4.模型和计算复杂度ModelandComputationalComplexity)  
[**5.实施方案 Implementation**](#5.实施方案Implementation)  
[**6.实验 Implementation**](#5.实施方案Implementation)  
 


## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  https://github.com/hujie-frank/SENet  
论文链接：  https://arxiv.org/pdf/1709.01507v2.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
卷积神经网络是建立在卷积操作之上的，通过在局部感受野内融合空间和通道信息来提取信息特征。为了增强网络的表征能力，最近的一些方法表明增强空间编码的好处。在这项工作中，我们专注于通道关系，并提出了一种新颖的架构单元，我们称之为“Squeeze-and-Excitation”（SE）块，它通过明确地建模通道之间的相互依赖关系，自适应地重新校准通道特征响应。我们证明通过堆叠这些块，我们可以构建出在具有挑战性的数据集上表现非常优秀的SENet架构。至关重要的是，我们发现SE块能够在极小的额外计算成本下，显著提高现有最先进的深度架构的性能。SENet奠定了我们在ILSVRC 2017分类比赛中获得一等奖并将前5错误率降低到2.251%的基础，相对于2016年的获奖作品，实现了约25%的改进。代码和模型可在 https://github.com/hujie-frank/SENet 上找到。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
卷积神经网络（CNNs）已被证明是处理各种视觉任务的有效模型[21, 27, 33, 45]。对于每个卷积层，都会学习一组滤波器，以表达沿输入通道的局部空间连接模式。换句话说，期望卷积滤波器通过在局部感受野内融合空间和通道信息来获得信息丰富的组合。通过堆叠一系列卷积层，交替插入非线性操作和下采样，CNN能够以全局感受野捕获具有强大图像描述能力的分层模式。最近的研究表明，通过显式嵌入学习机制来帮助捕获空间相关性，而无需额外的监督，可以改善网络的性能。Inception架构[16, 43]普及了这种方法之一，它显示出网络可以通过在其模块中嵌入多尺度过程来实现竞争性的准确性。更近期的工作则致力于更好地建模空间依赖关系[1, 31]并整合空间注意力[19]。

在这篇论文中，我们研究了架构设计的另一个方面——通道关系，引入了一种新的架构单元，我们称之为“Squeeze-and-Excitation”（SE）块。我们的目标是通过明确地建模卷积特征通道之间的相互依赖关系来提高网络的表征能力。为实现这一目标，我们提出了一种机制，使网络能够执行特征重新校准，通过这种机制，网络可以学习利用全局信息来有选择性地增强特定的通道特征。

SE构建块的基本结构如图1所示。对于任何给定的变换$` F_{tr}：X→U `$，其中$` X  \in R^{H^{'}×W^{'}×C^{'}} `$，$`U  \in R^{H×W×C}`$（例如，一个卷积或一组卷积），我们可以构建相应的SE块，以执行特征重新校准，具体操作如下。首先，特征U经过一个挤压操作，该操作在空间维度H×W上聚合特征图，生成一个通道描述符。这个描述符嵌入了通道特征响应的全局分布，使得网络的下层可以利用来自全局感受野的信息。然后进行激励操作，通过基于通道依赖关系的自门控机制学习每个通道的样本特定激活，来控制每个通道的激励。最后，对特征图U进行重新加权，生成SE块的输出，然后可以直接馈送到后续层中。  
![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/8eaf8579-e505-4965-a75d-7bc84d9a1ee5)  


一个SE网络可以通过简单地堆叠一系列SE构建块来生成。SE块也可以被用作架构中任何深度处原始块的即插即用替代品。然而，虽然构建块的模板是通用的，正如我们在第6.4节中所展示的，它在不同深度的角色会根据网络的需求进行调整。在早期层中，它学会以与类别无关的方式激发信息丰富的特征，增强共享的较低级表示的质量。在后续层中，SE块变得越来越专业化，并以高度特定于类别的方式响应不同的输入。因此，通过特征重新校准所进行的益处

可以通过简单堆叠一系列SE构建块来生成SE网络。SE块还可以作为原始块在架构的任何深度的即插即用替代品。然而，尽管构建块的模板是通用的，正如我们在第6.4节中所示，它在不同深度的角色会根据网络的需求进行调整。在早期层中，它学会以与类别无关的方式激发信息丰富的特征，增强共享的较低级表示的质量。在后续层中，SE块变得越来越专业化，并以高度特定于类别的方式响应不同的输入。因此，由SE块进行的特征重新校准所带来的益处可以在整个网络中累积起来。

设计新的CNN架构是一个具有挑战性的工程任务，通常涉及许多新的超参数和层配置的选择。相比之下，上面概述的SE块的设计是简单的，并且可以直接与现有的最先进的架构一起使用，这些架构的模块可以通过直接用它们的SE块进行加强替换。

此外，正如在第4节中所示，SE块计算轻量，并且只会对模型复杂性和计算负担产生轻微增加。为了支持这些说法，我们开发了几个SENet，并在ImageNet 2012数据集[34]上进行了广泛评估。为了证明它们的普适性，我们还展示了超出ImageNet范围的结果，表明所提出的方法不限于特定的数据集或任务。

使用SENets，我们在ILSVRC 2017分类竞赛中获得了第一名。我们的表现最佳的模型组合在测试集上实现了2.251%的top-5错误率。与前一年的冠军条目（top-5错误率为2.991%）相比，这代表了近25%的相对改进。

<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work
**深度架构** VGGNet [39] 和Inception模型 [43] 展示了增加深度的好处。批量归一化（Batch normalization，BN）[16] 通过插入单元来调节层输入，稳定了学习过程，从而改善了梯度传播。ResNet [10, 11] 通过使用基于恒等映射的跳跃连接展示了学习更深层网络的有效性。Highway网络 [40] 使用门控机制来调节快捷连接。对网络层之间连接的重新构造 [5, 14] 已被证明进一步改善了深度网络的学习和表示属性。

另一条研究方向探索了调整网络模块组件的功能形式的方法。分组卷积可用于增加基数（变换集的大小）[15, 47]。多分支卷积可以被解释为对这一概念的泛化，从而实现更灵活的操作符组合[16, 42, 43, 44]。最近，以自动方式学习的组合[26, 54, 55]已经显示出竞争性能。交叉通道相关性通常被映射为特征的新组合，可以独立于空间结构[6, 20]或者通过使用标准卷积滤波器[24]和1×1卷积联合进行。其中大部分工作集中在减少模型和计算复杂性的目标上，反映了一个假设，即通道关系可以被表述为实例-不可知函数与局部感受野的组合。相反，我们认为，为单元提供一种机制来明确地建模通道之间的动态、非线性依赖关系，利用全局信息可以简化学习过程，并显著增强网络的表示能力。

**注意力机制和门控机制** 广义上讲，注意力可以被视为一种工具，用于偏向将可用的处理资源分配给输入信号中最具信息量的组件 [17, 18, 22, 29, 32]。这种机制的好处已经在多个任务中得到验证，从图像的定位和理解 [3, 19] 到基于序列的模型 [2, 28]。通常，它与门控函数（例如softmax或sigmoid）和顺序技术结合使用 [12, 41]。最近的研究表明，它适用于诸如图像字幕生成 [4, 48] 和唇读 [7] 等任务。在这些应用中，它经常用于一个或多个代表高级抽象的层之上，以实现不同模态之间的适应性。Wang等人[46]介绍了一种强大的主干-掩膜注意力机制，采用了一个沙漏模块[31]。这个高容量单元被插入到深度残差网络的中间阶段。相比之下，我们提出的SE模块是一种轻量级的门控机制，专门用于以高效的方式建模通道之间的关系，并设计用于增强整个网络中基本模块的表征能力。

<a id="3.Squeeze-and-ExcitationBlocks"></a>
## 3. Squeeze-and-Excitation Blocks


<a id="4.模型和计算复杂度ModelandComputationalComplexity"></a>
## 4.模型和计算复杂度 Model and Computational Complexity
为了使提出的SE模块在实践中可行，它必须提供一种在模型复杂度和性能之间有效的平衡，这对于可扩展性非常重要。我们在所有实验中将缩减比例r设置为16，除非另有说明（更多讨论可以在第6.4节中找到）。为了说明该模块的成本，我们以ResNet-50和SE-ResNet-50之间的比较为例，其中SE-ResNet-50的准确性优于ResNet-50，并接近于更深的ResNet101网络（如表2所示）。ResNet-50需要在单次前向传递中使用约3.86 GFLOPs处理224×224像素的输入图像。每个SE模块在压缩阶段利用全局平均池化操作，在激发阶段使用两个小的全连接层，然后进行廉价的通道缩放操作。总体而言，SE-ResNet-50需要约3.87 GFLOPs，相对于原始的ResNet-50增加了0.26%。

在实践中，对于一个训练mini-batch包含256张图像，在ResNet-50上进行一次正向和反向传递需要190毫秒，而在SE-ResNet-50上需要209毫秒（这两个时间都是在一个拥有8个NVIDIA Titan X GPU的服务器上进行的）。我们认为，这代表了一个合理的开销，特别是由于现有的GPU库中全局池化和小内积运算没有被优化。此外，由于它对嵌入式设备应用的重要性，我们还对每个模型进行了CPU推理时间基准测试：对于一个224×224像素的输入图像，ResNet-50需要164毫秒，而SE-ResNet-50需要167毫秒。 SE模块所需的额外计算开销很小，但由于其对模型性能的贡献，这是合理的。

接下来，我们考虑所提出的模块引入的额外参数。它们全部包含在门控机制的两个全连接层中，构成了总网络容量的一小部分。更准确地说，引入的额外参数数量为：  

```math

\frac{2}{r} \sum_{s=1}^{S}  N_s \cdot C_s^2

```

其中，r表示缩减比例，S表示阶段数（每个阶段指的是在具有相同空间维度的特征图上操作的一组块），Cs表示输出通道的维度，Ns表示阶段s中重复的块数。相对于ResNet-50所需的约2500万参数，SE-ResNet-50引入了大约250万个额外参数，增加了约10%。其中，大部分参数来自网络的最后一个阶段，在这个阶段中激发操作涉及到最大的通道维度。然而，我们发现，可以以较小的性能成本（在ImageNet上<0.1%的top-1错误）移除SE模块的最后阶段，将相对参数增加降低到约4%，这在参数使用是一个关键考虑因素的情况下可能会很有用（请参阅第6.4节中的进一步讨论）。

<a id="5.实施方案Implementation"></a>
## 5.实施方案 Implementation
每个普通网络及其对应的SE版本在相同的优化方案下进行训练。在ImageNet上的训练过程中，我们采用了标准做法，对图像进行随机尺寸裁剪[43]至224×224像素（Inception-ResNet-v2和SE-Inception-ResNet-v2为299×299像素），并进行随机水平翻转。输入图像通过通道均值减法进行归一化处理。此外，我们采用了[36]中描述的数据平衡策略进行小批量采样。网络在我们的分布式学习系统"ROCS"上进行训练，该系统设计用于高效并行训练大型网络。优化过程使用带有动量0.9的同步SGD，并使用mini-batch大小为1024。初始学习率设置为0.6，每30个epoch减小10倍。所有模型从头开始训练100个epoch，使用[9]中描述的权重初始化策略。

在测试时，我们对验证集应用中心裁剪评估，从每个图像中裁剪出224×224像素，其中较短的边先调整为256（对于Inception-ResNet-v2和SE-Inception-ResNet-v2调整为352）。

<a id="6.实验Experiments"></a>
## 6.实验 Experiments
<a id="6.1ImageNet Classification"></a>
### 6.1. ImageNet Classification
ImageNet 2012数据集由128万张训练图像和5万张来自1000个类别的验证图像组成。我们在训练集上训练网络，并报告top-1和top-5的错误率。

**网络深度** 我们首先比较了不同深度的SE-ResNet和ResNet架构。表2中的结果显示，SE模块在不同深度上始终提高了性能，而计算复杂度的增加非常小。
值得注意的是，SE-ResNet-50在单一裁剪的top-5验证错误率方面达到了6.62%，超过了ResNet-50（7.48%）0.86%的错误率，并接近更深的ResNet-101网络（6.52% top-5错误率）的性能，而计算开销仅为后者的一半（3.87 GFLOPs对比7.58 GFLOPs）。这种模式在更大的深度下重复出现，SE-ResNet-101（6.07% top-5错误率）不仅与更深的ResNet-152网络（6.34% top-5错误率）相匹配，还超过了后者0.27%的错误率。图4显示了SE-ResNet-50和ResNet-50的训练和验证曲线（更多网络的曲线在附录中显示）。尽管应该注意到SE模块本身会增加网络深度，但它们以一种非常高效的方式增加深度，并且即使在扩展基础架构深度带来递减收益的阶段，它们仍然产生良好的回报。此外，我们可以看到，在不同深度的训练过程中，性能改进是一致的，这表明SE模块引起的改进可以与增加基础架构深度相结合使用。

**与现代架构的整合** 本部分研究了将SE模块与现代架构Inception-ResNet-v2和ResNeXt（使用32×4d设置）相结合的效果，这两种架构都在模块中引入了先前的结构。

我们构建了这些网络的SENet等效版本，SE-Inception-ResNet-v2和SE-ResNeXt（SE-ResNeXt-50的配置在表1中给出）。表2中的结果说明了当SE模块引入这两种架构时所带来的显著性能提升。特别是，SE-ResNeXt-50具有5.49％的top-5错误率，优于其直接对应物ResNeXt-50（5.90％的top-5错误率）以及更深的ResNeXt-101（5.57％的top-5错误率），后者具有几乎两倍的参数数量和计算开销。至于Inception-ResNet-v2的实验，我们推测裁剪策略的不同可能导致他们报告的结果与我们重新实现的结果之间的差距，因为在[42]中并没有明确他们原始图像的大小，而我们从相对较大的图像中裁剪出299×299区域（其中较短的边缘被调整为224×224或320×320）。SE-Inception-ResNet-v2（4.79％的top-5错误率）优于我们重新实现的Inception-ResNet-v2（5.21％的top-5错误率）0.42％（相对改进8.1％），以及[42]中报道的结果。

我们还评估了SE模块在非残差网络上的效果，通过对VGG-16 [39]和BN-Inception架构 [16]进行实验。由于深度网络很难优化 [16, 39]，为了便于从头开始训练VGG-16，我们在每个卷积层后添加了批量归一化层。我们对SE-VGG-16的训练采用相同的方案。比较结果如表2所示，展示了与残差架构中出现的相同现象。

最后，我们在两种典型的高效架构MobileNet [13]和ShuffleNet [52]上进行评估，结果在表3中显示，SE模块可以在计算成本最小增加的情况下显著提高准确性。这些实验证明，SE模块引起的改进可以与各种架构结合使用。此外，这个结果对于残差和非残差的基础都适用。

**ILSVRC 2017分类竞赛结果** SENets是我们参赛的基础，我们获得了第一名。我们的获奖作品由一小组使用标准的多尺度和多裁剪融合策略的SENets组成，在测试集上取得了2.251%的前5错误率。我们的一个性能出色的网络，称为SENet-154，是通过将SE模块与修改后的ResNeXt [47]相结合构建而成的（详细信息请参见附录），其目标是在较少关注模型复杂性的情况下达到最佳精度。我们在表4中将其与ImageNet验证集上表现最好的已发布模型进行了比较。我们的模型在使用224×224中心裁剪评估时，获得了18.68%的前1错误率和4.47%的前5错误率。为了进行公平比较，我们提供了一个320×320的中心裁剪评估，显示出对先前工作的显著性能改进。竞赛结束后，我们训练了一个输入尺寸更大的SENet-154，为320×320，在前1（16.88%）和前5（3.58%）错误指标下实现了更低的错误率。

<a id="6.2SceneClassification"></a>
### 6.2 Scene Classification
我们在Places365-Challenge数据集 [53] 上进行了场景分类的实验。该数据集包含了800万张训练图像和365个类别的36500张验证图像。相对于分类任务，场景理解的任务可以更好地评估模型良好泛化和处理抽象能力，因为它需要捕捉更复杂的数据关联并对更大程度的外观变化具有鲁棒性。

我们使用ResNet-152作为一个强大的基线来评估SE模块的有效性，并按照[37]中的训练和评估协议进行操作。表5显示了ResNet-152和SE-ResNet-152的结果。具体而言，SE-ResNet-152 (11.01% top-5错误率) 较ResNet-152 (11.61% top-5错误率) 实现了更低的验证错误率，这证明了SE模块在不同数据集上的良好表现。这个SENet超过了先前的最先进模型Places365-CNN [37]，在这个任务上的top-5错误率为11.48%。

<a id="6.3ObjectDetectiononCOCO"></a>
### 6.3 Object Detection on COCO
我们进一步使用COCO数据集 [25] 对SE模块在目标检测任务中的泛化能力进行评估。该数据集包含了8万张训练图像和4万张验证图像，我们按照[10]的方法进行操作。我们使用Faster R-CNN [33] 作为检测方法，并按照[10]中的基本实现进行操作。我们的目的是评估用SE-ResNet替代基础架构ResNet的好处，以便改进可以归因于更好的表示。表6分别显示了在验证集上使用ResNet-50、ResNet-101及其SE版本的结果。SE-ResNet-50在COCO的标准度量AP上比ResNet-50高出1.3%（相对提升5.2%），在AP@IoU=0.5上高出1.6%。重要的是，SE模块可以使更深层的架构ResNet-101获得0.7%的改进（相对提升2.6%）。

<a id="6.4AnalysisandInterpretation"></a>
### 6.4 Analysis and Interpretation
**减少比例** 公式（5）中引入的减少比例r是一个重要的超参数，它允许我们调整模型中SE模块的容量和计算成本。为了探究这种关系，我们对一系列不同r值的SE-ResNet-50进行了实验。表7的比较显示，性能并不随容量增加而单调提升。这可能是因为使SE模块过度拟合训练集的通道相关性。特别地，我们发现将r设置为16可以在准确性和复杂度之间取得良好的平衡，因此我们在所有实验中都使用了这个值。

**激励作用** 虽然经验上已经证明SE模块可以提高网络性能，但我们也想了解自门控激励机制在实践中是如何起作用的。为了更清晰地了解SE模块的行为，本节我们研究了SE-ResNet-50模型中的示例激活，并分析这些激活在不同类别和不同块上的分布。具体来说，我们从ImageNet数据集中抽取了表现出语义和外观多样性的四个类别，即金鱼、哈巴狗、飞机和悬崖（这些类别的示例图像显示在附录中）。然后我们从验证集中为每个类别抽取了50个样本，并计算每个阶段最后一个SE块（在下采样之前）中50个均匀抽样通道的平均激活，并将它们的分布绘制在图5中。作为参考，我们还绘制了1000个类别中所有类别的平均激活分布。

我们对激励作用做出了以下三点观察。首先，在较低层（例如SE 2 3），不同类别之间的分布几乎相同。这表明在网络的早期阶段，特征通道的重要性可能会被不同类别共享。然而有趣的是，第二点观察表明，在更深的层次，每个通道的价值变得更加具体于类别，因为不同类别对特征的判别价值有不同的偏好，例如SE 4 6和SE 5 1。这两点观察与之前研究中的发现[23, 50]一致，即较低层次的特征通常更加通用（即在分类的语境中与类别无关），而较高层次的特征具有更高的特异性。因此，表示学习受益于SE模块引起的重新校准，该模块能够自适应地促进特征提取和专门化，以满足需求。最后，我们观察到网络的最后一个阶段存在一种略有不同的现象。SE 5 2呈现出向饱和状态倾向的有趣趋势，其中大部分激活接近1，其余接近0。当所有激活值均为1时，此块将成为标准的残差块。在网络末端的SE 5 3（紧接着全局池化之前的分类器），在不同类别之间出现了类似的模式，只是尺度稍有变化（可以由分类器调节）。这表明SE 5 2和SE 5 3在为网络提供重新校准方面比之前的模块不那么重要。这一发现与第4节中的经验调查结果一致，该结果表明通过移除最后阶段的SE模块，可以显著减少总参数数量，而性能损失仅有轻微的。

<a id="7.结论Conclusion"></a>
## 7.结论 Conclusion
在这篇论文中，我们提出了SE模块，这是一种新颖的架构单元，旨在通过使网络能够进行动态的通道级特征重新校准来改进其表示能力。大量实验证明了SENets的有效性，在多个数据集上实现了最先进的性能。此外，它们还提供了一些关于以前架构在建模通道级特征依赖性方面的局限性的见解，我们希望这些见解对于其他需要强大的区分性特征的任务可能会有用。最后，SE模块引起的特征重要性可能对于相关领域（如网络剪枝压缩）也有帮助。

<a id="8.附录Appendix"></a>
## 8.附录 Appendix
<a id="A.TrainingCurvesonImageNet"></a>
### A. Training Curves on ImageNet
对于四种普通架构，即ResNet-152，ResNeXt-50，BN-Inception和Inception-ResNetv2，以及它们的SE对应架构，它们的训练曲线分别在图6中描绘出来，展示了SE块在整个训练过程中带来的改进的一致性。

<a id="B. Details of SENet-154"></a>
### B. Details of SENet-154
SENet-154是通过将SE块集成到修改版本的64×4d ResNeXt-152中构建而成的，这个版本是通过遵循ResNet-152的块堆叠方式来扩展原始的ResNeXt-101 [47]。除了使用SE块外，对设计和训练的更多不同包括：(a) 每个瓶颈建模块的第一个1×1卷积通道数量减半，以降低网络的计算成本，同时最小程度地降低性能。(b) 将第一个7×7卷积层替换为三个连续的3×3卷积层。(c) 用一个3×3步幅为2的卷积来替换下采样投影1×1步幅为2的卷积，以保留信息。(d) 在分类器层之前插入了一个dropout层（丢失比率为0.2），以防止过拟合。(e) 在训练过程中使用了标签平滑正则化（如[44]中所介绍的）。(f) 所有BN层的参数在最后几轮训练期间被冻结，以确保训练和测试之间的一致性。(g) 训练是在8台服务器（64个GPU）并行进行的，以实现大批量大小（2048）和初始学习速率为1.0。

<a id="C.FourClassExamples"></a>
### C. Four Class Examples
为了了解自激门激发机制在实践中是如何运作的，我们在“激发作用”章节中研究了来自SEResNet-50模型的示例激活，并检查它们在不同类别和不同块中的分布。我们从ImageNet数据集中抽取了四个展现语义和外观多样性的类别，分别是金鱼、哈巴狗、飞机和悬崖。这四个类别的示例图像如图7所示。详细的分析请参考该章节。

![image](https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/13103729-68af-4dfd-8e05-5d909fc6fd57)  
图7：在“激发作用”章节中使用的ImageNet四个类别的示例图像。




