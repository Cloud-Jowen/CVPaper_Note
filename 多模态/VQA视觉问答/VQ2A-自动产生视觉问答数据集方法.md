# All You May Need for VQA are Image Captions

[**相关链接**](#相关链接)  
[**0.摘要 Abstract**](#0.摘要Abstract)  
[**1.介绍 Introduction**](#1.介绍Introduction)  
[**2.相关工作 Related work**](#2.相关工作Relatedwork)  
[**3.网络结构**](#3.网络结构)  
[**4.实验 Experiments**](#4.实验Experiments)  
[**5.结论 Conclusion**](#5.结论Conclusion)  



## 相关链接
参考博文链接：  
参考视频链接：  
源码链接：  
论文链接：  https://arxiv.org/pdf/2205.01883.pdf

<a id="0.摘要Abstract"></a>
## 0.摘要 Abstract
视觉问答（VQA）得益于越来越复杂的模型，但在数据生成方面并没有享受到同等程度的参与。在本文中，我们提出了一种方法，通过利用现有图像标题注释的丰富性，并结合用于文本问题生成的神经模型来自动产生大量的 VQA 示例。我们证明了结果数据的质量很高。使用我们的数据训练的 VQA 模型在零样本准确率上比最先进的模型提高了两位数，并且达到了相同模型在人类标记的 VQA 数据上所缺乏的鲁棒性水平。

<a id="1.介绍Introduction"></a>
## 1.介绍 Introduction
视觉问答（VQA）是一项复杂的多模态任务，为了成功建模和评估，需要大量的注释数据，而这些数据不能自然地由现有的业务流程产生，就像翻译对齐注释（Guo等人，2018年）或图像alt文本注释（Sharma等人，2018年）那样。  

目前，开发有助于下游应用（如盲人、医学和教育领域）的鲁棒视觉问答系统的瓶颈似乎是缺乏数百万级的大规模图像-问题-答案训练三元组。对这些三元组进行手动注释成本高、耗时长，并且容易受到各种人类偏见的影响，而这些人类偏见很难解释清楚（Yuan, 2021）。此外，针对此类人工标注进行训练的视觉问答系统的脆弱性已被充分理解并记录在案（Agrawal et al., 2018；Kafla 和 Kanan, 2017）。

为了克服数据限制，我们转向了一个创造视觉问答示例的潜在来源：图像英语标题对（陈等，2015年；夏尔马等，2018年）。大规模图像标题数据集存在数百万（昌平诺等，2021）、数亿（拉德福德等，2021）甚至数十亿（贾等，2021）个例子。标题主要以陈述句的形式出现，例如“两只熊正在冰上躺着”。然而，将陈述性标题转换为视觉问答问题/答案对的任务仍然很大程度上未被探索。它需要根据标题文本自动诱导适合于视觉问答任务的答案候选项及其相应的问题（图1）。我们注意到将陈述形式转换为疑问形式加上答案似乎至关重要，因为有证据表明在声明语言数据上训练的视觉-语言模型不能成功地适应或转移“out-of-the-box”到视觉问答（王等，2021）。

<img width="218" alt="image" src="https://github.com/Cloud-Jowen/Paper_Note/assets/56760687/614e3959-e8da-4259-b97b-39a031e2e12f">

（图 1：给定一个英文标题（以及相应的图像），我们的 VQ2A 方法可以生成高质量的问题-答案对。这些图像-问题-答案三元组数据可以自动产生，并且以百万计的数据量使用，用于有效地训练视觉问答系统。）

在这篇论文中，我们探讨了使用神经模型进行文本问题生成和问答来自动创建数百万个VQA训练数据的方法。我们将此方法称为VQ2A，即带有答案验证的视觉问题生成。我们证明了在这种数据上训练的VQA模型，在完全没有接触过人类标注的VQA数据的情况下，表现出很高的零样本性能。我们的最佳模型在VQA2.0上的准确率为61.1％，在GQA上的准确率为52.1％，比以前的最佳零样本结果高出约15-17个百分点，并接近完全监督性能。此外，将我们生成的例子作为测试集，我们提供了进一步的证据，说明使用人工标注示例构建的VQA系统易受攻击，以及使用自动生成的VQ2A数据构建的VQA系统的鲁棒性。


<a id="2.相关工作Relatedwork"></a>
## 2.相关工作 Related work

<a id="2.1自然语言处理中的问题生成"></a>
### 2.1 自然语言处理中的问题生成 Question generation in NLP

问题生成（QG）是自然语言处理中一个活跃的研究课题。它被探索为一项独立的任务（Heilman 和 Smith，2009；Nema 等人，2019）、用于语言模型预训练的任务（Narayan 等人，2020），以及作为其他文本任务解决方案的组件，如问答（Al-berti 等人，2019；Puri 等人，2020）、信息检索（Mass 等人，2020；Gaur 等人，2021）和生成评估（Durmus 等人，2020；Wang 等人，2020；Honovich 等人，2021）。QG 的两个主要方向是基于模板的（Heil-man 和 Smith，2009；Lyu 等人，2021；Dhole 和 Manning，2020）和神经网络的，后者取得了最先进的结果（Alberti 等人，2019；Narayan 等人，2020）。

<a id="2.2计算机视觉中的问题生成"></a>
### 2.2 计算机视觉中的问题生成 Question generation in computer vision

计算机视觉中的问题生成旨在为给定的图像（或视频）生成关于其的视觉问题，这些问题可以是为了不知道答案而生成的问题（Mostafazadeh 等人，2016；Zhang等人，2017；Yang等人，2018；Uehara等人，2018；Krishna等人，2019），例如由人类来回答，或者为了帮助提高视觉问答任务（Kafla 等人，2017；Li等人，2018；Shah等人，2019；Xu等人，2021；Kil等人，2021；Akula等人，2021），例如额外评估和作为数据增强手段。此类 QG 模型通常基于 VQA 三元组训练数据，其语言复杂性往往有限，或者需要收集视觉 QG 数据（Mostafazadeh 等人，2016）。我们采取了不同的方法，利用在文本 QA 数据集上训练好的模型。

多个工作利用图像字幕或视频转录作为训练源（Ren等人，2015年a；Banerjee等人，2021年；Yang等人，2021年a；Lee等人，2021年）。这种方法从文本中自动生成问题-答案对，忽略视觉来源，并将其与相关的图像/视频组合以产生图像-问题-答案三元组。Banerjee等人（2021）提出了WeaQA，在其中他们使用改进的基于模板的方法在CO-COQA（Ren等人，2015年a）以及QA-SRL方法中从MSCOCO图像字幕（Chen等人，2015）生成问题，增强了解释性语言变化的改写和回译。Lee等人（2021）类似地从MSCOCO Caption衍生的问题-答案对训练VQA模型，但仅使用名词短语作为候选答案，专注于用它来验证生成的字幕，而不是VQA任务本身。Yang等人（2021年a）从教学视频ASR转录中生成问题-答案对，然后与相关视频配对。

在这项工作中，我们遵循这一方向，调查了在图像领域为视觉问答任务生成数据所需的覆盖范围。我们证明了基于神经网络的文本问题生成方法与标题相比具有更高的有效性。此外，与以前的工作不同，我们还探索了自动收集的域外图像文本数据源。

<a id="2.3图像问答中的迁移学习"></a>
### 2.3 图像问答中的迁移学习 Transfer learning for and in VQA

现有工作还探索了图像字幕生成任务与无需提问的视觉问答(VQA)任务之间的关系（第 2.2 节）。Fisch 等人 (2020) 预测视觉问题来执行图像字幕生成，即使用 VQA 数据作为额外监督并在推理后进行评估。Wu 等人 (2019) 生成与问题相关的图像字幕以帮助 VQA。Yang 等人 (2021b) 利用生成的标签和一些 VQA 示例提示 GPT-3 (Brown 等人, 2020) 回答基于知识的视觉问题。

证据表明，在大规模情况下进行的图像文本预训练有助于包括视觉问答在内的视觉语言任务（Lu等人，2019；Li等人，2019；Chen等人，2020；Tan和Bansal，2019；Su等人，2020；Lu等人，2020；Zhou等人，2020；Li等人，2020；Zhang等人，2021；Cho等人，2021；Wang等人，2021；Yuan等人，2021）。然而，这些方法在没有对下游 VQA 数据进行微调的情况下效果不佳（Wang等，2021）。此外，从预先训练好的图像文本模型中进行提示式的推断（Liu等，2021）并用于解决视觉问答仍然是一个开放的研究问题。相比之下，我们的方法直接处理训练数据，并显式地将其转换成可询问的形式。

我们的重点是在WeaQA（Banerjee等人，2021）中的零样本迁移设置，在训练期间没有可用的人工创建的VQA三元组。请注意，这里的“零样本”与（Teney和Hengel，2016）中使用的术语不同，在那里模型仍然可以访问人工创建的VQA三元组，但在测试时用未见过的问题进行评估。类似地，Chao等人。（2018年b）探索跨数据集的视觉问答，但他们只关注人类注释的数据以及转移方法。

<a id="3.网络结构"></a>
## 3.Textual Question Generation for VQA

我们研究了是否可以利用现有的图像文本资源自动生成视觉问答（VQA）注释，从而减轻或完全取代手动数据注释的需求。本文仅关注英语。为此，我们在第2.2节中遵循并改进了一些最近的自动问答生成方向。



<a id="4.实验Experiments"></a>
## 4.实验 Experiments

<a id="5.结论Conclusion"></a>
## 5.结论 Conclusion










